{
  "best_global_step": 840,
  "best_metric": 0.5203272153253424,
  "best_model_checkpoint": "/content/drive/MyDrive/Work/Capstone_Organized/3-Model_Training/3.2-LLM_Classification/3.2.0-FineTune_OpenBioLLM/OpenBioLLM_Checkpoints/checkpoint-840",
  "epoch": 5.0,
  "eval_steps": 500,
  "global_step": 1050,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.047619047619047616,
      "grad_norm": 473.1283264160156,
      "learning_rate": 9.523809523809525e-08,
      "loss": 8.55,
      "step": 10
    },
    {
      "epoch": 0.09523809523809523,
      "grad_norm": 356.2500305175781,
      "learning_rate": 3.3333333333333335e-07,
      "loss": 9.1997,
      "step": 20
    },
    {
      "epoch": 0.14285714285714285,
      "grad_norm": 192.23561096191406,
      "learning_rate": 5.714285714285715e-07,
      "loss": 7.9582,
      "step": 30
    },
    {
      "epoch": 0.19047619047619047,
      "grad_norm": 296.4898681640625,
      "learning_rate": 8.095238095238096e-07,
      "loss": 8.5528,
      "step": 40
    },
    {
      "epoch": 0.23809523809523808,
      "grad_norm": 175.4113006591797,
      "learning_rate": 1.0476190476190478e-06,
      "loss": 6.9355,
      "step": 50
    },
    {
      "epoch": 0.2857142857142857,
      "grad_norm": 114.84217834472656,
      "learning_rate": 1.2857142857142856e-06,
      "loss": 4.8628,
      "step": 60
    },
    {
      "epoch": 0.3333333333333333,
      "grad_norm": 271.5334777832031,
      "learning_rate": 1.523809523809524e-06,
      "loss": 3.8004,
      "step": 70
    },
    {
      "epoch": 0.38095238095238093,
      "grad_norm": 286.13623046875,
      "learning_rate": 1.761904761904762e-06,
      "loss": 3.7968,
      "step": 80
    },
    {
      "epoch": 0.42857142857142855,
      "grad_norm": 69.26998901367188,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 3.956,
      "step": 90
    },
    {
      "epoch": 0.47619047619047616,
      "grad_norm": 85.39361572265625,
      "learning_rate": 2.2380952380952384e-06,
      "loss": 3.7789,
      "step": 100
    },
    {
      "epoch": 0.5238095238095238,
      "grad_norm": 158.57568359375,
      "learning_rate": 2.4761904761904764e-06,
      "loss": 3.8073,
      "step": 110
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 99.92009735107422,
      "learning_rate": 2.7142857142857144e-06,
      "loss": 3.5779,
      "step": 120
    },
    {
      "epoch": 0.6190476190476191,
      "grad_norm": 130.354736328125,
      "learning_rate": 2.9523809523809525e-06,
      "loss": 3.7086,
      "step": 130
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 171.73484802246094,
      "learning_rate": 3.1904761904761905e-06,
      "loss": 3.4715,
      "step": 140
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 67.68699645996094,
      "learning_rate": 3.428571428571429e-06,
      "loss": 3.4147,
      "step": 150
    },
    {
      "epoch": 0.7619047619047619,
      "grad_norm": 299.71038818359375,
      "learning_rate": 3.6666666666666666e-06,
      "loss": 3.37,
      "step": 160
    },
    {
      "epoch": 0.8095238095238095,
      "grad_norm": 85.6669692993164,
      "learning_rate": 3.9047619047619055e-06,
      "loss": 3.276,
      "step": 170
    },
    {
      "epoch": 0.8571428571428571,
      "grad_norm": 211.67950439453125,
      "learning_rate": 4.1428571428571435e-06,
      "loss": 3.1312,
      "step": 180
    },
    {
      "epoch": 0.9047619047619048,
      "grad_norm": 91.49773406982422,
      "learning_rate": 4.3809523809523815e-06,
      "loss": 3.0972,
      "step": 190
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 82.4326400756836,
      "learning_rate": 4.6190476190476196e-06,
      "loss": 3.3726,
      "step": 200
    },
    {
      "epoch": 1.0,
      "grad_norm": 73.2900161743164,
      "learning_rate": 4.857142857142858e-06,
      "loss": 3.1688,
      "step": 210
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.6095238095238096,
      "eval_auc": 0.4983478702910959,
      "eval_f1": 0.2645739910313901,
      "eval_false_negatives": 197,
      "eval_false_positives": 131,
      "eval_loss": 0.8494375944137573,
      "eval_precision": 0.3105263157894737,
      "eval_recall/sensitivity": 0.23046875,
      "eval_runtime": 13.5759,
      "eval_samples_per_second": 61.874,
      "eval_specificity": 0.7756849315068494,
      "eval_steps_per_second": 7.734,
      "eval_true_negatives": 453,
      "eval_true_positives": 59,
      "step": 210
    },
    {
      "epoch": 1.0476190476190477,
      "grad_norm": 73.63407135009766,
      "learning_rate": 4.98941798941799e-06,
      "loss": 2.9415,
      "step": 220
    },
    {
      "epoch": 1.0952380952380953,
      "grad_norm": 100.97113037109375,
      "learning_rate": 4.962962962962964e-06,
      "loss": 2.627,
      "step": 230
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 105.82673645019531,
      "learning_rate": 4.936507936507937e-06,
      "loss": 3.1652,
      "step": 240
    },
    {
      "epoch": 1.1904761904761905,
      "grad_norm": 181.87559509277344,
      "learning_rate": 4.91005291005291e-06,
      "loss": 3.189,
      "step": 250
    },
    {
      "epoch": 1.2380952380952381,
      "grad_norm": 172.80099487304688,
      "learning_rate": 4.883597883597884e-06,
      "loss": 3.3584,
      "step": 260
    },
    {
      "epoch": 1.2857142857142856,
      "grad_norm": 251.36480712890625,
      "learning_rate": 4.857142857142858e-06,
      "loss": 3.1967,
      "step": 270
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 109.64617156982422,
      "learning_rate": 4.830687830687832e-06,
      "loss": 3.2624,
      "step": 280
    },
    {
      "epoch": 1.380952380952381,
      "grad_norm": 244.0347442626953,
      "learning_rate": 4.804232804232805e-06,
      "loss": 3.192,
      "step": 290
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 48.832847595214844,
      "learning_rate": 4.777777777777778e-06,
      "loss": 2.6564,
      "step": 300
    },
    {
      "epoch": 1.4761904761904763,
      "grad_norm": 99.40872955322266,
      "learning_rate": 4.7513227513227515e-06,
      "loss": 2.8506,
      "step": 310
    },
    {
      "epoch": 1.5238095238095237,
      "grad_norm": 97.60440826416016,
      "learning_rate": 4.724867724867726e-06,
      "loss": 3.1603,
      "step": 320
    },
    {
      "epoch": 1.5714285714285714,
      "grad_norm": 128.6259307861328,
      "learning_rate": 4.698412698412699e-06,
      "loss": 2.7639,
      "step": 330
    },
    {
      "epoch": 1.619047619047619,
      "grad_norm": 187.12283325195312,
      "learning_rate": 4.671957671957672e-06,
      "loss": 2.896,
      "step": 340
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 129.279052734375,
      "learning_rate": 4.6455026455026454e-06,
      "loss": 3.0836,
      "step": 350
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 202.77020263671875,
      "learning_rate": 4.6190476190476196e-06,
      "loss": 3.0893,
      "step": 360
    },
    {
      "epoch": 1.7619047619047619,
      "grad_norm": 61.58104705810547,
      "learning_rate": 4.592592592592593e-06,
      "loss": 3.0806,
      "step": 370
    },
    {
      "epoch": 1.8095238095238095,
      "grad_norm": 151.34945678710938,
      "learning_rate": 4.566137566137567e-06,
      "loss": 3.1268,
      "step": 380
    },
    {
      "epoch": 1.8571428571428572,
      "grad_norm": 77.04984283447266,
      "learning_rate": 4.53968253968254e-06,
      "loss": 2.716,
      "step": 390
    },
    {
      "epoch": 1.9047619047619047,
      "grad_norm": 285.198974609375,
      "learning_rate": 4.5132275132275135e-06,
      "loss": 2.9999,
      "step": 400
    },
    {
      "epoch": 1.9523809523809523,
      "grad_norm": 283.6949768066406,
      "learning_rate": 4.486772486772487e-06,
      "loss": 2.7615,
      "step": 410
    },
    {
      "epoch": 2.0,
      "grad_norm": 83.31765747070312,
      "learning_rate": 4.460317460317461e-06,
      "loss": 3.3308,
      "step": 420
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.49404761904761907,
      "eval_auc": 0.4960168289811644,
      "eval_f1": 0.3849493487698987,
      "eval_false_negatives": 123,
      "eval_false_positives": 302,
      "eval_loss": 0.7832451462745667,
      "eval_precision": 0.3057471264367816,
      "eval_recall/sensitivity": 0.51953125,
      "eval_runtime": 13.5791,
      "eval_samples_per_second": 61.86,
      "eval_specificity": 0.4828767123287671,
      "eval_steps_per_second": 7.732,
      "eval_true_negatives": 282,
      "eval_true_positives": 133,
      "step": 420
    },
    {
      "epoch": 2.0476190476190474,
      "grad_norm": 238.0260467529297,
      "learning_rate": 4.433862433862434e-06,
      "loss": 2.79,
      "step": 430
    },
    {
      "epoch": 2.0952380952380953,
      "grad_norm": 81.64073181152344,
      "learning_rate": 4.407407407407408e-06,
      "loss": 2.9591,
      "step": 440
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 177.21983337402344,
      "learning_rate": 4.3809523809523815e-06,
      "loss": 2.8292,
      "step": 450
    },
    {
      "epoch": 2.1904761904761907,
      "grad_norm": 287.4458923339844,
      "learning_rate": 4.354497354497355e-06,
      "loss": 2.8924,
      "step": 460
    },
    {
      "epoch": 2.238095238095238,
      "grad_norm": 231.71705627441406,
      "learning_rate": 4.328042328042328e-06,
      "loss": 3.1603,
      "step": 470
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 86.3564453125,
      "learning_rate": 4.301587301587302e-06,
      "loss": 2.8953,
      "step": 480
    },
    {
      "epoch": 2.3333333333333335,
      "grad_norm": 66.25282287597656,
      "learning_rate": 4.2751322751322754e-06,
      "loss": 2.7362,
      "step": 490
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 64.99789428710938,
      "learning_rate": 4.2486772486772496e-06,
      "loss": 2.5718,
      "step": 500
    },
    {
      "epoch": 2.4285714285714284,
      "grad_norm": 229.9142608642578,
      "learning_rate": 4.222222222222223e-06,
      "loss": 2.9015,
      "step": 510
    },
    {
      "epoch": 2.4761904761904763,
      "grad_norm": 108.19458770751953,
      "learning_rate": 4.195767195767196e-06,
      "loss": 2.7686,
      "step": 520
    },
    {
      "epoch": 2.5238095238095237,
      "grad_norm": 91.66593170166016,
      "learning_rate": 4.169312169312169e-06,
      "loss": 2.6636,
      "step": 530
    },
    {
      "epoch": 2.571428571428571,
      "grad_norm": 89.24822235107422,
      "learning_rate": 4.1428571428571435e-06,
      "loss": 2.8603,
      "step": 540
    },
    {
      "epoch": 2.619047619047619,
      "grad_norm": 149.4279022216797,
      "learning_rate": 4.116402116402117e-06,
      "loss": 2.8532,
      "step": 550
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 263.17193603515625,
      "learning_rate": 4.089947089947091e-06,
      "loss": 2.9862,
      "step": 560
    },
    {
      "epoch": 2.7142857142857144,
      "grad_norm": 282.0348815917969,
      "learning_rate": 4.063492063492064e-06,
      "loss": 3.0225,
      "step": 570
    },
    {
      "epoch": 2.761904761904762,
      "grad_norm": 94.49970245361328,
      "learning_rate": 4.037037037037037e-06,
      "loss": 2.734,
      "step": 580
    },
    {
      "epoch": 2.8095238095238093,
      "grad_norm": 93.42337036132812,
      "learning_rate": 4.010582010582011e-06,
      "loss": 2.8036,
      "step": 590
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 64.4403076171875,
      "learning_rate": 3.984126984126984e-06,
      "loss": 2.7196,
      "step": 600
    },
    {
      "epoch": 2.9047619047619047,
      "grad_norm": 116.51836395263672,
      "learning_rate": 3.957671957671958e-06,
      "loss": 2.9305,
      "step": 610
    },
    {
      "epoch": 2.9523809523809526,
      "grad_norm": 74.4985122680664,
      "learning_rate": 3.931216931216931e-06,
      "loss": 2.6668,
      "step": 620
    },
    {
      "epoch": 3.0,
      "grad_norm": 42.139461517333984,
      "learning_rate": 3.9047619047619055e-06,
      "loss": 2.7218,
      "step": 630
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.6261904761904762,
      "eval_auc": 0.5135514768835616,
      "eval_f1": 0.2764976958525346,
      "eval_false_negatives": 196,
      "eval_false_positives": 118,
      "eval_loss": 0.7533735632896423,
      "eval_precision": 0.33707865168539325,
      "eval_recall/sensitivity": 0.234375,
      "eval_runtime": 13.6027,
      "eval_samples_per_second": 61.753,
      "eval_specificity": 0.797945205479452,
      "eval_steps_per_second": 7.719,
      "eval_true_negatives": 466,
      "eval_true_positives": 60,
      "step": 630
    },
    {
      "epoch": 3.0476190476190474,
      "grad_norm": 53.497257232666016,
      "learning_rate": 3.878306878306879e-06,
      "loss": 2.4725,
      "step": 640
    },
    {
      "epoch": 3.0952380952380953,
      "grad_norm": 65.86927032470703,
      "learning_rate": 3.851851851851852e-06,
      "loss": 2.6956,
      "step": 650
    },
    {
      "epoch": 3.142857142857143,
      "grad_norm": 87.88822937011719,
      "learning_rate": 3.825396825396825e-06,
      "loss": 2.7859,
      "step": 660
    },
    {
      "epoch": 3.1904761904761907,
      "grad_norm": 150.34915161132812,
      "learning_rate": 3.7989417989417994e-06,
      "loss": 2.6792,
      "step": 670
    },
    {
      "epoch": 3.238095238095238,
      "grad_norm": 51.65056228637695,
      "learning_rate": 3.7724867724867726e-06,
      "loss": 2.8939,
      "step": 680
    },
    {
      "epoch": 3.2857142857142856,
      "grad_norm": 145.79129028320312,
      "learning_rate": 3.7460317460317463e-06,
      "loss": 2.8829,
      "step": 690
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 77.48387145996094,
      "learning_rate": 3.7195767195767196e-06,
      "loss": 2.8102,
      "step": 700
    },
    {
      "epoch": 3.380952380952381,
      "grad_norm": 76.17574310302734,
      "learning_rate": 3.6931216931216933e-06,
      "loss": 2.5449,
      "step": 710
    },
    {
      "epoch": 3.4285714285714284,
      "grad_norm": 50.2164306640625,
      "learning_rate": 3.6666666666666666e-06,
      "loss": 2.5936,
      "step": 720
    },
    {
      "epoch": 3.4761904761904763,
      "grad_norm": 111.26115417480469,
      "learning_rate": 3.6402116402116407e-06,
      "loss": 2.6822,
      "step": 730
    },
    {
      "epoch": 3.5238095238095237,
      "grad_norm": 186.987548828125,
      "learning_rate": 3.613756613756614e-06,
      "loss": 3.1948,
      "step": 740
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 182.249755859375,
      "learning_rate": 3.5873015873015877e-06,
      "loss": 3.1801,
      "step": 750
    },
    {
      "epoch": 3.619047619047619,
      "grad_norm": 148.5585174560547,
      "learning_rate": 3.560846560846561e-06,
      "loss": 2.7079,
      "step": 760
    },
    {
      "epoch": 3.6666666666666665,
      "grad_norm": 49.03056335449219,
      "learning_rate": 3.5343915343915346e-06,
      "loss": 2.6759,
      "step": 770
    },
    {
      "epoch": 3.7142857142857144,
      "grad_norm": 55.64649963378906,
      "learning_rate": 3.507936507936508e-06,
      "loss": 2.5885,
      "step": 780
    },
    {
      "epoch": 3.761904761904762,
      "grad_norm": 82.55479431152344,
      "learning_rate": 3.481481481481482e-06,
      "loss": 2.7306,
      "step": 790
    },
    {
      "epoch": 3.8095238095238093,
      "grad_norm": 102.72940826416016,
      "learning_rate": 3.4550264550264553e-06,
      "loss": 2.6733,
      "step": 800
    },
    {
      "epoch": 3.857142857142857,
      "grad_norm": 56.61379623413086,
      "learning_rate": 3.428571428571429e-06,
      "loss": 2.742,
      "step": 810
    },
    {
      "epoch": 3.9047619047619047,
      "grad_norm": 69.20025634765625,
      "learning_rate": 3.4021164021164022e-06,
      "loss": 2.7196,
      "step": 820
    },
    {
      "epoch": 3.9523809523809526,
      "grad_norm": 119.81743621826172,
      "learning_rate": 3.375661375661376e-06,
      "loss": 2.7149,
      "step": 830
    },
    {
      "epoch": 4.0,
      "grad_norm": 260.0867004394531,
      "learning_rate": 3.349206349206349e-06,
      "loss": 2.7135,
      "step": 840
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.6642857142857143,
      "eval_auc": 0.5203272153253424,
      "eval_f1": 0.23783783783783785,
      "eval_false_negatives": 212,
      "eval_false_positives": 70,
      "eval_loss": 0.7731927633285522,
      "eval_precision": 0.38596491228070173,
      "eval_recall/sensitivity": 0.171875,
      "eval_runtime": 13.6609,
      "eval_samples_per_second": 61.489,
      "eval_specificity": 0.8801369863013698,
      "eval_steps_per_second": 7.686,
      "eval_true_negatives": 514,
      "eval_true_positives": 44,
      "step": 840
    },
    {
      "epoch": 4.0476190476190474,
      "grad_norm": 93.26750183105469,
      "learning_rate": 3.322751322751323e-06,
      "loss": 2.9339,
      "step": 850
    },
    {
      "epoch": 4.095238095238095,
      "grad_norm": 59.03147888183594,
      "learning_rate": 3.296296296296296e-06,
      "loss": 2.6501,
      "step": 860
    },
    {
      "epoch": 4.142857142857143,
      "grad_norm": 43.4219856262207,
      "learning_rate": 3.2698412698412703e-06,
      "loss": 2.8034,
      "step": 870
    },
    {
      "epoch": 4.190476190476191,
      "grad_norm": 156.75132751464844,
      "learning_rate": 3.2433862433862435e-06,
      "loss": 2.6069,
      "step": 880
    },
    {
      "epoch": 4.238095238095238,
      "grad_norm": 156.4310302734375,
      "learning_rate": 3.2169312169312172e-06,
      "loss": 2.7458,
      "step": 890
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 148.702392578125,
      "learning_rate": 3.1904761904761905e-06,
      "loss": 2.7073,
      "step": 900
    },
    {
      "epoch": 4.333333333333333,
      "grad_norm": 124.65682983398438,
      "learning_rate": 3.164021164021164e-06,
      "loss": 2.9341,
      "step": 910
    },
    {
      "epoch": 4.380952380952381,
      "grad_norm": 54.419776916503906,
      "learning_rate": 3.1375661375661375e-06,
      "loss": 2.7102,
      "step": 920
    },
    {
      "epoch": 4.428571428571429,
      "grad_norm": 95.16092681884766,
      "learning_rate": 3.1111111111111116e-06,
      "loss": 2.8381,
      "step": 930
    },
    {
      "epoch": 4.476190476190476,
      "grad_norm": 112.92575073242188,
      "learning_rate": 3.084656084656085e-06,
      "loss": 2.5789,
      "step": 940
    },
    {
      "epoch": 4.523809523809524,
      "grad_norm": 203.69129943847656,
      "learning_rate": 3.0582010582010585e-06,
      "loss": 2.6466,
      "step": 950
    },
    {
      "epoch": 4.571428571428571,
      "grad_norm": 80.0968246459961,
      "learning_rate": 3.031746031746032e-06,
      "loss": 2.4983,
      "step": 960
    },
    {
      "epoch": 4.619047619047619,
      "grad_norm": 116.48131561279297,
      "learning_rate": 3.0052910052910055e-06,
      "loss": 2.6008,
      "step": 970
    },
    {
      "epoch": 4.666666666666667,
      "grad_norm": 183.86444091796875,
      "learning_rate": 2.9788359788359788e-06,
      "loss": 2.7497,
      "step": 980
    },
    {
      "epoch": 4.714285714285714,
      "grad_norm": 88.58370971679688,
      "learning_rate": 2.9523809523809525e-06,
      "loss": 2.4842,
      "step": 990
    },
    {
      "epoch": 4.761904761904762,
      "grad_norm": 64.63497161865234,
      "learning_rate": 2.9259259259259257e-06,
      "loss": 2.5679,
      "step": 1000
    },
    {
      "epoch": 4.809523809523809,
      "grad_norm": 82.19258117675781,
      "learning_rate": 2.8994708994709e-06,
      "loss": 2.7593,
      "step": 1010
    },
    {
      "epoch": 4.857142857142857,
      "grad_norm": 175.84756469726562,
      "learning_rate": 2.873015873015873e-06,
      "loss": 2.7631,
      "step": 1020
    },
    {
      "epoch": 4.904761904761905,
      "grad_norm": 244.18743896484375,
      "learning_rate": 2.846560846560847e-06,
      "loss": 2.8137,
      "step": 1030
    },
    {
      "epoch": 4.9523809523809526,
      "grad_norm": 128.4497528076172,
      "learning_rate": 2.82010582010582e-06,
      "loss": 2.6137,
      "step": 1040
    },
    {
      "epoch": 5.0,
      "grad_norm": 64.88059997558594,
      "learning_rate": 2.7936507936507938e-06,
      "loss": 2.479,
      "step": 1050
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.6071428571428571,
      "eval_auc": 0.513822372645548,
      "eval_f1": 0.3153526970954357,
      "eval_false_negatives": 180,
      "eval_false_positives": 150,
      "eval_loss": 0.7399172186851501,
      "eval_precision": 0.336283185840708,
      "eval_recall/sensitivity": 0.296875,
      "eval_runtime": 13.6275,
      "eval_samples_per_second": 61.64,
      "eval_specificity": 0.7431506849315068,
      "eval_steps_per_second": 7.705,
      "eval_true_negatives": 434,
      "eval_true_positives": 76,
      "step": 1050
    }
  ],
  "logging_steps": 10,
  "max_steps": 2100,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 2,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 1
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9.04054066642944e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
