# ER Triage LangGraph Workflow

A comprehensive LangGraph-based workflow for Emergency Room (ER) triage admission decisions, integrating traditional Machine Learning models, Large Language Model (LLM) classifiers, and a fusion agent with human-in-the-loop (HITL) capabilities.

## ğŸ“ Repository Structure

```
Capstone_Organized/
â”œâ”€â”€ 1-Data/                          # Data files
â”‚   â”œâ”€â”€ ED_Simulated_Database_Fixed.db
â”‚   â””â”€â”€ ED_Model_Training_Dataset.csv
â”œâ”€â”€ 2-PreWorkflow_Dataset_Prep/     # Data preparation notebooks
â”œâ”€â”€ 3-Model_Training/               # Model training artifacts
â”‚   â”œâ”€â”€ 3.1-Traditional_ML/
â”‚   â”‚   â””â”€â”€ 3.1.0-Traditional_ML_Artifacts/
â”‚   â”‚       â”œâ”€â”€ gb_model.joblib          # âš ï¸ Not in repo (too large)
â”‚   â”‚       â”œâ”€â”€ ml_preprocessor.joblib   # âš ï¸ Not in repo (too large)
â”‚   â”‚       â””â”€â”€ ml_feature_columns.json  # âœ… Included
â”‚   â””â”€â”€ 3.2-LLM_Classification/
â”‚       â””â”€â”€ 3.2.0-FineTune_OpenBioLLM/
â”‚           â””â”€â”€ OpenBioLLM_Final/        # âš ï¸ Not in repo (too large)
â”œâ”€â”€ 4-LangGraph/                    # LangGraph workflow notebooks
â”‚   â”œâ”€â”€ 4.0-LangGraph_Logs/        # Execution logs
â”‚   â””â”€â”€ 4.1.4-LangGraph_Agent_with_Reasoning-Optimal_Threshold_Finder.ipynb
â”œâ”€â”€ 5-Evaluation_Reports/          # Evaluation results
â””â”€â”€ er_triage_workflow/             # âœ… Python package (main code)
    â”œâ”€â”€ config/                     # Configuration
    â”œâ”€â”€ src/                        # Source code
    â”‚   â”œâ”€â”€ database/              # Database queries
    â”‚   â”œâ”€â”€ models/                # Model loading & inference
    â”‚   â”œâ”€â”€ utils/                 # Utilities
    â”‚   â”œâ”€â”€ workflow/              # LangGraph workflow
    â”‚   â””â”€â”€ main.py                # Entry point
    â”œâ”€â”€ tests/                      # Unit tests
    â”œâ”€â”€ scripts/                    # Utility scripts
    â””â”€â”€ requirements.txt           # Dependencies
```

## ğŸš€ Quick Start

### Prerequisites

1. **Python 3.9+**
2. **Model Artifacts**: You need to obtain the trained models separately (they're too large for Git):
   - ML Model: `3-Model_Training/3.1-Traditional_ML/3.1.0-Traditional_ML_Artifacts/gb_model.joblib`
   - ML Preprocessor: `3-Model_Training/3.1-Traditional_ML/3.1.0-Traditional_ML_Artifacts/ml_preprocessor.joblib`
   - LLM Model: `3-Model_Training/3.2-LLM_Classification/3.2.0-FineTune_OpenBioLLM/OpenBioLLM_Final/`

3. **Database**: `1-Data/ED_Simulated_Database_Fixed.db` (not in repo due to size)

### Installation

1. Clone the repository:
   ```bash
   git clone <your-repo-url>
   cd Capstone_Organized
   ```

2. Set up Python environment:
   ```bash
   cd er_triage_workflow
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   pip install -r requirements.txt
   ```

3. Set the base path (if different from default):
   ```bash
   export BASE_PATH="/path/to/Capstone_Organized"
   ```

4. Ensure model artifacts and database are in place (see structure above)

### Running the Workflow

```bash
cd er_triage_workflow
python -m src.main
```

Or use the workflow programmatically:

```python
from er_triage_workflow.src.main import run_simulation

result = run_simulation(
    visit_id=1,
    human_prompt="Patient is 70yo, frail, and on chemotherapy."
)
print(f"Decision: {result['decision']}")
```

## ğŸ“ Important Notes

### Large Files Handling

Due to GitHub's file size limits (100MB per file, 1GB repository warning), large files are currently excluded via `.gitignore`. You have several options:

#### Option 1: Use Git LFS (Recommended for Large Files)

Git LFS (Large File Storage) allows you to track large files without bloating your repository:

```bash
# Install Git LFS (if not already installed)
git lfs install

# Track large file types
git lfs track "*.joblib"
git lfs track "*.safetensors"
git lfs track "*.bin"
git lfs track "*.db"
git lfs track "*.pkl"

# Add the .gitattributes file
git add .gitattributes

# Add your large files
git add 1-Data/ED_Simulated_Database_Fixed.db
git add 3-Model_Training/**/*.joblib
git add 3-Model_Training/**/*.safetensors

# Commit and push
git commit -m "Add large files via Git LFS"
git push origin main
```

**Note**: Git LFS has storage quotas on GitHub (1GB free, then paid). Check [GitHub LFS pricing](https://docs.github.com/en/billing/managing-billing-for-git-large-file-storage/about-billing-for-git-large-file-storage).

#### Option 2: External Hosting (Recommended for Very Large Files)

For files > 100MB or to avoid LFS costs, host files externally:

1. **Google Drive / Dropbox**: Upload files and share download links
2. **Cloud Storage**: Use AWS S3, Google Cloud Storage, or Azure Blob Storage
3. **Hugging Face Hub**: For model files, use [Hugging Face Model Hub](https://huggingface.co/models)

Then document download links in `SETUP_GUIDE.md` or a `LARGE_FILES.md` file.

#### Option 3: Manual Addition (Current Approach)

Currently, large files are excluded. Users must add them manually after cloning:

- **Database files** (`.db`, `.sqlite`): Place in `1-Data/`
- **Model files** (`.joblib`, `.pkl`, `.safetensors`, `.bin`): Place in `3-Model_Training/`
- **Large CSV files**: Place in `1-Data/`
- **Log files** (`.jsonl`): Generated at runtime in `4-LangGraph/4.0-LangGraph_Logs/`

See `SETUP_GUIDE.md` for detailed instructions.

### Directory Structure

The code expects the following directory structure relative to `BASE_PATH`:

```
BASE_PATH/
â”œâ”€â”€ 1-Data/
â”‚   â””â”€â”€ ED_Simulated_Database_Fixed.db
â”œâ”€â”€ 3-Model_Training/
â”‚   â”œâ”€â”€ 3.1-Traditional_ML/
â”‚   â”‚   â””â”€â”€ 3.1.0-Traditional_ML_Artifacts/
â”‚   â”‚       â”œâ”€â”€ gb_model.joblib
â”‚   â”‚       â”œâ”€â”€ ml_preprocessor.joblib
â”‚   â”‚       â””â”€â”€ ml_feature_columns.json
â”‚   â””â”€â”€ 3.2-LLM_Classification/
â”‚       â””â”€â”€ 3.2.0-FineTune_OpenBioLLM/
â”‚           â””â”€â”€ OpenBioLLM_Final/
â””â”€â”€ 4-LangGraph/
    â””â”€â”€ 4.0-LangGraph_Logs/
```

## ğŸ”§ Configuration

Configuration is managed in `er_triage_workflow/config/settings.py`. You can:

1. Set `BASE_PATH` environment variable
2. Modify paths in the config file
3. Use `Config.from_env(base_path="/your/path")` programmatically

## ğŸ“š Documentation

- **Setup Guide**: See `SETUP_GUIDE.md` for post-clone setup instructions
- **Conversion Guide**: See `er_triage_workflow/CONVERSION_GUIDE.md`
- **Extraction Status**: See `er_triage_workflow/EXTRACTION_STATUS.md`
- **Quick Start**: See `er_triage_workflow/QUICK_START.md`

## ğŸ§ª Evaluation

The evaluation script is in the notebook `4-LangGraph/4.1.4-LangGraph_Agent_with_Reasoning-Optimal_Threshold_Finder.ipynb` (cells 38-48). This will be extracted to `er_triage_workflow/src/evaluation/evaluate.py` in a future update.

## ğŸ“„ License

[Add your license here]

## ğŸ‘¥ Contributors

[Add contributors here]
