{"cells":[{"cell_type":"markdown","metadata":{"id":"AQUhljnxNacw"},"source":["## Notebook Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SMFaX8MxFpNl","outputId":"b93ab9ad-bae8-44f9-e259-b21eb0629bc4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rDRKdKT-xn0v","outputId":"75e6a83b-1e7a-47e4-ab2e-25f52c18bb54"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.3/157.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m138.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip -q install --upgrade langgraph transformers peft accelerate bitsandbytes \"scikit-learn==1.6.1\" joblib \"pandas==2.2.2\" langchain-core langchain"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BYHrm0_Bc9wq"},"outputs":[],"source":["import json\n","import os\n","import uuid\n","import time\n","import traceback\n","from datetime import datetime\n","from typing import Optional, Dict, Any\n","from contextlib import contextmanager\n","\n","LOG_PATH = \"/content/drive/MyDrive/Colab Notebooks/Capstone_II/Final_Project/trace_log.jsonl\" # adjust path\n","ERROR_LOG_PATH = \"/content/drive/MyDrive/Colab Notebooks/Capstone_II/Final_Project/error_log.jsonl\" # adjust path\n","\n","# Global execution context for traceability\n","_execution_context = {\n","    \"execution_id\": None,\n","    \"visit_id\": None,\n","    \"start_time\": None,\n","}\n","\n","def init_execution_context(visit_id: int):\n","    \"\"\"Initialize execution context for a new workflow run.\"\"\"\n","    _execution_context[\"execution_id\"] = str(uuid.uuid4())\n","    _execution_context[\"visit_id\"] = visit_id\n","    _execution_context[\"start_time\"] = time.time()\n","    return _execution_context[\"execution_id\"]\n","\n","def get_execution_id() -> Optional[str]:\n","    \"\"\"Get current execution ID for traceability.\"\"\"\n","    return _execution_context.get(\"execution_id\")\n","\n","def _make_json_safe(obj):\n","    \"\"\"\n","    Recursively convert objects into JSON-serializable forms.\n","\n","    Rules:\n","    - dict     → clean keys and values\n","    - list/tuple → clean each element\n","    - basic types (int, float, str, bool, None) → keep as-is\n","    - anything else (custom classes like VitalSigns) → convert to str(obj)\n","    \"\"\"\n","    # Basic scalar types that JSON can handle directly\n","    if isinstance(obj, (int, float, str, bool)) or obj is None:\n","        return obj\n","\n","    # dict: clean each key/value\n","    if isinstance(obj, dict):\n","        return {str(k): _make_json_safe(v) for k, v in obj.items()}\n","\n","    # list or tuple: clean each element\n","    if isinstance(obj, (list, tuple)):\n","        return [_make_json_safe(v) for v in obj]\n","\n","    # Fallback: custom object, dataclass, pydantic model, etc.\n","    # We serialize it via its string representation.\n","    return str(obj)\n","\n","\n","def log_event(step: str, input_state: dict, output_state: dict, meta: dict = None,\n","              execution_id: Optional[str] = None, duration_ms: Optional[float] = None,\n","              error: Optional[str] = None):\n","    \"\"\"\n","    Enhanced logging utility with execution tracking and performance metrics.\n","\n","    Args:\n","        step: Name of the step/node\n","        input_state: Input state dictionary\n","        output_state: Output state dictionary\n","        meta: Additional metadata\n","        execution_id: Unique execution ID for traceability\n","        duration_ms: Execution duration in milliseconds\n","        error: Error message if any\n","    \"\"\"\n","    execution_id = execution_id or get_execution_id()\n","\n","    record = {\n","        \"timestamp\": datetime.now().isoformat(),\n","        \"execution_id\": execution_id,\n","        \"step\": step,\n","        \"input_state\": _make_json_safe(input_state),\n","        \"output_state\": _make_json_safe(output_state),\n","        \"meta\": _make_json_safe(meta or {}),\n","    }\n","\n","    # Add performance metrics\n","    if duration_ms is not None:\n","        record[\"duration_ms\"] = duration_ms\n","        record[\"meta\"][\"performance\"] = {\"duration_ms\": duration_ms}\n","\n","    # Add error information if present\n","    if error:\n","        record[\"error\"] = error\n","        record[\"meta\"][\"error\"] = error\n","\n","    # Append one line per event\n","    try:\n","        with open(LOG_PATH, \"a\") as f:\n","            f.write(json.dumps(record) + \"\\n\")\n","    except Exception as e:\n","        print(f\"[WARNING] Failed to write to log file: {e}\")\n","\n","    # Optional console debug\n","    log_msg = f\"[LOG] execution_id={execution_id} step={step}\"\n","    if duration_ms is not None:\n","        log_msg += f\" duration={duration_ms:.2f}ms\"\n","    if error:\n","        log_msg += f\" ERROR={error[:100]}\"\n","    print(log_msg)\n","\n","\n","def log_error(step: str, error: Exception, state: dict = None, execution_id: Optional[str] = None):\n","    \"\"\"\n","    Log errors with full context for debugging.\n","\n","    Args:\n","        step: Name of the step where error occurred\n","        error: Exception object\n","        state: State at time of error\n","        execution_id: Unique execution ID\n","    \"\"\"\n","    execution_id = execution_id or get_execution_id()\n","\n","    error_record = {\n","        \"timestamp\": datetime.now().isoformat(),\n","        \"execution_id\": execution_id,\n","        \"step\": step,\n","        \"error_type\": type(error).__name__,\n","        \"error_message\": str(error),\n","        \"traceback\": traceback.format_exc(),\n","        \"state\": _make_json_safe(state or {}),\n","    }\n","\n","    try:\n","        with open(ERROR_LOG_PATH, \"a\") as f:\n","            f.write(json.dumps(error_record) + \"\\n\")\n","    except Exception as e:\n","        print(f\"[WARNING] Failed to write to error log file: {e}\")\n","\n","    print(f\"[ERROR] execution_id={execution_id} step={step} error={type(error).__name__}: {str(error)}\")\n","\n","\n","@contextmanager\n","def track_performance(step_name: str):\n","    \"\"\"Context manager to track execution time of a step.\"\"\"\n","    start_time = time.time()\n","    try:\n","        yield\n","    finally:\n","        duration_ms = (time.time() - start_time) * 1000\n","        print(f\"[PERF] {step_name} took {duration_ms:.2f}ms\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2dkrFvBmiHm8"},"outputs":[],"source":["import copy\n","from functools import wraps\n","\n","def make_logged_node(fn, name: str, max_retries: int = 0, retry_delay: float = 0.1):\n","    \"\"\"\n","    Enhanced node wrapper with:\n","    - Comprehensive logging with execution IDs\n","    - Performance tracking\n","    - Error handling with graceful degradation\n","    - Retry logic for transient failures\n","    - State validation\n","\n","    Args:\n","        fn: Node function to wrap\n","        name: Name of the node for logging\n","        max_retries: Maximum number of retries for transient failures (0 = no retries)\n","        retry_delay: Delay between retries in seconds\n","    \"\"\"\n","    def _to_serializable_dict(obj):\n","        \"\"\"Recursively converts Pydantic BaseModel instances to dictionaries within a dict/list.\"\"\"\n","        if isinstance(obj, BaseModel):\n","            return obj.model_dump()\n","        elif isinstance(obj, dict):\n","            return {k: _to_serializable_dict(v) for k, v in obj.items()}\n","        elif isinstance(obj, list):\n","            return [_to_serializable_dict(elem) for elem in obj]\n","        return obj\n","\n","    def _validate_state(state: dict, required_keys: list) -> tuple[bool, Optional[str]]:\n","        \"\"\"Validate that required keys exist in state.\"\"\"\n","        missing = [key for key in required_keys if key not in state or state[key] is None]\n","        if missing:\n","            return False, f\"Missing required state keys: {missing}\"\n","        return True, None\n","\n","    @wraps(fn)\n","    def wrapped(state):\n","        execution_id = get_execution_id()\n","        start_time = time.time()\n","\n","        # Create a deep copy of the state and convert Pydantic objects for logging input\n","        serializable_input_state = _to_serializable_dict(copy.deepcopy(state))\n","\n","        # Log input\n","        log_event(\n","            f\"{name}_INPUT\",\n","            serializable_input_state,\n","            {},\n","            execution_id=execution_id\n","        )\n","\n","        # Retry logic for transient failures\n","        last_error = None\n","        for attempt in range(max_retries + 1):\n","            try:\n","                # Run original node\n","                with track_performance(f\"{name}_node\"):\n","                    out = fn(state)\n","\n","                # Validate output\n","                if out is None:\n","                    out = {}  # Ensure we always return a dict\n","\n","                # Calculate duration\n","                duration_ms = (time.time() - start_time) * 1000\n","\n","                # Create a deep copy of the output and convert Pydantic objects for logging output\n","                serializable_current_state_for_output_log = _to_serializable_dict(copy.deepcopy(state))\n","                serializable_output_from_node = _to_serializable_dict(copy.deepcopy(out))\n","\n","                # Log output with performance metrics\n","                log_event(\n","                    f\"{name}_OUTPUT\",\n","                    serializable_current_state_for_output_log,\n","                    serializable_output_from_node,\n","                    execution_id=execution_id,\n","                    duration_ms=duration_ms\n","                )\n","\n","                return out\n","\n","            except Exception as e:\n","                last_error = e\n","                duration_ms = (time.time() - start_time) * 1000\n","\n","                # Log error\n","                log_error(name, e, state, execution_id)\n","\n","                # If this is the last attempt, handle the error\n","                if attempt == max_retries:\n","                    # Log failed attempt\n","                    log_event(\n","                        f\"{name}_ERROR\",\n","                        serializable_input_state,\n","                        {},\n","                        execution_id=execution_id,\n","                        duration_ms=duration_ms,\n","                        error=f\"{type(e).__name__}: {str(e)}\"\n","                    )\n","\n","                    # For critical nodes, we might want to raise\n","                    # For non-critical nodes, return a safe default\n","                    if name in [\"fetch_data\", \"severity_gate\"]:\n","                        # Critical nodes - re-raise\n","                        raise\n","                    else:\n","                        # Non-critical nodes - return safe defaults\n","                        print(f\"[WARNING] {name} failed after {max_retries + 1} attempts, using safe defaults\")\n","                        return _get_safe_default_output(name, state)\n","                else:\n","                    # Wait before retry\n","                    time.sleep(retry_delay * (attempt + 1))  # Exponential backoff\n","                    print(f\"[RETRY] {name} attempt {attempt + 1}/{max_retries + 1}\")\n","\n","        # Should never reach here, but just in case\n","        return _get_safe_default_output(name, state)\n","\n","    return wrapped\n","\n","\n","def _get_safe_default_output(node_name: str, state: dict) -> dict:\n","    \"\"\"\n","    Return safe default outputs for nodes that fail.\n","    This allows the workflow to continue with degraded functionality.\n","    \"\"\"\n","    defaults = {\n","        \"ml_model\": {\"ml_score\": 0.5},  # Neutral probability\n","        \"llm_model\": {\"llm_score\": 0.5},  # Neutral probability\n","        \"human_input\": {},  # No output needed\n","        \"fusion\": {\n","            \"fused_prob\": 0.5,\n","            \"p_final\": 0.5,\n","            \"fusion_decision\": \"Error\",\n","            \"fusion_rationale\": \"Fusion failed, using default neutral probability.\"\n","        },\n","        \"confidence_check\": state,  # Pass through\n","        \"human_review\": {\n","            \"fused_prob\": state.get(\"fused_prob\", state.get(\"p_final\", 0.5)),\n","            \"p_final\": state.get(\"fused_prob\", state.get(\"p_final\", 0.5))\n","        },\n","        \"finalize\": {\n","            \"decision\": \"UNKNOWN\",\n","            \"rationale\": f\"Workflow encountered errors. Node {node_name} failed.\",\n","            \"p_final\": state.get(\"fused_prob\", state.get(\"p_final\", 0.5))\n","        }\n","    }\n","    return defaults.get(node_name, {})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kXen0tRTxqum"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import joblib\n","import json\n","import os\n","import sqlite3\n","import torch\n","from typing import TypedDict, Optional, Dict, Literal\n","from pydantic import BaseModel, field_validator\n","from math import exp\n","from datetime import datetime\n","\n","from langgraph.graph import StateGraph, START, END\n","from langgraph.checkpoint.memory import MemorySaver\n","\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM, BitsAndBytesConfig\n","from peft import PeftModel\n","\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.compose import ColumnTransformer\n","from sklearn.ensemble import GradientBoostingClassifier"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"31be_UzEIJuO","outputId":"379f8e2c-090d-49b1-c65b-1bce1631069d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tBO5jLVjyEDK","outputId":"8e6bb953-9544-4bb2-b9ff-2d27d8d1d08e"},"outputs":[{"output_type":"stream","name":"stdout","text":["All model artifacts and simulation DB paths are verified.\n"]}],"source":["# DEFINE PATHS\n","\n","BASE_PATH           = \"/content/drive/MyDrive/Colab Notebooks/Capstone_II/Final_Project\" # CHANGE THIS WHEN YOU USE THE NOTEBOOK, ENSURE THE FINAL DESTINATION IS Capstone_Organized\n","ML_ARTIFACT_PATH    = BASE_PATH + \"/3-Model_Training/3.1-Traditional_ML/3.1.0-Traditional_ML_Artifacts\"\n","LLM_ARTIFACT_PATH   = BASE_PATH + \"/3-Model_Training/3.2-LLM_Classification/3.2.0-FineTune_OpenBioLLM\"\n","\n","DB_PATH             = os.path.join(BASE_PATH + \"/1-Data/ED_Simulated_Database_Fixed.db\")\n","\n","ML_MODEL_PATH       = os.path.join(ML_ARTIFACT_PATH, \"gb_model.joblib\")\n","ML_PREPROCESSOR_PATH= os.path.join(ML_ARTIFACT_PATH, \"ml_preprocessor.joblib\")\n","ML_FEATURES_PATH    = os.path.join(ML_ARTIFACT_PATH, \"ml_feature_columns.json\")\n","\n","LLM_MODEL_ID        = \"aaditya/Llama3-OpenBioLLM-8B\"\n","LLM_MODEL_PATH      = os.path.join(LLM_ARTIFACT_PATH, \"OpenBioLLM_Final\")\n","LLM_OFFLOAD_PATH    = os.path.join(LLM_ARTIFACT_PATH, \"OpenBioLLM_Offload\")\n","os.makedirs(LLM_OFFLOAD_PATH, exist_ok=True)\n","\n","assert os.path.exists(ML_MODEL_PATH), f\"ML Model not found: {ML_MODEL_PATH}\"\n","assert os.path.exists(ML_PREPROCESSOR_PATH), f\"ML Preprocessor not found: {ML_PREPROCESSOR_PATH}\"\n","assert os.path.exists(ML_FEATURES_PATH), f\"ML Features JSON not found: {ML_FEATURES_PATH}\"\n","assert os.path.exists(LLM_MODEL_PATH), f\"LLM Checkpoint not found: {LLM_MODEL_PATH}\"\n","assert os.path.exists(DB_PATH), f\"Simulation DB not found: {DB_PATH}\"\n","\n","print(\"All model artifacts and simulation DB paths are verified.\")"]},{"cell_type":"markdown","metadata":{"id":"Tn4CtpaAvH_V"},"source":["## Load Artifacts & Define Helper Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1jh6I0kl2kwy","outputId":"9ec4030f-c8d3-4d7f-91b5-c19f4d8121d7"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.12/pickle.py:1760: UserWarning: [20:24:53] WARNING: /workspace/src/collective/../data/../common/error_msg.h:83: If you are loading a serialized model (like pickle in Python, RDS in R) or\n","configuration generated by an older version of XGBoost, please export the model by calling\n","`Booster.save_model` from that version first, then load it back in current version. See:\n","\n","    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n","\n","for more details about differences between saving model and serializing.\n","\n","  setstate(state)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Successfully loaded ML model and preprocessor (143 features).\n"]}],"source":["# LOAD ML ARTIFACTS\n","\n","# Define function for joblib pointer\n","def clean_text_for_ml(text: str) -> str:\n","    \"\"\"\n","    Cleans the *already redacted* notes for TF-IDF.\n","    This version removes the [AGE] tags and all non-alpha characters.\n","    (Copied from 3.1.1-Traditional_ML_Training.ipynb)\n","    \"\"\"\n","    if not isinstance(text, str):\n","        return \"\"\n","    text = re.sub(r'\\\\[.*?\\\\]', ' ', text) # Remove tags like [AGE]\n","    text = re.sub(r'[^a-zA-Z\\s]', ' ', text) # Remove special characters\n","    text = text.lower() # Convert to lowercase\n","    text = re.sub(r'\\s+', ' ', text).strip() # Consolidate whitespace\n","    return text\n","\n","# Load joblib files\n","ml_model = joblib.load(ML_MODEL_PATH)\n","ml_preprocessor = joblib.load(ML_PREPROCESSOR_PATH)\n","\n","with open(ML_FEATURES_PATH, 'r') as f:\n","    ml_feature_names = json.load(f)\n","\n","print(f\"\\nSuccessfully loaded ML model and preprocessor ({len(ml_feature_names)} features).\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":464,"referenced_widgets":["ba5b8c97a16b44459c82604d40be0c57","2926f9e3e7d64030af4eb85ddf05e180","5cbf75615fa74e4e80c95a0d96099b9a","f0900ccf5b4b45649f98d42b32662005","11437132ecaa4ae9892ceebaf63c8a73","8b4b7edadb7443a2af3c43118f9e5900","eae73de69ae744d38fa4ae3c372f5677","82e61d81dce04da49232663856082750","8a94a9e851f14a098da94c2e4b58ec3a","f018630ac426479195d2f96f2a1c6885","595a724531ff4d3c979f42b4b3c86032","4163a2ed8bff4834b95bc074bd2ea0b6","0c13027362d6459da668c5f4f5ba5aab","66417661c2754bd6bee7a5e14fd90890","94c3ef593b1248d4abca0893590c7112","0bf374a3b7e24f839f8e7a890dca5585","e45cb6477ad248308302628e0f764ae5","29ef63cf8b9c4c4c8be0372b8c665d1a","6b2d4c1033cb4a5e8df96c6ea2f82147","6fdda9bacbf847dd9abeee4b2d7d5e37","16950daeefd14719a4dc579d8bbd73d9","f6cc8f8077c448bfa78ff8e317e0e8b5","2f886651e3284558871ac79a9a6be5d5","91bc304385034143a9761aa31106ee2f","7c711fe88284466180d0ae97d20b60e2","28e54731441d4ae6b7d8325e4785de94","d85325e8dc73482c8b6408a0a5a68292","b8526ace9dc341ffbb0cbe6fcd0d2490","060dc633e9b94b68b51f5466951b80a8","b199aeaf16ba4b209e6ec8f4a070148a","ccad5026f9e242fc954b752c826c0ce3","7cd58420be0448cc9fbf19cbbc97297a","d3ea3761c61e40aca12dd6e06221e7b7","ba9d9dd762364ee59bb02a69e2c7f1c7","efb3e415fb854a19b739c280faa9503a","03a4d9f4cec44d9fa33ffbf80cecbbf6","7b1ea16658254d54b766622ad6f05f8a","04525b71a6994024a4cfa824e645e8b8","38b4858ccca5480ebcc2060392398e5e","1890f8f86c81478cb0f3ee51c1373644","20198b1b842f45139356a8379d0d5704","57d86a558bf746a18e374022fcafe61f","8291f2132c8448cd915add9767b9a6e2","5bd865b317224f8791116f921b048f5b","0133333d86ad482aaf7d31c123668e77","7f63de97c365449d9095c82f7c365e2e","5df8e80c82cf4d548781457fb7dd6b1f","18de533ea0054a20be12739b0ee1aab1","bf8ea643010b43aeab317346a3b416c1","116160384c04409580ae62325361fb26","b7de788d62a44bb98c25ecdfe1055304","82ee80f38e384112a72669ea67312de8","2edb52a2a1f24977810f1da1f8435485","3210269fabbd4a7e8853ac1d8e64b566","b9ed1d90b27947bbb740079c6b9fb235","cddded1b6ef648468dd42737ff1d4813","32a6309896794788bad68119aa8e499e","289c75f9f132465daee3a152e2eb092a","b6a5019194d1474686ca3bb189ff9fd0","f62bfa2d19c5430b88667bbf32835bd5","c0cb53af3f0d40d08f1648752ecf2046","c46e91ee845d4b66bcf7a10b08640e4c","be430d1f92f94dc8bab8f9fb1beccbc6","655094ee2ffd4e2c9efa2361279d9f82","1f7cb8782145487b884f62a5c82ddff0","d24638d52bbd4cf9b9407ae375e78735","1288ca4417ab4b9382578b85b992682a","5a7c5ac48da942da9d144e88f4210da8","76b4b5f295bf4caeadb341955a7a93fa","e81d2d9c636c43c287b9fdb551e9dddf","500b397067ab4c18ab2923b945df23b0","81ada5e65a6d4de9bb6af5bc992e3d36","45d61093bed544b5919f65606a4931b5","b387af0b95d94bfab3a6bd0ec0c4023a","8643a3f4955b4df68b7ad94e9059e14f","60098fb016fb413484a4fbb19c128013","78f9aa02bc0d4b94873641fc12d33cf2","3c8ca533e28c4b68a8db4db92e93cab5","86ca425c82af4115b73b3b3fa4451fdb","4d3ebd3b7f464f9c93ea00946748dffc","39ecf00a4f9c4f2cb1b98f44428c6a75","4990de143024475784568bcc14391483","f2d476402b084ba7800a186ec70a3acb","4588d95e926e473bbd135cf54cdcb1a0","a0e7ade5d0fd4a599f36d4e84c3ca745","a564cdcd8ad447668772c8c157f7ad18","2a1f6c01a4d843fb9b8c03f9fb23f434","dd41bf30af7041f9899707ea010e0778"]},"id":"h7uQmKHDF524","outputId":"73eb99d3-705d-49a0-b415-36730d6b73f2"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/704 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba5b8c97a16b44459c82604d40be0c57"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["`torch_dtype` is deprecated! Use `dtype` instead!\n"]},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin.index.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4163a2ed8bff4834b95bc074bd2ea0b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f886651e3284558871ac79a9a6be5d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model-00004-of-00004.bin:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba9d9dd762364ee59bb02a69e2c7f1c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model-00001-of-00004.bin:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0133333d86ad482aaf7d31c123668e77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model-00002-of-00004.bin:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cddded1b6ef648468dd42737ff1d4813"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model-00003-of-00004.bin:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1288ca4417ab4b9382578b85b992682a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c8ca533e28c4b68a8db4db92e93cab5"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at aaditya/Llama3-OpenBioLLM-8B and are newly initialized: ['score.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["\n","Successfully loaded fine-tuned OpenBioLLM model.\n"]}],"source":["from peft import AutoPeftModelForSequenceClassification\n","\n","classifier_tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL_PATH)\n","if classifier_tokenizer.pad_token is None:\n","    classifier_tokenizer.pad_token = classifier_tokenizer.eos_token\n","\n","# Use AutoPeftModelForSequenceClassification to load the fine-tuned model\n","llm_classifier_model = AutoPeftModelForSequenceClassification.from_pretrained(\n","    LLM_MODEL_PATH,\n","    num_labels=2,\n","    torch_dtype=torch.float32,\n","    trust_remote_code=True,\n","    device_map=\"auto\", # Requires a GPU!\n","    offload_folder=LLM_OFFLOAD_PATH\n",")\n","llm_classifier_model.eval()\n","\n","print(\"\\nSuccessfully loaded fine-tuned OpenBioLLM model.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":212,"referenced_widgets":["a00229253a9e4526bdee50b9f41ef5a4","a84465b4390f4b71bdc5d6796e3c567e","0f4cca56dfb2487e81edb381d1df744e","f8686dd5bd6142d085f128979811138a","34898a3b0c01422cab3213b80c1a4d7a","0c992475cd55439c86b160710913a7e3","7fef1d06c29e437bb391eb8db1e9f1d3","cf2d7d838d864fbab5c7d9d64650f5df","76db97d578e24c55911ccc68fcc8f9e3","284dc723b99048c2a36aff1cc53e578c","fa85d316f629432c8508bfeb5c8dfd3f","29d9aa787b014a7c9017b485fc5e4790","28569bdf415142a889b7c52e493ec810","7c0e7a7a1fe441ea86b3f58cae42d3e0","277f4be200c743668dccc1f9a63bda82","13c9888d973e4e739cb888f11ddffb28","7140e3f0d891473a8b24e19788d3e893","8d3cabe7ee0940d683edc77838571ebd","5f30ac89d8e14e1286afe1d74d13f8cc","9cec50d27b554633881bdba24fb0ba11","6a8de97f43974a98b5aafcf633b26459","86d4ff4ee86f41c38207026ec215a405","df57689962ef48309aa2fd780bb4dcbc","2dc0217e5d8b4060ba3aa1ac5e6705c3","3e1fb829107244c39adb7262269387bc","29da525d20a54b05b57ba6683aad9812","c5d829ca90c94616985a06cb71232ca8","f41eaeacdddf430d923f606ead05d63c","c6cfc9365b344d3fb9b1fc02e8b50794","922d44f0c3654f699f08ac35b40a05bd","2b919a3206f141729ebb80896d982176","90fd6167faf74031aa1d0069c904a899","0d72e26fe3f243e9a8b37306ab184041","f264b147cc6849bd889c2a5be6799027","0a29bb8465e741bd8b0904d1bb0c77f3","7edc0f02dcc94317ae506716a81a1c2d","571cc8213aac4c6bb844df8b4252eaf4","0f644461640c43429d27467311d75f71","0892506629694c978ed16c2823ec5239","3d543eeacab44af5869265528e0b638b","47a3b86bd268498b9ebeb8d02a7029e2","00dd3a24ab2b4c20ad98f049fcb93bd2","e2cf1050a4944237a3fe070cd0a4af45","1299781f55aa40709701bc6650a8160c","08663c7aee824341b1e62eda002807dc","f56a19995f61473eaadc3aacb50caf17","7449fb113aec474b9c74c464b59d97f8","2f4571d448e446649747374fcdcae125","2a9d74fd064b4776add64f0450d9217b","6de7fe1a74904ae59f24e134c4f8c916","8a80f95fe1a943879265e59e5978445b","ab4aae237d5a472e881bbf90a1d9f04f","e1f2bab5cfcd4d81b55bed160ab9cbc0","d63dcc23004a4b698199fd64d5952ab5","ec1b0fbd06d445ca8e46972421deedfc"]},"id":"hh3A6OOWmwPG","outputId":"e1966aba-28d0-4b42-d167-13ddd560dcdd"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a00229253a9e4526bdee50b9f41ef5a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29d9aa787b014a7c9017b485fc5e4790"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df57689962ef48309aa2fd780bb4dcbc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f264b147cc6849bd889c2a5be6799027"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/449 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08663c7aee824341b1e62eda002807dc"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Successfully loaded base OpenBioLLM *Fusion Agent* model.\n"]}],"source":["# LOAD LLM FUSION AGENT\n","\n","# 1. Configure 4-bit quantization to save memory\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.float16,\n",")\n","\n","# 2. Load the base model with AutoModelForCausalLM\n","llm_fusion_model = AutoModelForCausalLM.from_pretrained(\n","    LLM_MODEL_ID,\n","    quantization_config=bnb_config,\n","    trust_remote_code=True,\n","    device_map=\"auto\",\n",")\n","\n","# 3. Load its tokenizer\n","fusion_tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL_ID, trust_remote_code=True)\n","if fusion_tokenizer.pad_token is None:\n","    fusion_tokenizer.pad_token = fusion_tokenizer.eos_token\n","\n","print(\"\\nSuccessfully loaded base OpenBioLLM *Fusion Agent* model.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qBtG054a8UlO","outputId":"c34a6168-fa75-4a0b-b632-43d249f670a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model helper functions defined.\n"]}],"source":["# LOAD HELPER FUNCTIONS\n","\n","# --- Helper for LLM Prediction ---\n","def format_for_llm_classifier(patient_data: dict) -> str:\n","    \"\"\"Formats the raw DB row for the CLASSIFICATION model.\"\"\"\n","    return (\n","        f\"age range: {patient_data.get('age_bucket')} / \"\n","        f\"sex: {patient_data.get('sex')} / \"\n","        f\"heart rate: {patient_data.get('heart_rate')} / \"\n","        f\"systolic blood pressure: {patient_data.get('bp_systolic')} / \"\n","        f\"diastolic blood pressure: {patient_data.get('bp_diastolic')} / \"\n","        f\"respiratory rate: {patient_data.get('resp_rate')} / \"\n","        f\"temperature in Celsius: {patient_data.get('temperature_C')} / \"\n","        f\"oxygen saturation: {patient_data.get('oxygen_saturation')} / \"\n","        f\"ESI: {int(patient_data.get('ESI', 0))} / \"\n","        f\"recent admissions (in 30 days): {int(patient_data.get('recent_admissions_30d', 0))} / \"\n","        f\"{patient_data.get('triage_notes_redacted', '')}\"\n","    )\n","\n","def llm_predict_proba(text: str) -> float:\n","    \"\"\"Runs the formatted text through the CLASSIFIER and returns P(Admit).\"\"\"\n","    device = llm_classifier_model.device\n","    inputs = classifier_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n","    inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","    with torch.no_grad():\n","        logits = llm_classifier_model(**inputs).logits\n","        probs = torch.softmax(logits, dim=-1)[0]\n","        return float(probs[1].cpu().numpy())\n","\n","\n","# --- Helper for ML Prediction ---\n","def ml_predict_proba(patient_data: dict) -> float:\n","    \"\"\"Runs the raw data through the ML preprocessor and model.\"\"\"\n","    input_df = pd.DataFrame([patient_data])\n","    transformed_data = ml_preprocessor.transform(input_df)\n","    input_transformed_df = pd.DataFrame(transformed_data.toarray(), columns=ml_feature_names)\n","    prob_admit = ml_model.predict_proba(input_transformed_df)[0][1]\n","    return float(prob_admit)\n","\n","print(\"Model helper functions defined.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rAO01CsfnR9V","outputId":"332f1c72-c85f-4659-c2a1-23176438de62"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fusion helper functions defined.\n"]}],"source":["def run_fusion_agent(ml_prob: float, llm_prob: float, human_note: str) -> dict:\n","    \"\"\"\n","    Uses the generative LLM to synthesize inputs and make a\n","    final decision with rationale.\n","    \"\"\"\n","\n","    prompt = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n","You are an expert ER triage physician. Your job is to synthesize three signals to make a final, clinically sound admission decision.\n","\n","You are given three inputs:\n","1) p_ml:  probability of admission from a traditional ML model (strong on structured vitals).\n","2) p_llm: probability of admission from an LLM classifier (strong on clinical text).\n","3) human_note: short free-text note from a nurse or physician providing real-time context.\n","\n","Your task:\n","- Interpret all three signals.\n","- Resolve disagreements between the signals.\n","- Produce ONE final admission decision.\n","- Provide ONE rationale explaining exactly WHY you chose \"Admit\" or \"Discharge\".\n","  * Your rationale MUST explicitly reference p_ml, p_llm, and human_note.\n","  * It MUST give a clear clinical justification (e.g., high risk → admit, stable symptoms → discharge).\n","\n","Output STRICTLY as a single valid JSON object with EXACTLY two keys:\n","{{\n","  \"decision\": \"Admit\" | \"Discharge\",\n","  \"rationale\": \"string (2–4 sentences explaining the reason for your decision based on p_ml, p_llm, and human_note)\"\n","}}\n","\n","Do NOT output anything else.\n","Do NOT add comments or markdown.\n","Return ONLY the JSON object.\n","<|eot_id|><|start_header_id|>user<|end_header_id|>\n","Please make a final decision based on this information:\n","- p_ml (ML model): {ml_prob:.2f}\n","- p_llm (LLM classifier): {llm_prob:.2f}\n","- human_note: \"{human_note}\"\n","\n","Return ONLY the JSON object described above:\n","<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n","\"\"\"\n","\n","    device = llm_fusion_model.device\n","    inputs = fusion_tokenizer(prompt, return_tensors=\"pt\").to(device)\n","\n","    # Generate the response\n","    with torch.no_grad():\n","        outputs = llm_fusion_model.generate(\n","            **inputs,\n","            max_new_tokens=150,\n","            eos_token_id=fusion_tokenizer.eos_token_id\n","        )\n","\n","    # Decode and clean the output\n","    response_text = fusion_tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n","\n","    # Extract the JSON part\n","    json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n","    if json_match:\n","        try:\n","            return json.loads(json_match.group(0))\n","        except json.JSONDecodeError:\n","            return {\"decision\": \"Error\", \"rationale\": \"Failed to parse LLM JSON response.\"}\n","    else:\n","        return {\"decision\": \"Error\", \"rationale\": \"No JSON object found in LLM response.\"}\n","\n","print(\"Fusion helper functions defined.\")"]},{"cell_type":"markdown","metadata":{"id":"SjfsIbvF8fbQ"},"source":["### Define Graph State"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pkepvlM58g3a","outputId":"fc156d15-f10b-4510-9015-274ceff97df8"},"outputs":[{"output_type":"stream","name":"stdout","text":["LangGraph state defined with enhanced optional fields for robustness.\n"]}],"source":["class VitalSigns(BaseModel):\n","    \"\"\"Pydantic model for validating vital signs.\"\"\"\n","    sex: Optional[str] = None\n","    age_bucket: Optional[str] = None\n","    heart_rate: Optional[float] = None\n","    resp_rate: Optional[float] = None\n","    bp_systolic: Optional[float] = None\n","    bp_diastolic: Optional[float] = None\n","    oxygen_saturation: Optional[float] = None\n","    temperature_C: Optional[float] = None\n","    ESI: Optional[int] = None\n","    mental_status: Optional[str] = None\n","    recent_admissions_30d: Optional[int] = None\n","\n","\n","class ERState(TypedDict, total=False):\n","    \"\"\"Defines the state of our graph with optional fields for robustness.\"\"\"\n","    visit_id: int\n","    human_prompt: str\n","    patient_data: Dict\n","    vitals_validated: VitalSigns\n","    triage_text: str\n","    ml_score: Optional[float]\n","    llm_score: Optional[float]\n","    severe: Optional[bool]\n","    p_final: Optional[float]\n","    fused_prob: Optional[float]\n","    decision: Optional[str]\n","    final_decision: Optional[str]\n","    confidence: Optional[float]\n","    rationale: Optional[str]\n","    fusion_decision: Optional[str]\n","    fusion_rationale: Optional[str]\n","    human_override: Optional[float]\n","    execution_id: Optional[str]  # For traceability\n","    error_log: Optional[list]  # Track errors during execution\n","\n","print(\"LangGraph state defined with enhanced optional fields for robustness.\")\n","\n","\n","def validate_initial_state(state: dict) -> tuple[bool, Optional[str]]:\n","    \"\"\"\n","    Validate initial state before workflow execution.\n","\n","    Returns:\n","        (is_valid, error_message)\n","    \"\"\"\n","    required = [\"visit_id\"]\n","    missing = [key for key in required if key not in state]\n","    if missing:\n","        return False, f\"Missing required initial state keys: {missing}\"\n","\n","    if not isinstance(state.get(\"visit_id\"), int) or state[\"visit_id\"] <= 0:\n","        return False, f\"Invalid visit_id: {state.get('visit_id')}\"\n","\n","    return True, None\n","\n","\n","def validate_state_transition(state: dict, node_name: str) -> tuple[bool, Optional[str]]:\n","    \"\"\"\n","    Validate state before node execution based on node requirements.\n","\n","    Returns:\n","        (is_valid, error_message)\n","    \"\"\"\n","    node_requirements = {\n","        \"fetch_data\": [\"visit_id\"],\n","        \"severity_gate\": [\"vitals_validated\"],\n","        \"ml_model\": [\"patient_data\"],\n","        \"llm_model\": [\"patient_data\"],\n","        \"human_input\": [\"human_prompt\"],\n","        \"fusion\": [\"ml_score\", \"llm_score\"],\n","        \"confidence_check\": [\"ml_score\", \"llm_score\", \"fused_prob\"],\n","        \"human_review\": [\"fused_prob\"],\n","        \"finalize\": [\"fused_prob\"],\n","    }\n","\n","    required = node_requirements.get(node_name, [])\n","    missing = [key for key in required if key not in state or state[key] is None]\n","    if missing:\n","        return False, f\"Node {node_name} missing required state keys: {missing}\"\n","\n","    return True, None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OP99DR459VyA"},"outputs":[],"source":["# --- Node 1: Fetch Data from DB ---\n","def fetch_data_node(state: ERState):\n","    \"\"\"\n","    Fetch Data Node\n","    ---------------\n","    Takes a visit_id, connects to the DB, and fetches the patient's\n","    de-identified data from Visit_Details, Triage_Notes, and ESI.\n","\n","    According to the diagram flow:\n","    - START → fetch_data (solid arrow)\n","    - fetch_data → severity_gate (solid arrow)\n","\n","    Enhanced with:\n","    - Input validation\n","    - Better error messages\n","    - Execution ID tracking\n","    \"\"\"\n","    visit_id = state.get('visit_id')\n","    execution_id = get_execution_id()\n","\n","    # Validate input\n","    if not visit_id or not isinstance(visit_id, int) or visit_id <= 0:\n","        raise ValueError(f\"Invalid visit_id: {visit_id}\")\n","\n","    print(f\"--- 1. Fetching data for visit_id: {visit_id} (execution_id: {execution_id}) ---\")\n","\n","    # Initialize execution context if not already set\n","    if execution_id is None:\n","        init_execution_context(visit_id)\n","        execution_id = get_execution_id()\n","\n","    # Update state with execution ID for traceability\n","    state_update = {\"execution_id\": execution_id}\n","\n","    conn = None\n","    try:\n","        # Validate DB path exists\n","        if not os.path.exists(DB_PATH):\n","            raise FileNotFoundError(f\"Database file not found: {DB_PATH}\")\n","\n","        conn = sqlite3.connect(DB_PATH, timeout=10.0)  # Add timeout\n","        conn.row_factory = sqlite3.Row\n","\n","        query = \"\"\"\n","        SELECT\n","            v.visit_id, v.patient_id, v.sex, v.age_bucket,\n","            v.heart_rate, v.bp_systolic, v.bp_diastolic, v.resp_rate,\n","            v.temperature_C, v.oxygen_saturation, v.recent_admissions_30d,\n","            v.admitted,\n","            t.triage_notes_redacted,\n","            e.ESI\n","        FROM Visit_Details v\n","        LEFT JOIN Triage_Notes t ON v.visit_id = t.visit_id AND v.patient_id = t.patient_id\n","        LEFT JOIN ESI e ON v.visit_id = e.visit_id AND v.patient_id = e.patient_id\n","        WHERE v.visit_id = ?\n","        \"\"\"\n","\n","        cursor = conn.cursor()\n","        cursor.execute(query, (visit_id,))\n","        row = cursor.fetchone()\n","\n","    except sqlite3.Error as e:\n","        error_msg = f\"Database error for visit_id {visit_id}: {str(e)}\"\n","        log_error(\"fetch_data\", e, state, execution_id)\n","        raise RuntimeError(error_msg) from e\n","    except Exception as e:\n","        error_msg = f\"Unexpected error fetching data for visit_id {visit_id}: {str(e)}\"\n","        log_error(\"fetch_data\", e, state, execution_id)\n","        raise\n","    finally:\n","        if conn:\n","            try:\n","                conn.close()\n","            except Exception:\n","                pass  # Ignore errors during cleanup\n","\n","    if row is None:\n","        error_msg = f\"No data found for visit_id: {visit_id} in {DB_PATH}\"\n","        raise ValueError(error_msg)\n","\n","    patient_data = dict(row)\n","\n","    # Validate that we have essential data\n","    if not patient_data.get('visit_id'):\n","        raise ValueError(f\"Invalid patient data returned for visit_id: {visit_id}\")\n","\n","    # Validate vitals with error handling\n","    try:\n","        vitals_validated = VitalSigns(**patient_data)\n","    except Exception as e:\n","        log_error(\"fetch_data_vitals_validation\", e, {\"patient_data\": patient_data}, execution_id)\n","        # Try to create with minimal required fields\n","        vitals_validated = VitalSigns(\n","            sex=patient_data.get('sex'),\n","            age_bucket=patient_data.get('age_bucket'),\n","            heart_rate=patient_data.get('heart_rate'),\n","            resp_rate=patient_data.get('resp_rate'),\n","            bp_systolic=patient_data.get('bp_systolic'),\n","            bp_diastolic=patient_data.get('bp_diastolic'),\n","            oxygen_saturation=patient_data.get('oxygen_saturation'),\n","            temperature_C=patient_data.get('temperature_C'),\n","            ESI=patient_data.get('ESI'),\n","            recent_admissions_30d=patient_data.get('recent_admissions_30d')\n","        )\n","\n","    state_update.update({\n","        \"patient_data\": patient_data,\n","        \"vitals_validated\": vitals_validated,\n","        \"triage_text\": patient_data.get('triage_notes_redacted', '')\n","    })\n","\n","    return state_update\n","\n","# --- Node 2: Severity Gate ---\n","def severity_gate_node(state: ERState):\n","    \"\"\"\n","    Severity Gate Node\n","    ------------------\n","    Checks for any critical vital signs that would require immediate admission.\n","\n","    According to the diagram flow:\n","    - fetch_data → severity_gate (solid arrow)\n","    - severity_gate has two conditional paths:\n","      1. Early exit (dotted arrow labeled \"end\") → END\n","      2. Continue (dotted arrow) → run_models\n","    \"\"\"\n","    print(\"--- 2. Checking severity gate ---\")\n","    v = state[\"vitals_validated\"]\n","\n","    if (v.oxygen_saturation is not None and v.oxygen_saturation < 88) or \\\n","       (v.bp_systolic is not None and v.bp_systolic < 80) or \\\n","       (v.resp_rate is not None and (v.resp_rate > 35 or v.resp_rate < 8)):\n","        print(\" -> CRITICAL: Patient is severe. Bypassing models.\")\n","        return {\n","            \"severe\": True,\n","            \"decision\": \"Admit\",\n","            \"p_final\": 1.0,\n","            \"rationale\": \"Critical vital signs detected. Bypassed ML/LLM.\"\n","        }\n","\n","    print(\" -> OK: Patient is not severe. Proceeding to models.\")\n","    return {\"severe\": False}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mS07x5_A9an8"},"outputs":[],"source":["# --- Node 3a: ML Model ---\n","def ml_model_node(state: ERState):\n","    \"\"\"\n","    ML Model Node\n","    -------------\n","    Runs the patient data through the retrained ML pipeline.\n","\n","    According to the diagram flow:\n","    - run_models → ml_model (solid arrow, parallel execution)\n","    - ml_model → fusion (solid arrow, converges with other models)\n","\n","    Enhanced with:\n","    - Input validation\n","    - Error handling with fallback\n","    - Score validation (0-1 range)\n","    \"\"\"\n","    print(\"--- 3a. Running ML Model ---\")\n","\n","    # Validate input\n","    patient_data = state.get('patient_data')\n","    if not patient_data:\n","        raise ValueError(\"Missing patient_data for ML model\")\n","\n","    try:\n","        score = ml_predict_proba(patient_data)\n","\n","        # Validate score is in valid range\n","        if not isinstance(score, (int, float)) or score < 0 or score > 1:\n","            print(f\"[WARNING] ML model returned invalid score: {score}, clamping to [0, 1]\")\n","            score = max(0.0, min(1.0, float(score)))\n","\n","        print(f\" -> ML Score (P_Admit): {score:.4f}\")\n","        return {\"ml_score\": float(score)}\n","\n","    except Exception as e:\n","        log_error(\"ml_model\", e, state, get_execution_id())\n","        # Return neutral score on error\n","        print(f\"[WARNING] ML model failed, using neutral score: {e}\")\n","        return {\"ml_score\": 0.5}\n","\n","# --- Node 3b: LLM Model ---\n","def llm_model_node(state: ERState):\n","    \"\"\"\n","    LLM Model Node\n","    --------------\n","    Runs the patient data through the retrained LLM pipeline.\n","\n","    According to the diagram flow:\n","    - run_models → llm_model (solid arrow, parallel execution)\n","    - llm_model → fusion (solid arrow, converges with other models)\n","\n","    Enhanced with:\n","    - Input validation\n","    - Error handling with fallback\n","    - Score validation (0-1 range)\n","    \"\"\"\n","    print(\"--- 3b. Running LLM Classifier ---\")\n","\n","    # Validate input\n","    patient_data = state.get('patient_data')\n","    if not patient_data:\n","        raise ValueError(\"Missing patient_data for LLM model\")\n","\n","    try:\n","        formatted_text = format_for_llm_classifier(patient_data)\n","\n","        # Validate formatted text is not empty\n","        if not formatted_text or not formatted_text.strip():\n","            print(\"[WARNING] Empty formatted text for LLM, using default\")\n","            formatted_text = \"No patient data available.\"\n","\n","        score = llm_predict_proba(formatted_text)\n","\n","        # Validate score is in valid range\n","        if not isinstance(score, (int, float)) or score < 0 or score > 1:\n","            print(f\"[WARNING] LLM model returned invalid score: {score}, clamping to [0, 1]\")\n","            score = max(0.0, min(1.0, float(score)))\n","\n","        print(f\" -> LLM Classifier Score (P_Admit): {score:.4f}\")\n","        return {\"llm_score\": float(score)}\n","\n","    except Exception as e:\n","        log_error(\"llm_model\", e, state, get_execution_id())\n","        # Return neutral score on error\n","        print(f\"[WARNING] LLM model failed, using neutral score: {e}\")\n","        return {\"llm_score\": 0.5}\n","\n","# --- Node 3c: Human Input ---\n","def human_input_node(state: ERState):\n","    \"\"\"\n","    Human Input Node\n","    ---------------\n","    This node acknowledges and processes the human prompt/note.\n","\n","    According to the diagram flow:\n","    - run_models → human_input (solid arrow, parallel execution)\n","    - human_input → fusion (solid arrow, converges with other models)\n","    \"\"\"\n","    print(\"--- 3c. Acknowledging Human Input ---\")\n","    print(f\" -> Human Note: '{state['human_prompt']}'\")\n","    return {}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FNe6Npqmnq04","outputId":"42dca2af-3c29-447b-84d3-61b7b47bd494"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fusion & Logic nodes defined.\n"]}],"source":["# --- Node 4: Fusion ---\n","def fusion_node(state: ERState):\n","    \"\"\"\n","    Fusion Node\n","    -----------\n","    Fuses the outputs from human_input, llm_model, and ml_model.\n","\n","    According to the diagram flow:\n","    - human_input, llm_model, ml_model → fusion (solid arrows, all converge)\n","    - fusion → confidence_check (solid arrow)\n","\n","    Calls the generative fusion agent (run_fusion_agent) to produce:\n","      - fusion_decision    : \"Admit\" / \"Discharge\" / \"Error\"\n","      - fusion_rationale   : textual explanation (2–4 sentences)\n","\n","    Also computes a numeric fused probability:\n","      fused_prob = 0.7 * ml_prob + 0.3 * llm_prob\n","\n","    Returns a partial state update with:\n","      - fused_prob\n","      - p_final            (alias for fused_prob)\n","      - fusion_decision\n","      - fusion_rationale\n","    \"\"\"\n","\n","    print(\"--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\")\n","\n","    # Validate and extract inputs with defaults\n","    ml_prob = state.get(\"ml_score\")\n","    llm_prob = state.get(\"llm_score\")\n","    human_note = (state.get(\"human_prompt\") or \"\").strip()\n","\n","    # Validate scores exist and are valid\n","    if ml_prob is None:\n","        print(\"[WARNING] ml_score missing, using default 0.5\")\n","        ml_prob = 0.5\n","    if llm_prob is None:\n","        print(\"[WARNING] llm_score missing, using default 0.5\")\n","        llm_prob = 0.5\n","\n","    # Ensure scores are in valid range\n","    ml_prob = max(0.0, min(1.0, float(ml_prob)))\n","    llm_prob = max(0.0, min(1.0, float(llm_prob)))\n","\n","    execution_id = get_execution_id()\n","\n","    # 1) Call fusion agent with error handling\n","    fusion_output = None\n","    fusion_error = None\n","    try:\n","        fusion_output = run_fusion_agent(\n","            ml_prob=ml_prob,\n","            llm_prob=llm_prob,\n","            human_note=human_note,\n","        )\n","\n","        # Validate fusion output\n","        if not isinstance(fusion_output, dict):\n","            raise ValueError(\"Fusion agent returned non-dict output\")\n","\n","    except Exception as e:\n","        fusion_error = str(e)\n","        log_error(\"fusion_agent\", e, state, execution_id)\n","        print(f\" -> Fusion agent raised an exception: {e}\")\n","        fusion_output = {\n","            \"decision\": \"Error\",\n","            \"rationale\": f\"Exception during fusion agent call: {e}. Using weighted average.\",\n","        }\n","\n","    fusion_decision = fusion_output.get(\"decision\", \"Error\") if fusion_output else \"Error\"\n","    fusion_rationale = fusion_output.get(\n","        \"rationale\",\n","        \"No rationale returned by fusion agent. Using weighted average of ML and LLM scores.\"\n","    ) if fusion_output else \"Fusion agent failed. Using weighted average.\"\n","\n","    # 2) Numeric fused probability (always compute as fallback)\n","    fused_prob = 0.7 * ml_prob + 0.3 * llm_prob\n","\n","    # If fusion agent failed, use weighted average as decision\n","    if fusion_error or fusion_decision == \"Error\":\n","        if fused_prob >= 0.5:\n","            fusion_decision = \"Admit\"\n","        else:\n","            fusion_decision = \"Discharge\"\n","        fusion_rationale = f\"Fusion agent unavailable. Using weighted average (0.7*ML + 0.3*LLM) = {fused_prob:.3f}. Decision: {fusion_decision}.\"\n","\n","    print(\n","        f\" -> Final P(Admit) Score (numeric): {fused_prob:.4f} | \"\n","        f\"Fusion Agent Decision: {fusion_decision}\"\n","    )\n","    print(f\" -> Fusion Agent Rationale (inside fusion_node): {fusion_rationale}\")\n","\n","    # 3) VERY IMPORTANT: return all fields you want to keep in the state\n","    return {\n","        \"fused_prob\": float(fused_prob),\n","        \"p_final\": float(fused_prob),\n","        \"fusion_decision\": fusion_decision,\n","        \"fusion_rationale\": fusion_rationale,\n","    }\n","\n","\n","\n","# --- Conditional Edge: Severity Gate ---\n","def conditional_severity_gate(state: ERState):\n","    \"\"\"\n","    Conditional Severity Gate Routing\n","    ----------------------------------\n","    Routes the workflow based on severity assessment:\n","    - If severe (critical vitals) → \"end\" (early exit to END)\n","    - If not severe → \"run_models\" (proceed to parallel model execution)\n","\n","    This matches the diagram flow where severity_gate has two paths:\n","    1. Early exit path (dotted arrow labeled \"end\") → END\n","    2. Continue path (dotted arrow) → run_models\n","    \"\"\"\n","    if state.get(\"severe\", False):\n","        print(\"[Routing] Severe case detected → early exit to END\")\n","        return \"end\"  # Go straight to the end (early exit path)\n","    else:\n","        print(\"[Routing] Non-severe case → proceeding to run_models\")\n","        return \"run_models\"  # Proceed to parallel branches\n","\n","print(\"Fusion & Logic nodes defined.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z5Sy_dIi7sP1"},"outputs":[],"source":["def confidence_check_node(state: ERState):\n","    \"\"\"\n","    Confidence Check Node\n","    ---------------------\n","    This node is executed after the fusion step.\n","\n","    According to the diagram flow:\n","    - fusion → confidence_check (solid arrow)\n","    - confidence_check has two conditional paths:\n","      1. high_confidence (dotted arrow) → finalize\n","      2. low_confidence (dotted arrow) → human_review\n","\n","    Purpose:\n","    - Validate that ML and LLM scores exist in the state.\n","    - Print debugging information for verification.\n","    - Pass-through node (no state modification).\n","\n","    NOTE:\n","    The actual routing decision (high vs. low confidence)\n","    is performed by `conditional_confidence_routing`.\n","    \"\"\"\n","    ml = state.get(\"ml_score\")\n","    llm = state.get(\"llm_score\")\n","    fused_prob = state.get(\"fused_prob\", state.get(\"p_final\"))\n","    print(\"--- 5. Confidence Check Node ---\")\n","    print(f\"[ConfidenceCheck] ml_score={ml:.4f}, llm_score={llm:.4f}, fused_prob={fused_prob:.4f}\")\n","    return state\n","\n","def human_review_node(state: ERState):\n","    \"\"\"\n","    Human Review Node (HITL - Human In The Loop)\n","    ---------------------------------------------\n","    This node is executed when confidence_check routes to low_confidence.\n","\n","    According to the diagram flow:\n","    - confidence_check → low_confidence (dotted arrow) → human_review\n","    - human_review → finalize (solid arrow)\n","\n","    This node provides human oversight for low-confidence cases.\n","\n","    Workflow:\n","    1. On first pass, LangGraph stops *before* this node\n","       if interrupt_before=[\"human_review\"] is set.\n","    2. You manually inspect the state via get_state().\n","    3. You insert state[\"human_override\"] manually.\n","    4. The graph is resumed → this node executes.\n","\n","    Behavior:\n","    - If human_override exists → override fused_prob.\n","    - If not → use the original fused_prob.\n","\n","    This ensures fully traceable HITL correction.\n","    \"\"\"\n","    print(\"--- 6. Human Review Node (HITL) ---\")\n","    override = state.get(\"human_override\", None)\n","\n","    if override is not None:\n","        output = {\"fused_prob\": float(override), \"p_final\": float(override)}\n","        log_event(\"human_review_override\", dict(state), output)\n","        print(f\"[HITL] Human override applied → fused_prob={override:.4f}\")\n","        return output\n","\n","    # No override → retain original fused_prob\n","    fused_prob = state.get(\"fused_prob\", state.get(\"p_final\"))\n","    output = {\"fused_prob\": float(fused_prob), \"p_final\": float(fused_prob)}\n","    log_event(\"human_review_no_override\", dict(state), output)\n","    print(f\"[HITL] No override provided → using original fused_prob={fused_prob:.4f}\")\n","    return output\n","\n","\n","\n","# 2d. finalize node\n","def finalize_node(state: ERState):\n","    \"\"\"\n","    Finalize Node\n","    -------------\n","    This node produces the final admission decision and rationale.\n","\n","    According to the diagram flow:\n","    - finalize can be reached from two paths:\n","      1. confidence_check → high_confidence (dotted arrow) → finalize\n","      2. confidence_check → low_confidence → human_review → finalize (solid arrow)\n","    - finalize → END (solid arrow)\n","\n","    Decision rule:\n","      - ADMIT     if fused_prob >= 0.50\n","      - DISCHARGE if fused_prob <  0.50\n","      - UNKNOWN   if fused_prob is missing\n","\n","    It writes the following fields into the state:\n","      - final_decision : canonical final decision\n","      - rationale      : canonical final rationale\n","      - decision       : backward-compatible alias\n","      - p_final        : backward-compatible alias for fused_prob\n","\n","    IMPORTANT:\n","      - We start from the existing state (`dict(state)`) so that\n","        previous fields like `fusion_rationale` are preserved.\n","    \"\"\"\n","\n","    print(\"--- 7. Finalize Node ---\")\n","\n","    # Prefer fused_prob, but fall back to p_final if needed\n","    fused = state.get(\"fused_prob\", state.get(\"p_final\", None))\n","\n","    if fused is None:\n","        decision = \"UNKNOWN\"\n","        rationale = (\n","            \"Missing fused_prob; unable to generate a final decision. \"\n","            \"Check fusion or human review steps.\"\n","        )\n","    else:\n","        THRESH = 0.5\n","        if fused >= THRESH:\n","            decision = \"ADMIT\"\n","            rationale = (\n","                f\"Fused probability {fused:.2f} ≥ threshold {THRESH:.2f}; \"\n","                \"patient should be admitted.\"\n","            )\n","        else:\n","            decision = \"DISCHARGE\"\n","            rationale = (\n","                f\"Fused probability {fused:.2f} < threshold {THRESH:.2f}; \"\n","                \"patient may be safely discharged.\"\n","            )\n","\n","    # Merge decision fields back into the *existing* state\n","    new_state = dict(state)\n","    new_state[\"final_decision\"] = decision\n","    new_state[\"rationale\"] = rationale\n","\n","    # Backward-compatible aliases\n","    new_state[\"decision\"] = decision\n","    new_state[\"p_final\"] = fused\n","\n","    log_event(\"finalize_node\", dict(state), new_state)\n","    print(f\"[Finalize] Decision={decision}, Rationale={rationale}\")\n","\n","    return new_state\n","\n","\n","# 2e. confidence routing function（decide high / low confidence）\n","def conditional_confidence_routing(state: ERState):\n","    \"\"\"\n","    Conditional Confidence Routing\n","    ------------------------------\n","    This function determines whether the workflow should:\n","    - Auto-complete the decision (high confidence), OR\n","    - Trigger a Human Review (low confidence)\n","\n","    According to the diagram flow:\n","    - confidence_check has two conditional paths:\n","      1. high_confidence (dotted arrow) → finalize\n","      2. low_confidence (dotted arrow) → human_review\n","\n","    It returns one of ONLY these keys (must match add_conditional_edges):\n","        - \"high_confidence\"\n","        - \"low_confidence\"\n","\n","    This ensures LangGraph can correctly route AND\n","    ensures the interrupt_before=[\"human_review\"] will fire\n","    when low confidence is detected.\n","\n","    Routing Logic:\n","    1. If ML or LLM score is missing → LOW CONFIDENCE (force review)\n","    2. Compute:\n","        - probability gap = |ml_score - llm_score|\n","        - average score   = (ml_score + llm_score) / 2\n","    3. High confidence if:\n","        - gap < 0.20  AND  avg > 0.70\n","    4. Otherwise → low confidence → human review\n","    \"\"\"\n","    ml = state.get(\"ml_score\")\n","    llm = state.get(\"llm_score\")\n","\n","    # Missing scores → force human review\n","    if ml is None or llm is None:\n","        print(\"[Routing] Missing ML/LLM scores → LOW confidence → human_review\")\n","        return \"low_confidence\"\n","\n","    prob_gap = abs(ml - llm)\n","    avg_prob = (ml + llm) / 2\n","\n","    HIGH_CONF_GAP = 0.20\n","    HIGH_CONF_THRESH = 0.70\n","\n","    # High confidence path (matches diagram: high_confidence → finalize)\n","    if prob_gap < HIGH_CONF_GAP and avg_prob > HIGH_CONF_THRESH:\n","        print(f\"[Routing] HIGH confidence (gap={prob_gap:.2f}, avg={avg_prob:.2f}) → finalize\")\n","        return \"high_confidence\"\n","\n","    # Low confidence path (matches diagram: low_confidence → human_review)\n","    print(f\"[Routing] LOW confidence (gap={prob_gap:.2f}, avg={avg_prob:.2f}) → human_review\")\n","    return \"low_confidence\"\n","\n","\n","# Define a router node for parallel execution\n","def run_models_node(state: ERState):\n","    \"\"\"\n","    Run Models Router Node\n","    ----------------------\n","    This is a router node that triggers the parallel model runs.\n","\n","    According to the diagram flow:\n","    - severity_gate → run_models (dotted arrow, when not severe)\n","    - run_models fans out in parallel to:\n","      1. human_input (solid arrow)\n","      2. llm_model (solid arrow)\n","      3. ml_model (solid arrow)\n","    - All three converge into fusion (solid arrows from each)\n","    \"\"\"\n","    print(\"--- 3. Fanning out to parallel models (human_input, llm_model, ml_model) ---\")\n","    return {}"]},{"cell_type":"markdown","metadata":{"id":"Bj5BKMY2Ngsd"},"source":["## Initiate the Graph"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XSWiayWf9kVg"},"outputs":[],"source":["# 1. Initialize the graph\n","workflow = StateGraph(ERState)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ya-2TyQC1PUW","outputId":"fcde8802-9222-403b-c4a1-7b83173bb46b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- LangGraph Compiled Successfully! ---\n","Graph flow matches the diagram:\n","  START → fetch_data → severity_gate → (end OR run_models)\n","    → run_models → [human_input, llm_model, ml_model] (parallel)\n","    → fusion → confidence_check → (high_confidence OR low_confidence)\n","    → (high_confidence → finalize) OR (low_confidence → human_review → finalize)\n","    → finalize → END\n"]}],"source":["# ============================================\n","# Graph Construction - Matching Diagram Flow\n","# ============================================\n","# Flow according to diagram:\n","# START → fetch_data → severity_gate → (end OR run_models)\n","#   → run_models → [human_input, llm_model, ml_model] (parallel)\n","#   → fusion → confidence_check → (high_confidence OR low_confidence)\n","#   → (high_confidence → finalize) OR (low_confidence → human_review → finalize)\n","#   → finalize → END\n","\n","# Add all the nodes with enhanced error handling and retry logic\n","# Critical nodes (fetch_data, severity_gate) have no retries - failures should be explicit\n","# Non-critical nodes can retry transient failures\n","\n","workflow.add_node(\"fetch_data\", make_logged_node(fetch_data_node, \"fetch_data\", max_retries=0))\n","workflow.add_node(\"severity_gate\", make_logged_node(severity_gate_node, \"severity_gate\", max_retries=0))\n","workflow.add_node(\"run_models\", make_logged_node(run_models_node, \"run_models\", max_retries=0))   # router node\n","workflow.add_node(\"ml_model\", make_logged_node(ml_model_node, \"ml_model\", max_retries=1, retry_delay=0.5))\n","workflow.add_node(\"llm_model\", make_logged_node(llm_model_node, \"llm_model\", max_retries=1, retry_delay=0.5))\n","workflow.add_node(\"human_input\", make_logged_node(human_input_node, \"human_input\", max_retries=0))\n","workflow.add_node(\"fusion\", make_logged_node(fusion_node, \"fusion\", max_retries=1, retry_delay=1.0))\n","workflow.add_node(\"confidence_check\", make_logged_node(confidence_check_node, \"confidence_check\", max_retries=0))\n","workflow.add_node(\"human_review\", make_logged_node(human_review_node, \"human_review\", max_retries=0))\n","workflow.add_node(\"finalize\", make_logged_node(finalize_node, \"finalize\", max_retries=0))\n","\n","# ============================================\n","# Define the graph flow (matching diagram)\n","# ============================================\n","\n","# START → fetch_data (entry point)\n","workflow.set_entry_point(\"fetch_data\")\n","\n","# fetch_data → severity_gate (solid arrow)\n","workflow.add_edge(\"fetch_data\", \"severity_gate\")\n","\n","# severity_gate → conditional routing (matches diagram: two dotted arrows)\n","#   - \"end\" (early exit) → END\n","#   - \"run_models\" (continue) → run_models\n","workflow.add_conditional_edges(\n","    \"severity_gate\",\n","    conditional_severity_gate,\n","    {\n","        \"run_models\": \"run_models\",  # Continue path (dotted arrow in diagram)\n","        \"end\": END,                   # Early exit path (dotted arrow labeled \"end\" in diagram)\n","    },\n",")\n","\n","# run_models → parallel fan-out (matches diagram: three solid arrows)\n","# All three models run in parallel\n","workflow.add_edge(\"run_models\", \"ml_model\")\n","workflow.add_edge(\"run_models\", \"llm_model\")\n","workflow.add_edge(\"run_models\", \"human_input\")\n","\n","# Converge into fusion (matches diagram: three solid arrows converging)\n","# All three parallel branches must complete before fusion runs\n","workflow.add_edge(\"ml_model\", \"fusion\")\n","workflow.add_edge(\"llm_model\", \"fusion\")\n","workflow.add_edge(\"human_input\", \"fusion\")\n","\n","# fusion → confidence_check (solid arrow)\n","workflow.add_edge(\"fusion\", \"confidence_check\")\n","\n","# confidence_check → conditional routing (matches diagram: two dotted arrows)\n","#   - \"high_confidence\" (dotted arrow) → finalize\n","#   - \"low_confidence\" (dotted arrow) → human_review\n","workflow.add_conditional_edges(\n","    \"confidence_check\",\n","    conditional_confidence_routing,\n","    {\n","        \"high_confidence\": \"finalize\",    # High confidence path (dotted arrow in diagram)\n","        \"low_confidence\": \"human_review\",  # Low confidence path (dotted arrow in diagram)\n","    },\n",")\n","\n","# human_review → finalize (solid arrow)\n","# This path is taken when confidence is low\n","workflow.add_edge(\"human_review\", \"finalize\")\n","\n","# finalize → END (solid arrow)\n","workflow.add_edge(\"finalize\", END)\n","\n","# ============================================\n","# Compile the graph\n","# ============================================\n","memory = MemorySaver()\n","graph = workflow.compile(\n","    checkpointer=memory,\n","    #interrupt_before=[\"human_review\"],  # Uncomment to enable HITL interrupt\n",")\n","\n","print(\"\\n--- LangGraph Compiled Successfully! ---\")\n","print(\"Graph flow matches the diagram:\")\n","print(\"  START → fetch_data → severity_gate → (end OR run_models)\")\n","print(\"    → run_models → [human_input, llm_model, ml_model] (parallel)\")\n","print(\"    → fusion → confidence_check → (high_confidence OR low_confidence)\")\n","print(\"    → (high_confidence → finalize) OR (low_confidence → human_review → finalize)\")\n","print(\"    → finalize → END\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":993},"id":"LPyIyHg59kxE","outputId":"ce157aae-fae3-4c8b-f8ff-49a36b35961a"},"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{}}],"source":["from IPython.display import Image, display\n","\n","try:\n","    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n","except Exception:\n","    print(\"Could not draw graph. Skipping visualization.\")"]},{"cell_type":"markdown","metadata":{"id":"BVZi0ZuqCy7U"},"source":["## Test Run the Graph"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vZQaIYBwHyKz","outputId":"0080ca71-2952-4312-b7d0-1fff42b6be18"},"outputs":[{"output_type":"stream","name":"stdout","text":["Enhanced workflow invocation helper defined.\n"]}],"source":["## Enhanced Workflow Invocation Helper\n","\n","def invoke_workflow_with_tracking(graph, inputs: dict, config: dict = None):\n","    \"\"\"\n","    Enhanced workflow invocation with automatic execution tracking.\n","\n","    This function:\n","    1. Validates initial state\n","    2. Initializes execution context\n","    3. Invokes the graph\n","    4. Returns results with execution metadata\n","\n","    Args:\n","        graph: Compiled LangGraph workflow\n","        inputs: Input state dictionary\n","        config: LangGraph configuration (optional)\n","\n","    Returns:\n","        Final state dictionary with execution metadata\n","    \"\"\"\n","    # Validate initial state\n","    is_valid, error_msg = validate_initial_state(inputs)\n","    if not is_valid:\n","        raise ValueError(f\"Invalid initial state: {error_msg}\")\n","\n","    # Initialize execution context\n","    visit_id = inputs.get('visit_id')\n","    execution_id = init_execution_context(visit_id)\n","\n","    print(f\"\\n{'='*60}\")\n","    print(f\"Starting workflow execution\")\n","    print(f\"  Execution ID: {execution_id}\")\n","    print(f\"  Visit ID: {visit_id}\")\n","    print(f\"{'='*60}\\n\")\n","\n","    try:\n","        # Invoke graph\n","        if config is None:\n","            config = {\"configurable\": {\"thread_id\": f\"exec-{execution_id}\"}}\n","\n","        final_state = graph.invoke(inputs, config)\n","\n","        # Add execution metadata\n","        execution_time = time.time() - _execution_context[\"start_time\"]\n","        final_state[\"execution_metadata\"] = {\n","            \"execution_id\": execution_id,\n","            \"visit_id\": visit_id,\n","            \"execution_time_seconds\": execution_time,\n","            \"timestamp\": datetime.now().isoformat()\n","        }\n","\n","        print(f\"\\n{'='*60}\")\n","        print(f\"Workflow execution completed\")\n","        print(f\"  Execution ID: {execution_id}\")\n","        print(f\"  Total time: {execution_time:.2f}s\")\n","        print(f\"  Final decision: {final_state.get('decision', 'N/A')}\")\n","        print(f\"{'='*60}\\n\")\n","\n","        return final_state\n","\n","    except Exception as e:\n","        execution_time = time.time() - _execution_context[\"start_time\"]\n","        log_error(\"workflow_invocation\", e, inputs, execution_id)\n","\n","        print(f\"\\n{'='*60}\")\n","        print(f\"Workflow execution failed\")\n","        print(f\"  Execution ID: {execution_id}\")\n","        print(f\"  Time before failure: {execution_time:.2f}s\")\n","        print(f\"  Error: {type(e).__name__}: {str(e)}\")\n","        print(f\"{'='*60}\\n\")\n","\n","        raise\n","\n","print(\"Enhanced workflow invocation helper defined.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WifqwykRCylP","outputId":"8b9be7ab-3476-4116-8ada-d7d66a4d30e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["--- Running Simulation 1 (High-Risk Note) ---\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=fetch_data_INPUT\n","--- 1. Fetching data for visit_id: 1 (execution_id: 91a5cd44-2ca1-4640-8687-21ce1cee764c) ---\n","[PERF] fetch_data_node took 4.62ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=fetch_data_OUTPUT duration=8.21ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=severity_gate_INPUT\n","--- 2. Checking severity gate ---\n"," -> OK: Patient is not severe. Proceeding to models.\n","[PERF] severity_gate_node took 0.01ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=severity_gate_OUTPUT duration=2.20ms\n","[Routing] Non-severe case → proceeding to run_models\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=run_models_INPUT\n","--- 3. Fanning out to parallel models (human_input, llm_model, ml_model) ---\n","[PERF] run_models_node took 0.01ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=run_models_OUTPUT duration=2.27ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=human_input_INPUT\n","--- 3c. Acknowledging Human Input ---\n"," -> Human Note: 'Patient is 70yo, frail, and on chemotherapy.'\n","[PERF] human_input_node took 0.01ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=llm_model_INPUT\n","--- 3b. Running LLM Classifier ---\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=ml_model_INPUT\n","--- 3a. Running ML Model ---\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=human_input_OUTPUT duration=3.56ms\n"," -> ML Score (P_Admit): 0.8125\n","[PERF] ml_model_node took 14.87ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=ml_model_OUTPUT duration=21.86ms\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> LLM Classifier Score (P_Admit): 0.9899\n","[PERF] llm_model_node took 172.64ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=llm_model_OUTPUT duration=178.27ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=fusion_INPUT\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"," -> Final P(Admit) Score (numeric): 0.8657 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Given the patient's frailty, age, and current chemotherapy, the high probabilities from both the ML model and LLM classifier, along with the clinical context provided by the human_note, support the decision to admit the patient.\n","[PERF] fusion_node took 3191.89ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=fusion_OUTPUT duration=3205.24ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=confidence_check_INPUT\n","--- 5. Confidence Check Node ---\n","[ConfidenceCheck] ml_score=0.8125, llm_score=0.9899, fused_prob=0.8657\n","[PERF] confidence_check_node took 0.02ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=confidence_check_OUTPUT duration=2.58ms\n","[Routing] HIGH confidence (gap=0.18, avg=0.90) → finalize\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=finalize_INPUT\n","--- 7. Finalize Node ---\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=finalize_node\n","[Finalize] Decision=ADMIT, Rationale=Fused probability 0.87 ≥ threshold 0.50; patient should be admitted.\n","[PERF] finalize_node took 2.20ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=finalize_OUTPUT duration=4.67ms\n","\n","--- Final State 1 ---\n","Decision: ADMIT\n","P(Admit): 0.8657\n","Final Rationale: Fused probability 0.87 ≥ threshold 0.50; patient should be admitted.\n","Fusion Rationale: Given the patient's frailty, age, and current chemotherapy, the high probabilities from both the ML model and LLM classifier, along with the clinical context provided by the human_note, support the decision to admit the patient.\n","\n","\n","--- Running Simulation 2 (Low-Risk Note) ---\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=fetch_data_INPUT\n","--- 1. Fetching data for visit_id: 5 (execution_id: 91a5cd44-2ca1-4640-8687-21ce1cee764c) ---\n","[PERF] fetch_data_node took 4.60ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=fetch_data_OUTPUT duration=7.07ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=severity_gate_INPUT\n","--- 2. Checking severity gate ---\n"," -> OK: Patient is not severe. Proceeding to models.\n","[PERF] severity_gate_node took 0.02ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=severity_gate_OUTPUT duration=2.75ms\n","[Routing] Non-severe case → proceeding to run_models\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=run_models_INPUT\n","--- 3. Fanning out to parallel models (human_input, llm_model, ml_model) ---\n","[PERF] run_models_node took 0.01ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=run_models_OUTPUT duration=2.36ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=human_input_INPUT\n","--- 3c. Acknowledging Human Input ---\n"," -> Human Note: 'Patient looks stable, likely just needs follow-up.'\n","[PERF] human_input_node took 0.01ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=llm_model_INPUT\n","--- 3b. Running LLM Classifier ---\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=ml_model_INPUT\n","--- 3a. Running ML Model ---\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=human_input_OUTPUT duration=3.20ms\n"," -> ML Score (P_Admit): 0.0922\n","[PERF] ml_model_node took 15.11ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=ml_model_OUTPUT duration=22.41ms\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> LLM Classifier Score (P_Admit): 0.9807\n","[PERF] llm_model_node took 169.42ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=llm_model_OUTPUT duration=174.98ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=fusion_INPUT\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"," -> Final P(Admit) Score (numeric): 0.3588 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the LLM classifier's high probability of admission (0.98), and the nurse's note suggesting the patient is stable and likely needs follow-up, we decide to discharge the patient. Despite the ML model's lower probability (0.09), the clinical context provided by the human_note overrides the machine learning prediction.\n","[PERF] fusion_node took 4279.19ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=fusion_OUTPUT duration=4281.69ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=confidence_check_INPUT\n","--- 5. Confidence Check Node ---\n","[ConfidenceCheck] ml_score=0.0922, llm_score=0.9807, fused_prob=0.3588\n","[PERF] confidence_check_node took 0.01ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=confidence_check_OUTPUT duration=2.32ms\n","[Routing] LOW confidence (gap=0.89, avg=0.54) → human_review\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=human_review_INPUT\n","--- 6. Human Review Node (HITL) ---\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=human_review_override\n","[HITL] Human override applied → fused_prob=0.1500\n","[PERF] human_review_node took 1.82ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=human_review_OUTPUT duration=4.15ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=finalize_INPUT\n","--- 7. Finalize Node ---\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=finalize_node\n","[Finalize] Decision=DISCHARGE, Rationale=Fused probability 0.15 < threshold 0.50; patient may be safely discharged.\n","[PERF] finalize_node took 1.94ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=finalize_OUTPUT duration=4.19ms\n","\n","--- Final State 2 ---\n","Decision: DISCHARGE\n","P(Admit): 0.1500\n","Final Rationale: Fused probability 0.15 < threshold 0.50; patient may be safely discharged.\n","Fusion Rationale: Based on the LLM classifier's high probability of admission (0.98), and the nurse's note suggesting the patient is stable and likely needs follow-up, we decide to discharge the patient. Despite the ML model's lower probability (0.09), the clinical context provided by the human_note overrides the machine learning prediction.\n"]}],"source":["# --- Run 1: High-Risk Patient Note ---\n","# We'll use visit_id=1 and add a high-risk note\n","inputs_1 = {\n","    \"visit_id\": 1,\n","    \"human_prompt\": \"Patient is 70yo, frail, and on chemotherapy.\"\n","}\n","config = {\"configurable\": {\"thread_id\": \"sim-1\"}}\n","\n","print(\"--- Running Simulation 1 (High-Risk Note) ---\")\n","final_state_1 = graph.invoke(inputs_1, config)\n","\n","print(\"\\n--- Final State 1 ---\")\n","print(f\"Decision: {final_state_1.get('decision')}\")\n","print(f\"P(Admit): {final_state_1.get('p_final'):.4f}\")\n","print(f\"Final Rationale: {final_state_1.get('rationale')}\")\n","print(f\"Fusion Rationale: {final_state_1.get('fusion_rationale')}\")\n","\n","\n","# --- Run 2: Low-Risk Patient Note ---\n","# We'll use visit_id=5 (assuming this is a lower-risk patient in the DB)\n","inputs_2 = {\n","    \"visit_id\": 5,\n","    \"human_prompt\": \"Patient looks stable, likely just needs follow-up.\"\n","}\n","config = {\"configurable\": {\"thread_id\": \"sim-2\"}}\n","\n","print(\"\\n\\n--- Running Simulation 2 (Low-Risk Note) ---\")\n","final_state_2 = graph.invoke(inputs_2, config)\n","\n","print(\"\\n--- Final State 2 ---\")\n","print(f\"Decision: {final_state_2.get('decision')}\")\n","print(f\"P(Admit): {final_state_2.get('p_final'):.4f}\")\n","print(f\"Final Rationale: {final_state_2.get('rationale')}\")\n","print(f\"Fusion Rationale: {final_state_2.get('fusion_rationale')}\")"]},{"cell_type":"markdown","metadata":{"id":"S0crK8shAjMZ"},"source":["Human review test (haven't adjusted good)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2N70s9iy8mhV","outputId":"ed2e329b-08f5-489b-8fbc-b1d6d217ae28"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Running Simulation 2 (Low-Risk Note) — Phase 1 (until interrupt) ---\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=fetch_data_INPUT\n","--- 1. Fetching data for visit_id: 5 (execution_id: 91a5cd44-2ca1-4640-8687-21ce1cee764c) ---\n","[PERF] fetch_data_node took 5.18ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=fetch_data_OUTPUT duration=9.04ms\n","{'fetch_data': {'execution_id': '91a5cd44-2ca1-4640-8687-21ce1cee764c', 'patient_data': {'visit_id': 5, 'patient_id': 'aa17128506622ee5', 'sex': 'Male', 'age_bucket': '18-34', 'heart_rate': 65.0, 'bp_systolic': 187.0, 'bp_diastolic': 77.0, 'resp_rate': 22.0, 'temperature_C': 39.9, 'oxygen_saturation': 91.0, 'recent_admissions_30d': 0, 'admitted': 0, 'triage_notes_redacted': 'the patient presents with chest pain for 2 hours, rated 7/10. Onset after eating dinner, associated with sharp stabbing pain. Denies recent travel or sick contacts. Past medical history includes COPD; Hypertension. Current medications: none reported. Vital signs on arrival: HR 65 bpm, BP 187/77 mmHg, RR 22 breaths/min, Temp 39.9 °C, O₂ sat 91%. Patient triaged as ESI level 3.', 'ESI': 3}, 'vitals_validated': VitalSigns(sex='Male', age_bucket='18-34', heart_rate=65.0, resp_rate=22.0, bp_systolic=187.0, bp_diastolic=77.0, oxygen_saturation=91.0, temperature_C=39.9, ESI=3, mental_status=None, recent_admissions_30d=0), 'triage_text': 'the patient presents with chest pain for 2 hours, rated 7/10. Onset after eating dinner, associated with sharp stabbing pain. Denies recent travel or sick contacts. Past medical history includes COPD; Hypertension. Current medications: none reported. Vital signs on arrival: HR 65 bpm, BP 187/77 mmHg, RR 22 breaths/min, Temp 39.9 °C, O₂ sat 91%. Patient triaged as ESI level 3.'}}\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=severity_gate_INPUT\n","--- 2. Checking severity gate ---\n"," -> OK: Patient is not severe. Proceeding to models.\n","[PERF] severity_gate_node took 0.01ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=severity_gate_OUTPUT duration=2.16ms\n","[Routing] Non-severe case → proceeding to run_models\n","{'severity_gate': {'severe': False}}\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=run_models_INPUT\n","--- 3. Fanning out to parallel models (human_input, llm_model, ml_model) ---\n","[PERF] run_models_node took 0.01ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=run_models_OUTPUT duration=2.20ms\n","{'run_models': None}\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=human_input_INPUT\n","--- 3c. Acknowledging Human Input ---\n"," -> Human Note: 'Patient looks stable, likely just needs follow-up.'\n","[PERF] human_input_node took 0.01ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=llm_model_INPUT\n","--- 3b. Running LLM Classifier ---\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=ml_model_INPUT\n","--- 3a. Running ML Model ---\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=human_input_OUTPUT duration=3.91ms\n"," -> ML Score (P_Admit): 0.0922\n","[PERF] ml_model_node took 16.04ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=ml_model_OUTPUT duration=22.58ms\n","{'human_input': None}\n","{'ml_model': {'ml_score': 0.09224370121955872}}\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> LLM Classifier Score (P_Admit): 0.9807\n","[PERF] llm_model_node took 187.71ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=llm_model_OUTPUT duration=192.30ms\n","{'llm_model': {'llm_score': 0.9806503653526306}}\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=fusion_INPUT\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"," -> Final P(Admit) Score (numeric): 0.3588 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.7*ML + 0.3*LLM) = 0.359. Decision: Discharge.\n","[PERF] fusion_node took 2943.15ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=fusion_OUTPUT duration=2945.35ms\n","{'fusion': {'fused_prob': 0.35876570045948025, 'p_final': 0.35876570045948025, 'fusion_decision': 'Discharge', 'fusion_rationale': 'Fusion agent unavailable. Using weighted average (0.7*ML + 0.3*LLM) = 0.359. Decision: Discharge.'}}\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=confidence_check_INPUT\n","--- 5. Confidence Check Node ---\n","[ConfidenceCheck] ml_score=0.0922, llm_score=0.9807, fused_prob=0.3588\n","[PERF] confidence_check_node took 0.01ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=confidence_check_OUTPUT duration=2.26ms\n","[Routing] LOW confidence (gap=0.89, avg=0.54) → human_review\n","{'confidence_check': {'visit_id': 5, 'human_prompt': 'Patient looks stable, likely just needs follow-up.', 'patient_data': {'visit_id': 5, 'patient_id': 'aa17128506622ee5', 'sex': 'Male', 'age_bucket': '18-34', 'heart_rate': 65.0, 'bp_systolic': 187.0, 'bp_diastolic': 77.0, 'resp_rate': 22.0, 'temperature_C': 39.9, 'oxygen_saturation': 91.0, 'recent_admissions_30d': 0, 'admitted': 0, 'triage_notes_redacted': 'the patient presents with chest pain for 2 hours, rated 7/10. Onset after eating dinner, associated with sharp stabbing pain. Denies recent travel or sick contacts. Past medical history includes COPD; Hypertension. Current medications: none reported. Vital signs on arrival: HR 65 bpm, BP 187/77 mmHg, RR 22 breaths/min, Temp 39.9 °C, O₂ sat 91%. Patient triaged as ESI level 3.', 'ESI': 3}, 'vitals_validated': VitalSigns(sex='Male', age_bucket='18-34', heart_rate=65.0, resp_rate=22.0, bp_systolic=187.0, bp_diastolic=77.0, oxygen_saturation=91.0, temperature_C=39.9, ESI=3, mental_status=None, recent_admissions_30d=0), 'triage_text': 'the patient presents with chest pain for 2 hours, rated 7/10. Onset after eating dinner, associated with sharp stabbing pain. Denies recent travel or sick contacts. Past medical history includes COPD; Hypertension. Current medications: none reported. Vital signs on arrival: HR 65 bpm, BP 187/77 mmHg, RR 22 breaths/min, Temp 39.9 °C, O₂ sat 91%. Patient triaged as ESI level 3.', 'ml_score': 0.09224370121955872, 'llm_score': 0.9806503653526306, 'severe': False, 'p_final': 0.35876570045948025, 'fused_prob': 0.35876570045948025, 'decision': 'DISCHARGE', 'final_decision': 'DISCHARGE', 'rationale': 'Fused probability 0.36 < threshold 0.50; patient may be safely discharged.', 'fusion_decision': 'Discharge', 'fusion_rationale': 'Fusion agent unavailable. Using weighted average (0.7*ML + 0.3*LLM) = 0.359. Decision: Discharge.', 'execution_id': '91a5cd44-2ca1-4640-8687-21ce1cee764c'}}\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=human_review_INPUT\n","--- 6. Human Review Node (HITL) ---\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=human_review_no_override\n","[HITL] No override provided → using original fused_prob=0.3588\n","[PERF] human_review_node took 1.68ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=human_review_OUTPUT duration=4.03ms\n","{'human_review': {'fused_prob': 0.35876570045948025, 'p_final': 0.35876570045948025}}\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=finalize_INPUT\n","--- 7. Finalize Node ---\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=finalize_node\n","[Finalize] Decision=DISCHARGE, Rationale=Fused probability 0.36 < threshold 0.50; patient may be safely discharged.\n","[PERF] finalize_node took 1.82ms\n","[LOG] execution_id=91a5cd44-2ca1-4640-8687-21ce1cee764c step=finalize_OUTPUT duration=3.85ms\n","{'finalize': {'visit_id': 5, 'human_prompt': 'Patient looks stable, likely just needs follow-up.', 'patient_data': {'visit_id': 5, 'patient_id': 'aa17128506622ee5', 'sex': 'Male', 'age_bucket': '18-34', 'heart_rate': 65.0, 'bp_systolic': 187.0, 'bp_diastolic': 77.0, 'resp_rate': 22.0, 'temperature_C': 39.9, 'oxygen_saturation': 91.0, 'recent_admissions_30d': 0, 'admitted': 0, 'triage_notes_redacted': 'the patient presents with chest pain for 2 hours, rated 7/10. Onset after eating dinner, associated with sharp stabbing pain. Denies recent travel or sick contacts. Past medical history includes COPD; Hypertension. Current medications: none reported. Vital signs on arrival: HR 65 bpm, BP 187/77 mmHg, RR 22 breaths/min, Temp 39.9 °C, O₂ sat 91%. Patient triaged as ESI level 3.', 'ESI': 3}, 'vitals_validated': VitalSigns(sex='Male', age_bucket='18-34', heart_rate=65.0, resp_rate=22.0, bp_systolic=187.0, bp_diastolic=77.0, oxygen_saturation=91.0, temperature_C=39.9, ESI=3, mental_status=None, recent_admissions_30d=0), 'triage_text': 'the patient presents with chest pain for 2 hours, rated 7/10. Onset after eating dinner, associated with sharp stabbing pain. Denies recent travel or sick contacts. Past medical history includes COPD; Hypertension. Current medications: none reported. Vital signs on arrival: HR 65 bpm, BP 187/77 mmHg, RR 22 breaths/min, Temp 39.9 °C, O₂ sat 91%. Patient triaged as ESI level 3.', 'ml_score': 0.09224370121955872, 'llm_score': 0.9806503653526306, 'severe': False, 'p_final': 0.35876570045948025, 'fused_prob': 0.35876570045948025, 'decision': 'DISCHARGE', 'final_decision': 'DISCHARGE', 'rationale': 'Fused probability 0.36 < threshold 0.50; patient may be safely discharged.', 'fusion_decision': 'Discharge', 'fusion_rationale': 'Fusion agent unavailable. Using weighted average (0.7*ML + 0.3*LLM) = 0.359. Decision: Discharge.', 'execution_id': '91a5cd44-2ca1-4640-8687-21ce1cee764c'}}\n","\n","--- State BEFORE Human Review (Simulation 2) ---\n","Keys: dict_keys(['visit_id', 'human_prompt', 'patient_data', 'vitals_validated', 'triage_text', 'ml_score', 'llm_score', 'severe', 'p_final', 'fused_prob', 'decision', 'final_decision', 'rationale', 'fusion_decision', 'fusion_rationale', 'execution_id'])\n","\n","ML score (p_ml):      0.09224370121955872\n","LLM score (p_llm):    0.9806503653526306\n","Fused P(Admit):       0.35876570045948025\n","Fusion Decision:      Discharge\n","Fusion Rationale:     Fusion agent unavailable. Using weighted average (0.7*ML + 0.3*LLM) = 0.359. Decision: Discharge.\n","Original Human Note:  Patient looks stable, likely just needs follow-up.\n"]}],"source":["# ============================================\n","# Simulation 2: Low-Risk Note (HITL demo)\n","# Step 1 — Run until interrupt BEFORE 'human_review'\n","# ============================================\n","\n","inputs_2 = {\n","    \"visit_id\": 5,\n","    \"human_prompt\": \"Patient looks stable, likely just needs follow-up.\"\n","}\n","\n","config_2 = {\"configurable\": {\"thread_id\": \"sim-2\"}}\n","\n","print(\"\\n--- Running Simulation 2 (Low-Risk Note) — Phase 1 (until interrupt) ---\")\n","\n","# 1) Run the graph; it will stop before 'human_review'\n","for event in graph.stream(inputs_2, config_2):\n","    # Each event is a dict like {\"node_name\": {...partial_state_update...}}\n","    print(event)\n","\n","# 2) After the interrupt, fetch the current state from the checkpointer\n","state_before_review = graph.get_state(config_2).values\n","\n","print(\"\\n--- State BEFORE Human Review (Simulation 2) ---\")\n","print(\"Keys:\", state_before_review.keys())\n","\n","# 3) Inspect model / fusion outputs to help the human reviewer\n","print(f\"\\nML score (p_ml):      {state_before_review.get('ml_score')}\")\n","print(f\"LLM score (p_llm):    {state_before_review.get('llm_score')}\")\n","print(f\"Fused P(Admit):       {state_before_review.get('p_final')}\")\n","print(f\"Fusion Decision:      {state_before_review.get('fusion_decision')}\")\n","print(f\"Fusion Rationale:     {state_before_review.get('fusion_rationale')}\")\n","print(f\"Original Human Note:  {state_before_review.get('human_prompt')}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ecdWTC2O8noO","outputId":"05b07edf-5df0-4679-ce06-323e812feb94"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Applying human_override = 0.15 and resuming the graph...\n","\n","\n","--- Final State 2 (AFTER Human Review) ---\n","Decision:          DISCHARGE\n","P(Admit):          0.3588\n","Final Rationale:   Fused probability 0.36 < threshold 0.50; patient may be safely discharged.\n","Fusion Decision:   Discharge\n","Fusion Rationale:  Fusion agent unavailable. Using weighted average (0.7*ML + 0.3*LLM) = 0.359. Decision: Discharge.\n","Human Override:    0.15\n"]}],"source":["# ============================================\n","# Simulation 2: Low-Risk Note (HITL demo)\n","# Step 2 — Apply human_override and resume the graph\n","# ============================================\n","\n","# Example: Human reviewer decides true admission risk is only 0.15\n","# (You can change this value and re-run to see different outcomes.)\n","human_override_value = 0.15\n","\n","print(f\"\\nApplying human_override = {human_override_value:.2f} and resuming the graph...\\n\")\n","\n","# 1) Take previous state and inject human_override\n","updated_values = dict(state_before_review)\n","updated_values[\"human_override\"] = human_override_value\n","\n","# 2) Write back into the graph state\n","graph.update_state(config_2, updated_values)\n","\n","# 3) Resume execution from the interrupt point\n","#    It will now run: human_review -> finalize -> END\n","for event in graph.stream(None, config_2):\n","    print(event)\n","\n","# 4) Fetch the FINAL state after human review and finalize\n","final_state_2 = graph.get_state(config_2).values\n","\n","print(\"\\n--- Final State 2 (AFTER Human Review) ---\")\n","print(f\"Decision:          {final_state_2.get('decision')}\")\n","p2 = final_state_2.get(\"p_final\")\n","print(f\"P(Admit):          {p2:.4f}\" if p2 is not None else \"P(Admit): N/A\")\n","print(f\"Final Rationale:   {final_state_2.get('rationale')}\")\n","print(f\"Fusion Decision:   {final_state_2.get('fusion_decision')}\")\n","print(f\"Fusion Rationale:  {final_state_2.get('fusion_rationale')}\")\n","print(f\"Human Override:    {final_state_2.get('human_override')}\")\n"]},{"cell_type":"markdown","metadata":{"id":"LmQY2UN38iww"},"source":["check"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YmVIcOsUum5B","outputId":"2b145b1f-11b2-458b-ec3c-62a13245cb77"},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["{'decision': 'Admit', 'rationale': \"Given the patient's frailty, age, and being on chemotherapy, the best course of action is to admit the patient to observe for any potential respiratory distress, given the high probability as indicated by both the ML model and LLM classifier, and the clinical context provided by the nurse's note.\"}\n","Decision from fusion agent: Admit\n","Rationale from fusion agent: Given the patient's frailty, age, and being on chemotherapy, the best course of action is to admit the patient to observe for any potential respiratory distress, given the high probability as indicated by both the ML model and LLM classifier, and the clinical context provided by the nurse's note.\n"]}],"source":["test_output = run_fusion_agent(ml_prob=0.81, llm_prob=0.99, human_note=\"70yo, frail, on chemotherapy\")\n","print(test_output)\n","print(\"Decision from fusion agent:\", test_output.get(\"decision\"))\n","print(\"Rationale from fusion agent:\", test_output.get(\"rationale\"))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FPDfZYsftNR6","outputId":"1c9b0bd3-fb5d-4af9-99ee-4d879608c5a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Final State 1 RAW ---\n","{'visit_id': 1, 'human_prompt': 'Patient is 70yo, frail, and on chemotherapy.', 'patient_data': {'visit_id': 1, 'patient_id': '2c63e4a66e75f974', 'sex': 'Male', 'age_bucket': '65+', 'heart_rate': 148.0, 'bp_systolic': 182.0, 'bp_diastolic': 67.0, 'resp_rate': 29.0, 'temperature_C': 37.8, 'oxygen_saturation': 94.0, 'recent_admissions_30d': 0, 'admitted': 1, 'triage_notes_redacted': 'the patient presents with fever for 2 hours, rated 7/10. Onset after a fall, associated with productive cough. Denies recent travel or sick contacts. Past medical history includes no significant history. Current medications: metformin. Vital signs on arrival: HR 148 bpm, BP 182/67 mmHg, RR 29 breaths/min, Temp 37.8 °C, O₂ sat 94%. Patient triaged as ESI level 5.', 'ESI': 5}, 'vitals_validated': VitalSigns(sex='Male', age_bucket='65+', heart_rate=148.0, resp_rate=29.0, bp_systolic=182.0, bp_diastolic=67.0, oxygen_saturation=94.0, temperature_C=37.8, ESI=5, mental_status=None, recent_admissions_30d=0), 'triage_text': 'the patient presents with fever for 2 hours, rated 7/10. Onset after a fall, associated with productive cough. Denies recent travel or sick contacts. Past medical history includes no significant history. Current medications: metformin. Vital signs on arrival: HR 148 bpm, BP 182/67 mmHg, RR 29 breaths/min, Temp 37.8 °C, O₂ sat 94%. Patient triaged as ESI level 5.', 'ml_score': 0.8125269412994385, 'llm_score': 0.9898709654808044, 'severe': False, 'p_final': 0.8657301485538482, 'decision': 'ADMIT', 'rationale': 'Fused probability 0.87 ≥ threshold 0.50; patient should be admitted.'}\n","--- Keys ---\n","dict_keys(['visit_id', 'human_prompt', 'patient_data', 'vitals_validated', 'triage_text', 'ml_score', 'llm_score', 'severe', 'p_final', 'decision', 'rationale'])\n"]}],"source":["print(\"--- Final State 1 RAW ---\")\n","print(final_state_1)\n","print(\"--- Keys ---\")\n","print(final_state_1.keys())\n"]},{"cell_type":"markdown","metadata":{"id":"goybhQz9NqyV"},"source":["## Evaluate the Graph"]},{"cell_type":"markdown","metadata":{"id":"SF7KWaXTNtvh"},"source":["To maintain consistency, we will be using the 4200-row csv dataset that was used to train/test the LLM Classifier and the ML Model. The purpose of the graph workflow above using a database is to simulate a real-world workflow. For evaluation, we will be using a csv format."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UXUhfU4lNsxy"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"56VRBOWrODRw","outputId":"afc6e49b-c559-413c-ae0a-51d287fd20fc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Loaded 4200 rows from /content/drive/MyDrive/Work/Capstone-TeamFolder/Capstone_Organized/1-Data/ED_Model_Training_Dataset.csv.\n"]}],"source":["INPUT_CSV_PATH = os.path.join(BASE_PATH + \"/1-Data/ED_Model_Training_Dataset.csv\")\n","\n","df_full = pd.read_csv(INPUT_CSV_PATH)\n","df_full = df_full.dropna().reset_index(drop=True)\n","print(f\"Loaded {len(df_full)} rows from {INPUT_CSV_PATH}.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nh22rg3KDcpx"},"outputs":[],"source":["# PII MASKING: age\n","\n","def bucket_age(a):\n","    \"\"\"Bins the age column into categorical ranges.\"\"\"\n","    if pd.isna(a): return None\n","    a = int(a)\n","    if a <= 17: return \"0-17\"\n","    if a <= 34: return \"18-34\"\n","    if a <= 49: return \"35-49\"\n","    if a <= 64: return \"50-64\"\n","    return \"65+\"\n","\n","df_full[\"age_bucket\"] = df_full[\"age\"].apply(bucket_age)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6JMtIoLSGbC9","outputId":"0fecebd9-6933-42fd-db7d-071f8d475336"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Original Note:\n","the patient presents with fever for 2 hours, rated 7/10. Onset after a fall, associated with productive cough. Denies recent travel or sick contacts. Past medical history includes no significant history. Current medications: metformin. Vital signs on arrival: HR 148 bpm, BP 182/67 mmHg, RR 29 breaths/min, Temp 37.8 °C, O₂ sat 94%. Patient triaged as ESI level 5.\n"]}],"source":["# PII MASKING: triage_notes\n","\n","EMAIL_RE  = re.compile(r\"\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b\", re.IGNORECASE)\n","PHONE_RE  = re.compile(r\"\\b(?:\\+?1[-.\\s]?)?(?:\\(?\\d{3}\\)?[-.\\s]?)?\\d{3}[-.\\s]?\\d{4}\\b\")\n","SSN_RE    = re.compile(r\"\\b\\d{3}-?\\d{2}-?\\d{4}\\b\")\n","DATE_RE   = re.compile(r\"\\b(?:\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}|\\d{4}-\\d{2}-\\d{2})\\b\")\n","\n","# Normalize unicode dashes to ASCII hyphen\n","DASHES = dict.fromkeys(map(ord, \"\\u2010\\u2011\\u2012\\u2013\\u2014\\u2015\"), \"-\")\n","\n","AGE_PATTERNS = [\n","    re.compile(r\"\\b(\\d{1,3})\\W*(?:year|yrs?|yo|y\\/?o)\\W*(?:old|of\\s+age)?\\b\", re.IGNORECASE), # Catch X-year-old, X y/o, X yrs, etc.\n","    re.compile(r\"\\bage[d]?\\s*(\\d{1,3})\\b\", re.IGNORECASE), # Catch aged X / age X\n","    re.compile(r\"\\b(in\\s+(?:his|her|their|a|the)\\s+)\\d{2}s\\b\", re.IGNORECASE) # Catching decades (in his 40s)\n","]\n","\n","# Gendered words/titles and pronouns\n","GENDER_RE   = re.compile(r\"\\b(male|female|man|woman|boy|girl|gentleman|lady|mr\\.?|mrs\\.?|ms\\.?)\\b\", re.IGNORECASE)\n","PRONOUN_RE  = re.compile(r\"\\b(he|she|him|her|his|hers)\\b\", re.IGNORECASE)\n","_PRONOUN_MAP = {'he':'they','she':'they','him':'them','her':'them','his':'their','hers':'their'}\n","\n","def _neutralize_pronouns(text: str) -> str:\n","    def _sub(m):\n","        src = m.group(1)\n","        repl = _PRONOUN_MAP[src.lower()]\n","        if src.isupper():     return repl.upper()\n","        if src[0].isupper():  return repl.capitalize()\n","        return repl\n","    return PRONOUN_RE.sub(_sub, text)\n","\n","def _remove_age(m):\n","    \"\"\"Removes the entire matched age phrase.\"\"\"\n","    return \"\"\n","\n","def redact_text(s):\n","    \"\"\"Redact PII + demographics; REMOVES all numeric ages.\"\"\"\n","    if pd.isna(s):\n","        return None\n","    t = str(s).translate(DASHES)\n","\n","    # PII\n","    t = EMAIL_RE.sub(\"[EMAIL]\", t)\n","    t = PHONE_RE.sub(\"[PHONE]\", t)\n","    t = SSN_RE.sub(\"[SSN]\", t)\n","    t = DATE_RE.sub(\"[DATE]\", t)\n","\n","    # Ages → REMOVE (using the aggressive patterns above)\n","    for rx in AGE_PATTERNS:\n","        # This replaces the entire matched phrase (e.g., \"67-year-old\") with \"[AGE]\"\n","        t = rx.sub(_remove_age, t)\n","\n","    # Gendered terms and pronouns\n","    t = GENDER_RE.sub(\"the patient\", t)\n","    t = _neutralize_pronouns(t)\n","\n","    return re.sub(r\"\\s+\", \" \", t).strip()\n","\n","df_full[\"triage_notes_redacted\"] = df_full[\"triage_notes\"].apply(redact_text)\n","test_note_redacted = df_full[\"triage_notes_redacted\"].iloc[0]\n","print(\"\\nOriginal Note:\")\n","print(test_note_redacted)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Daf5SDdkTbaB","outputId":"1c4a988e-9902-479d-98f0-8fb07bec8b4d"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 4200 entries, 0 to 4199\n","Data columns (total 12 columns):\n"," #   Column                 Non-Null Count  Dtype  \n","---  ------                 --------------  -----  \n"," 0   sex                    4200 non-null   object \n"," 1   heart_rate             4200 non-null   int64  \n"," 2   bp_systolic            4200 non-null   int64  \n"," 3   bp_diastolic           4200 non-null   int64  \n"," 4   resp_rate              4200 non-null   int64  \n"," 5   temperature_C          4200 non-null   float64\n"," 6   oxygen_saturation      4200 non-null   float64\n"," 7   ESI                    4200 non-null   int64  \n"," 8   recent_admissions_30d  4200 non-null   int64  \n"," 9   admitted               4200 non-null   int64  \n"," 10  age_bucket             4200 non-null   object \n"," 11  triage_notes_redacted  4200 non-null   object \n","dtypes: float64(2), int64(7), object(3)\n","memory usage: 393.9+ KB\n"]}],"source":["df_full = df_full.drop(columns=['triage_notes', 'age'])\n","\n","df_full.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5yhyRXS7OifO"},"outputs":[],"source":["TARGET_COLUMN = 'admitted'\n","y = df_full[TARGET_COLUMN]\n","X = df_full.drop(columns=[TARGET_COLUMN])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MiJuwYx6Ojk5","outputId":"3e59d46a-020a-492d-8d6e-1dd2da4214b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Created evaluation set with 840 patients.\n"]}],"source":["_, X_test, _, y_test = train_test_split(\n","    X, y,\n","    test_size=0.2,\n","    random_state=14,\n","    stratify=y\n",")\n","\n","test_patients = X_test.to_dict('records')\n","true_labels = y_test.tolist()\n","\n","print(f\"Created evaluation set with {len(test_patients)} patients.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Pt1NaYniSTXf","outputId":"8f6f8ac1-780d-4196-9cd4-ca0a30715a1f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Running Head-to-Head evaluation on 840 test patients...\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 0/840 [00:00<?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","  0%|          | 1/840 [00:04<57:11,  4.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4895 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 2/840 [00:04<28:52,  2.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.2826 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 3/840 [00:07<31:53,  2.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1089 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  0%|          | 4/840 [00:09<31:38,  2.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0653 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  1%|          | 5/840 [00:09<21:36,  1.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.3228 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  1%|          | 6/840 [00:12<25:31,  1.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2994 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  1%|          | 7/840 [00:15<30:28,  2.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5597 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  1%|          | 8/840 [00:15<22:05,  1.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.2385 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  1%|          | 9/840 [00:18<26:30,  1.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2391 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  1%|          | 10/840 [00:21<33:56,  2.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5015 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  1%|▏         | 11/840 [00:24<34:09,  2.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1319 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  1%|▏         | 12/840 [00:27<37:27,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5323 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 13/840 [00:30<38:01,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3179 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 14/840 [00:35<46:31,  3.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1759 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 15/840 [00:37<43:54,  3.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0949 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 16/840 [00:41<43:30,  3.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3652 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 17/840 [00:43<41:27,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2228 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 18/840 [00:46<39:43,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4255 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 19/840 [00:47<33:29,  2.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.3782 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  2%|▏         | 20/840 [00:50<34:42,  2.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0456 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  2%|▎         | 21/840 [00:54<42:40,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3871 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 22/840 [00:57<38:36,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1239 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 23/840 [01:00<38:58,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3447 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 24/840 [01:02<37:27,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3528 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 25/840 [01:06<42:42,  3.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2636 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 26/840 [01:10<44:01,  3.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2265 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 27/840 [01:11<36:38,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1839 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 28/840 [01:14<36:14,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2580 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  3%|▎         | 29/840 [01:16<35:10,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3818 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  4%|▎         | 30/840 [01:19<37:23,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3692 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  4%|▎         | 31/840 [01:21<34:59,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3293 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  4%|▍         | 32/840 [01:25<36:59,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2433 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  4%|▍         | 33/840 [01:27<34:41,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4080 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  4%|▍         | 34/840 [01:31<40:12,  2.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3862 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  4%|▍         | 35/840 [01:33<39:05,  2.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1092 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  4%|▍         | 36/840 [01:34<31:28,  2.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1677 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  4%|▍         | 37/840 [01:37<31:11,  2.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1976 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  5%|▍         | 38/840 [01:39<32:41,  2.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4077 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  5%|▍         | 39/840 [01:42<31:19,  2.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2795 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  5%|▍         | 40/840 [01:43<29:04,  2.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2987 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  5%|▍         | 41/840 [01:46<29:58,  2.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6736 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  5%|▌         | 42/840 [01:49<35:25,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2553 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  5%|▌         | 43/840 [01:52<34:54,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3023 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  5%|▌         | 44/840 [01:55<36:37,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3582 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  5%|▌         | 46/840 [01:57<25:11,  1.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2939 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  6%|▌         | 47/840 [01:59<27:31,  2.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.8590 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  6%|▌         | 48/840 [02:02<30:24,  2.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1113 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  6%|▌         | 49/840 [02:05<31:22,  2.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5890 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  6%|▌         | 50/840 [02:09<36:33,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2282 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  6%|▌         | 51/840 [02:11<35:51,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0863 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  6%|▌         | 52/840 [02:14<35:22,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2642 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  6%|▋         | 53/840 [02:16<31:59,  2.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1932 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  6%|▋         | 54/840 [02:19<34:06,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1137 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  7%|▋         | 55/840 [02:21<34:13,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5325 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  7%|▋         | 56/840 [02:24<35:31,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1676 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  7%|▋         | 57/840 [02:26<30:10,  2.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1058 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  7%|▋         | 58/840 [02:30<36:35,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4846 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  7%|▋         | 59/840 [02:33<37:38,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2060 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  7%|▋         | 60/840 [02:35<35:44,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1611 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  7%|▋         | 61/840 [02:39<39:17,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1196 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  7%|▋         | 62/840 [02:43<41:44,  3.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2216 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  8%|▊         | 63/840 [02:46<41:45,  3.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5062 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  8%|▊         | 64/840 [02:48<36:14,  2.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1715 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  8%|▊         | 65/840 [02:50<32:40,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1676 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  8%|▊         | 66/840 [02:53<36:44,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4338 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  8%|▊         | 67/840 [02:53<26:59,  2.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1367 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  8%|▊         | 68/840 [02:55<25:42,  2.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1199 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  8%|▊         | 69/840 [02:57<26:29,  2.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1016 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  8%|▊         | 70/840 [03:00<28:57,  2.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5287 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  8%|▊         | 71/840 [03:02<28:54,  2.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2215 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  9%|▊         | 72/840 [03:05<31:50,  2.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2335 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  9%|▊         | 73/840 [03:08<31:32,  2.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2349 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  9%|▉         | 74/840 [03:10<29:38,  2.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2975 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  9%|▉         | 75/840 [03:13<33:00,  2.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2623 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  9%|▉         | 76/840 [03:16<33:10,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4784 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  9%|▉         | 77/840 [03:18<30:48,  2.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2145 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  9%|▉         | 78/840 [03:21<33:25,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2154 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r  9%|▉         | 79/840 [03:23<32:31,  2.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1732 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 10%|▉         | 80/840 [03:26<34:23,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2636 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 10%|▉         | 81/840 [03:29<33:17,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1452 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 10%|▉         | 82/840 [03:33<40:42,  3.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1583 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 10%|▉         | 83/840 [03:36<37:07,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3846 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 10%|█         | 84/840 [03:38<34:22,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5464 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 10%|█         | 85/840 [03:41<35:22,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3686 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 10%|█         | 86/840 [03:44<35:23,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2498 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 10%|█         | 87/840 [03:44<25:47,  2.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1851 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 10%|█         | 88/840 [03:47<30:59,  2.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2305 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 11%|█         | 89/840 [03:48<23:04,  1.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1983 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 11%|█         | 90/840 [03:50<26:07,  2.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3064 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 11%|█         | 91/840 [03:53<29:40,  2.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4674 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 11%|█         | 92/840 [03:56<31:15,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2666 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 11%|█         | 93/840 [03:59<32:17,  2.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3905 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 11%|█         | 94/840 [04:06<46:35,  3.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1899 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 11%|█▏        | 95/840 [04:09<44:25,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4664 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 11%|█▏        | 96/840 [04:12<43:54,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5732 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 12%|█▏        | 97/840 [04:14<37:51,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6191 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 12%|█▏        | 98/840 [04:16<35:22,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1609 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 12%|█▏        | 99/840 [04:18<31:13,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4512 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 12%|█▏        | 100/840 [04:22<36:07,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1921 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 12%|█▏        | 101/840 [04:27<41:34,  3.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5264 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 12%|█▏        | 102/840 [04:29<37:10,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2315 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 12%|█▏        | 103/840 [04:32<38:46,  3.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5367 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 12%|█▏        | 104/840 [04:34<34:44,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2056 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 12%|█▎        | 105/840 [04:35<25:42,  2.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1782 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 13%|█▎        | 106/840 [04:38<30:24,  2.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4827 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 13%|█▎        | 107/840 [04:40<26:58,  2.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2412 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 13%|█▎        | 108/840 [04:40<19:48,  1.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.2560 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 13%|█▎        | 109/840 [04:42<23:00,  1.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2092 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 13%|█▎        | 110/840 [04:45<25:27,  2.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2704 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 13%|█▎        | 111/840 [04:47<24:34,  2.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1531 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 13%|█▎        | 112/840 [04:50<29:47,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2792 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 13%|█▎        | 113/840 [04:52<28:54,  2.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2065 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 14%|█▎        | 114/840 [04:55<30:49,  2.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4404 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 14%|█▎        | 115/840 [04:58<31:01,  2.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1720 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 14%|█▍        | 116/840 [04:58<23:02,  1.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.0560 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 14%|█▍        | 117/840 [05:02<29:39,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1892 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 14%|█▍        | 118/840 [05:02<21:55,  1.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.3732 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 14%|█▍        | 119/840 [05:05<25:16,  2.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2279 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 14%|█▍        | 120/840 [05:09<29:39,  2.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2029 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 14%|█▍        | 121/840 [05:12<32:09,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1514 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 15%|█▍        | 122/840 [05:14<31:57,  2.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6829 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 15%|█▍        | 123/840 [05:17<31:15,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5354 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 15%|█▍        | 124/840 [05:20<31:50,  2.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6618 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 15%|█▍        | 125/840 [05:24<38:06,  3.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3108 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 15%|█▌        | 126/840 [05:27<37:05,  3.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2689 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 15%|█▌        | 127/840 [05:29<34:06,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1582 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 15%|█▌        | 128/840 [05:32<33:22,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1282 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 15%|█▌        | 129/840 [05:35<33:28,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3134 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 15%|█▌        | 130/840 [05:35<25:17,  2.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.0853 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 16%|█▌        | 131/840 [05:39<31:24,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1105 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 16%|█▌        | 132/840 [05:44<37:49,  3.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3238 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 16%|█▌        | 133/840 [05:48<42:03,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6777 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 16%|█▌        | 134/840 [05:52<43:20,  3.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1648 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 16%|█▌        | 135/840 [05:54<37:27,  3.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2222 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 16%|█▌        | 136/840 [05:56<34:16,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3075 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 16%|█▋        | 137/840 [05:58<28:50,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2803 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 16%|█▋        | 138/840 [06:01<29:44,  2.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1946 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 17%|█▋        | 139/840 [06:01<22:05,  1.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.6905 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 17%|█▋        | 140/840 [06:04<26:52,  2.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1684 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 17%|█▋        | 141/840 [06:07<28:20,  2.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4040 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 17%|█▋        | 142/840 [06:09<28:38,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.6929 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 17%|█▋        | 143/840 [06:12<29:09,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6545 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 17%|█▋        | 144/840 [06:15<31:12,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1061 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 17%|█▋        | 145/840 [06:18<30:52,  2.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3854 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 17%|█▋        | 146/840 [06:22<34:47,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2644 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 18%|█▊        | 147/840 [06:25<34:37,  3.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1549 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 18%|█▊        | 148/840 [06:28<37:12,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2343 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 18%|█▊        | 149/840 [06:33<40:35,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3778 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 18%|█▊        | 150/840 [06:35<38:06,  3.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4904 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 18%|█▊        | 151/840 [06:38<36:35,  3.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1777 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 18%|█▊        | 152/840 [06:41<34:45,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6744 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 18%|█▊        | 153/840 [06:43<31:50,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3628 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 18%|█▊        | 154/840 [06:45<28:26,  2.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2132 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 18%|█▊        | 155/840 [06:48<30:37,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3589 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 19%|█▊        | 156/840 [06:51<32:06,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4520 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 19%|█▊        | 157/840 [06:54<30:53,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1379 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 19%|█▉        | 158/840 [06:56<29:17,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6845 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 19%|█▉        | 159/840 [07:00<33:48,  2.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1122 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 19%|█▉        | 160/840 [07:03<33:42,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1540 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 19%|█▉        | 161/840 [07:05<32:05,  2.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4508 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 19%|█▉        | 162/840 [07:08<30:35,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1438 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 19%|█▉        | 163/840 [07:13<39:19,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1869 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 20%|█▉        | 164/840 [07:15<35:01,  3.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1773 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 20%|█▉        | 165/840 [07:18<34:43,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4803 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 20%|█▉        | 166/840 [07:21<32:04,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1404 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 20%|█▉        | 167/840 [07:23<30:10,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2976 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 20%|██        | 168/840 [07:25<28:47,  2.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0941 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 20%|██        | 169/840 [07:28<28:56,  2.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5197 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 20%|██        | 170/840 [07:32<34:19,  3.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0939 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 20%|██        | 171/840 [07:35<33:50,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1763 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 20%|██        | 172/840 [07:37<31:17,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2952 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 21%|██        | 173/840 [07:41<32:35,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5654 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 21%|██        | 174/840 [07:43<31:37,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3764 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 21%|██        | 175/840 [07:46<30:26,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2345 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 21%|██        | 176/840 [07:51<37:41,  3.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4642 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 21%|██        | 177/840 [07:55<41:11,  3.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2260 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 21%|██        | 178/840 [07:58<38:32,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.7957 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 21%|██▏       | 179/840 [08:01<38:11,  3.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2721 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 21%|██▏       | 180/840 [08:03<33:13,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.3197 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 22%|██▏       | 181/840 [08:06<32:02,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1316 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 22%|██▏       | 182/840 [08:08<30:02,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1525 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 22%|██▏       | 183/840 [08:11<29:02,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3857 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 22%|██▏       | 184/840 [08:15<32:13,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6258 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 22%|██▏       | 185/840 [08:18<33:35,  3.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1493 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 22%|██▏       | 186/840 [08:20<31:41,  2.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1920 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 22%|██▏       | 187/840 [08:24<34:19,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2107 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 22%|██▏       | 188/840 [08:27<33:45,  3.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1785 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 22%|██▎       | 189/840 [08:28<25:20,  2.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1888 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 23%|██▎       | 190/840 [08:30<24:49,  2.29s/it]"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3480 | Agent Decision: Admit\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 23%|██▎       | 191/840 [08:34<30:50,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1842 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 23%|██▎       | 192/840 [08:36<29:27,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2977 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 23%|██▎       | 193/840 [08:39<28:56,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2210 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 23%|██▎       | 194/840 [08:41<26:31,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0644 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 23%|██▎       | 195/840 [08:44<26:42,  2.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0956 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 23%|██▎       | 196/840 [08:47<28:33,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3712 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 23%|██▎       | 197/840 [08:48<23:17,  2.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3821 | Agent Decision: Your final decision\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 24%|██▎       | 198/840 [08:50<24:16,  2.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1791 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 24%|██▎       | 199/840 [08:54<28:28,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2152 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 24%|██▍       | 200/840 [08:56<28:20,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4858 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 24%|██▍       | 201/840 [08:59<28:57,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2525 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 24%|██▍       | 202/840 [09:02<28:03,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1380 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 24%|██▍       | 203/840 [09:04<28:10,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1573 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 24%|██▍       | 204/840 [09:07<28:29,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1396 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 24%|██▍       | 205/840 [09:11<31:21,  2.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2772 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 25%|██▍       | 206/840 [09:13<27:38,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3785 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 25%|██▍       | 207/840 [09:14<24:03,  2.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5249 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 25%|██▍       | 208/840 [09:16<24:31,  2.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1849 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 25%|██▍       | 209/840 [09:20<26:45,  2.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2876 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 25%|██▌       | 210/840 [09:22<26:24,  2.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2399 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 25%|██▌       | 211/840 [09:26<32:26,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1875 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 25%|██▌       | 212/840 [09:28<28:46,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1913 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 25%|██▌       | 213/840 [09:32<31:17,  2.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4738 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 25%|██▌       | 214/840 [09:34<28:57,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0609 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 26%|██▌       | 215/840 [09:36<27:10,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1165 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 26%|██▌       | 216/840 [09:39<26:50,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3785 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 26%|██▌       | 217/840 [09:42<27:59,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4244 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 26%|██▌       | 218/840 [09:46<32:50,  3.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1475 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 26%|██▌       | 219/840 [09:47<24:09,  2.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1478 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 26%|██▌       | 220/840 [09:50<26:34,  2.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5659 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 26%|██▋       | 221/840 [09:53<28:45,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5285 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 26%|██▋       | 222/840 [09:57<31:52,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3893 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 27%|██▋       | 223/840 [10:01<35:34,  3.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3940 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 27%|██▋       | 224/840 [10:05<38:23,  3.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0818 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 27%|██▋       | 225/840 [10:07<32:39,  3.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2732 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 27%|██▋       | 226/840 [10:10<29:42,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5884 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 27%|██▋       | 227/840 [10:12<27:34,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6016 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 27%|██▋       | 228/840 [10:17<34:51,  3.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4238 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 27%|██▋       | 229/840 [10:18<28:02,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0838 | Agent Decision: <Admit or Discharge>\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 27%|██▋       | 230/840 [10:22<30:50,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1689 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 28%|██▊       | 231/840 [10:26<33:39,  3.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2436 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 28%|██▊       | 232/840 [10:29<33:18,  3.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3530 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 28%|██▊       | 233/840 [10:32<32:57,  3.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4574 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 28%|██▊       | 234/840 [10:34<27:20,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.8002 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 28%|██▊       | 235/840 [10:37<29:04,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4528 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 28%|██▊       | 236/840 [10:40<29:14,  2.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3906 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 28%|██▊       | 237/840 [10:43<29:19,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1028 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 28%|██▊       | 238/840 [10:45<27:02,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2265 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 28%|██▊       | 239/840 [10:48<28:23,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4121 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 29%|██▊       | 240/840 [10:51<28:33,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2627 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 29%|██▊       | 241/840 [10:53<26:29,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2081 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 29%|██▉       | 242/840 [10:57<29:01,  2.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1648 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 29%|██▉       | 243/840 [10:59<27:06,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0844 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 29%|██▉       | 244/840 [11:02<28:20,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0486 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 29%|██▉       | 245/840 [11:05<29:30,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0830 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 29%|██▉       | 246/840 [11:09<30:18,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3988 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 29%|██▉       | 247/840 [11:11<28:14,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0880 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 30%|██▉       | 248/840 [11:14<26:56,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3314 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 30%|██▉       | 249/840 [11:16<26:25,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2514 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 30%|██▉       | 250/840 [11:19<25:38,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1009 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 30%|██▉       | 251/840 [11:21<25:21,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2295 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 30%|███       | 252/840 [11:21<18:53,  1.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.4071 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 30%|███       | 253/840 [11:27<29:26,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1594 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 30%|███       | 254/840 [11:31<33:31,  3.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.2659 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 30%|███       | 255/840 [11:34<32:06,  3.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1351 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 30%|███       | 256/840 [11:38<34:09,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1221 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 31%|███       | 257/840 [11:41<32:00,  3.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1453 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 31%|███       | 258/840 [11:44<31:11,  3.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5648 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 31%|███       | 259/840 [11:49<35:07,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0910 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 31%|███       | 260/840 [11:52<35:06,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2114 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 31%|███       | 261/840 [11:54<30:20,  3.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3481 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 31%|███       | 262/840 [11:56<25:47,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1285 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 31%|███▏      | 263/840 [11:59<27:07,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2473 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 31%|███▏      | 264/840 [12:02<26:01,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2090 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 32%|███▏      | 265/840 [12:04<25:08,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2103 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 32%|███▏      | 266/840 [12:07<26:14,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1178 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 32%|███▏      | 267/840 [12:09<25:10,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1221 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 32%|███▏      | 268/840 [12:12<24:32,  2.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2252 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 32%|███▏      | 269/840 [12:14<23:34,  2.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2222 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 32%|███▏      | 270/840 [12:17<25:20,  2.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3547 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 32%|███▏      | 271/840 [12:21<27:03,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2425 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 32%|███▏      | 272/840 [12:23<25:12,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3590 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 32%|███▎      | 273/840 [12:24<21:22,  2.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0681 | Agent Decision: Your final decision goes here.\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 33%|███▎      | 274/840 [12:25<16:59,  1.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2067 | Agent Decision: \n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 33%|███▎      | 275/840 [12:28<21:45,  2.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1514 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 33%|███▎      | 276/840 [12:31<22:00,  2.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2798 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 33%|███▎      | 277/840 [12:35<26:47,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2261 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 33%|███▎      | 278/840 [12:36<22:52,  2.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.2753 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 33%|███▎      | 279/840 [12:40<25:49,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1754 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 33%|███▎      | 280/840 [12:41<20:31,  2.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5001 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 33%|███▎      | 281/840 [12:45<26:28,  2.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2154 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 34%|███▎      | 282/840 [12:50<32:40,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1997 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 34%|███▎      | 283/840 [12:54<32:27,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5534 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 34%|███▍      | 284/840 [12:56<29:14,  3.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5651 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 34%|███▍      | 285/840 [12:56<21:13,  2.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.0833 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 34%|███▍      | 286/840 [13:01<27:25,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1520 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 34%|███▍      | 287/840 [13:04<28:10,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3037 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 34%|███▍      | 288/840 [13:06<24:01,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1785 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 34%|███▍      | 289/840 [13:08<22:41,  2.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1567 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 35%|███▍      | 290/840 [13:10<21:03,  2.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5412 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 35%|███▍      | 291/840 [13:12<22:06,  2.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1066 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 35%|███▍      | 292/840 [13:16<25:40,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2233 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 35%|███▍      | 293/840 [13:22<34:45,  3.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2322 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 35%|███▌      | 294/840 [13:25<30:49,  3.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5683 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 35%|███▌      | 295/840 [13:28<31:56,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3321 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 35%|███▌      | 296/840 [13:33<34:33,  3.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3238 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 35%|███▌      | 297/840 [13:33<25:02,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1481 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 35%|███▌      | 298/840 [13:37<27:21,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3867 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 36%|███▌      | 299/840 [13:40<27:35,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3427 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 36%|███▌      | 300/840 [13:42<25:15,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1554 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 36%|███▌      | 301/840 [13:44<22:50,  2.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2405 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 36%|███▌      | 302/840 [13:47<23:02,  2.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5711 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 36%|███▌      | 303/840 [13:49<22:50,  2.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2146 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 36%|███▌      | 304/840 [13:51<20:20,  2.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2127 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 36%|███▋      | 305/840 [13:55<25:40,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1566 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 36%|███▋      | 306/840 [14:01<33:22,  3.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1420 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 37%|███▋      | 307/840 [14:03<29:00,  3.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1812 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 37%|███▋      | 308/840 [14:03<21:16,  2.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.3802 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 37%|███▋      | 309/840 [14:07<22:54,  2.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6553 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 37%|███▋      | 310/840 [14:09<23:04,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1161 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 37%|███▋      | 311/840 [14:10<17:08,  1.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.2069 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 37%|███▋      | 312/840 [14:14<24:17,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4457 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 37%|███▋      | 313/840 [14:17<24:00,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2356 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 37%|███▋      | 314/840 [14:20<26:12,  2.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.7096 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 38%|███▊      | 315/840 [14:24<27:49,  3.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0685 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 38%|███▊      | 316/840 [14:24<20:18,  2.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.0993 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 38%|███▊      | 317/840 [14:27<21:24,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2575 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 38%|███▊      | 318/840 [14:30<22:25,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3492 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 38%|███▊      | 319/840 [14:32<21:38,  2.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.2007 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 38%|███▊      | 320/840 [14:35<22:40,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6224 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 38%|███▊      | 321/840 [14:39<25:52,  2.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2811 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 38%|███▊      | 322/840 [14:42<26:33,  3.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.9765 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 38%|███▊      | 323/840 [14:45<25:10,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5565 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 39%|███▊      | 324/840 [14:49<27:20,  3.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3188 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 39%|███▊      | 325/840 [14:51<25:18,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0785 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 39%|███▉      | 326/840 [14:54<25:27,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5360 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 39%|███▉      | 327/840 [14:58<27:39,  3.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4642 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 39%|███▉      | 328/840 [15:01<27:21,  3.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3885 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 39%|███▉      | 329/840 [15:05<28:58,  3.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2791 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 39%|███▉      | 330/840 [15:07<25:48,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2319 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 39%|███▉      | 331/840 [15:09<21:36,  2.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.2478 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 40%|███▉      | 332/840 [15:11<20:50,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.7296 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 40%|███▉      | 333/840 [15:13<20:48,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3660 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 40%|███▉      | 334/840 [15:16<20:58,  2.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4005 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 40%|███▉      | 335/840 [15:18<20:41,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2660 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 40%|████      | 336/840 [15:20<18:37,  2.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2769 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 40%|████      | 337/840 [15:23<19:27,  2.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1417 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 40%|████      | 338/840 [15:26<21:49,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4553 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 40%|████      | 339/840 [15:28<21:34,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1130 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 40%|████      | 340/840 [15:32<23:12,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4468 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 41%|████      | 341/840 [15:34<22:30,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3378 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 41%|████      | 342/840 [15:36<19:53,  2.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2691 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 41%|████      | 343/840 [15:39<21:24,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5275 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 41%|████      | 344/840 [15:42<22:55,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4641 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 41%|████      | 345/840 [15:43<17:40,  2.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1523 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 41%|████      | 346/840 [15:47<22:47,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4687 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 41%|████▏     | 347/840 [15:50<24:44,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3314 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 41%|████▏     | 348/840 [15:51<18:06,  2.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.2431 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 42%|████▏     | 349/840 [15:52<16:17,  1.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1247 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 42%|████▏     | 350/840 [15:55<17:14,  2.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2430 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 42%|████▏     | 351/840 [15:57<18:24,  2.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4381 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 42%|████▏     | 352/840 [16:00<18:37,  2.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0621 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 42%|████▏     | 353/840 [16:02<19:56,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.7054 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 42%|████▏     | 354/840 [16:05<19:14,  2.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4017 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 42%|████▏     | 355/840 [16:07<18:16,  2.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2771 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 42%|████▏     | 356/840 [16:10<21:39,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2361 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 42%|████▎     | 357/840 [16:13<21:21,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2657 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 43%|████▎     | 358/840 [16:15<20:37,  2.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1291 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 43%|████▎     | 359/840 [16:18<21:06,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.3921 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 43%|████▎     | 360/840 [16:20<20:06,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2564 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 43%|████▎     | 361/840 [16:23<20:13,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6043 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 43%|████▎     | 363/840 [16:26<16:01,  2.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2343 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 43%|████▎     | 364/840 [16:30<19:31,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4976 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 44%|████▎     | 366/840 [16:33<16:44,  2.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5514 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 44%|████▎     | 367/840 [16:35<17:34,  2.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.4954 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 44%|████▍     | 368/840 [16:39<19:14,  2.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2881 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 44%|████▍     | 369/840 [16:42<21:11,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2892 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 44%|████▍     | 370/840 [16:44<19:39,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1745 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 44%|████▍     | 371/840 [16:46<18:48,  2.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1155 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 44%|████▍     | 372/840 [16:49<18:58,  2.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1521 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 44%|████▍     | 373/840 [16:51<18:54,  2.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1138 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 45%|████▍     | 374/840 [16:55<23:13,  2.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5783 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 45%|████▍     | 375/840 [16:58<23:30,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1742 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 45%|████▍     | 376/840 [17:01<21:32,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1330 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 45%|████▍     | 377/840 [17:03<21:19,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2393 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 45%|████▌     | 378/840 [17:06<21:12,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2547 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 45%|████▌     | 379/840 [17:10<22:39,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2567 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 45%|████▌     | 380/840 [17:13<24:54,  3.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5770 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 45%|████▌     | 381/840 [17:17<25:49,  3.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2373 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 45%|████▌     | 382/840 [17:20<23:31,  3.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1107 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 46%|████▌     | 383/840 [17:22<22:04,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3315 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 46%|████▌     | 384/840 [17:26<24:05,  3.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1469 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 46%|████▌     | 385/840 [17:26<17:37,  2.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1627 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 46%|████▌     | 386/840 [17:30<21:22,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2899 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 46%|████▌     | 388/840 [17:32<15:15,  2.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1132 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 46%|████▋     | 389/840 [17:35<16:10,  2.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0870 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 46%|████▋     | 390/840 [17:38<17:52,  2.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3901 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 47%|████▋     | 391/840 [17:41<20:08,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2918 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 47%|████▋     | 392/840 [17:45<22:40,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4278 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 47%|████▋     | 393/840 [17:49<24:20,  3.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3912 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 47%|████▋     | 394/840 [17:52<22:39,  3.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4524 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 47%|████▋     | 395/840 [17:55<23:14,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3000 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 47%|████▋     | 396/840 [17:58<22:03,  2.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1145 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 47%|████▋     | 397/840 [18:00<21:06,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0567 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 47%|████▋     | 398/840 [18:04<23:10,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4375 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 48%|████▊     | 399/840 [18:06<20:27,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1288 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 48%|████▊     | 400/840 [18:08<19:26,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1016 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 48%|████▊     | 401/840 [18:11<19:10,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2925 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 48%|████▊     | 402/840 [18:13<18:06,  2.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1625 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 48%|████▊     | 403/840 [18:15<17:31,  2.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4738 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 48%|████▊     | 404/840 [18:18<18:15,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4271 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 48%|████▊     | 405/840 [18:20<17:21,  2.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1346 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 48%|████▊     | 406/840 [18:22<16:52,  2.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1741 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 48%|████▊     | 407/840 [18:26<18:45,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2763 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 49%|████▊     | 408/840 [18:28<18:02,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1775 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 49%|████▊     | 409/840 [18:32<20:43,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2099 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 49%|████▉     | 410/840 [18:32<15:15,  2.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.2662 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 49%|████▉     | 411/840 [18:34<15:17,  2.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1715 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 49%|████▉     | 412/840 [18:41<24:26,  3.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3207 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 49%|████▉     | 413/840 [18:41<17:39,  2.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.3270 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 49%|████▉     | 414/840 [18:42<14:04,  1.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2452 | Agent Decision: \n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 49%|████▉     | 415/840 [18:44<15:06,  2.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3656 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 50%|████▉     | 416/840 [18:47<16:47,  2.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4404 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 50%|████▉     | 417/840 [18:50<18:42,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1859 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 50%|████▉     | 418/840 [18:53<19:20,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2026 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 50%|████▉     | 419/840 [18:58<22:43,  3.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2383 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 50%|█████     | 420/840 [19:01<21:39,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2819 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 50%|█████     | 421/840 [19:03<21:09,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0754 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 50%|█████     | 422/840 [19:06<20:41,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1801 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 50%|█████     | 423/840 [19:09<20:52,  3.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5738 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 50%|█████     | 424/840 [19:13<21:13,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4993 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 51%|█████     | 425/840 [19:16<21:09,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4290 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 51%|█████     | 426/840 [19:18<19:19,  2.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1018 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 51%|█████     | 427/840 [19:21<20:09,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4951 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 51%|█████     | 428/840 [19:23<19:12,  2.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1448 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 51%|█████     | 429/840 [19:27<19:48,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1808 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 51%|█████     | 430/840 [19:29<19:38,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2064 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 51%|█████▏    | 431/840 [19:34<22:30,  3.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2940 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 51%|█████▏    | 432/840 [19:37<21:42,  3.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4621 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 52%|█████▏    | 433/840 [19:39<20:39,  3.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2782 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 52%|█████▏    | 434/840 [19:43<22:08,  3.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3145 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 52%|█████▏    | 435/840 [19:47<23:54,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2415 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 52%|█████▏    | 436/840 [19:51<23:27,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1972 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 52%|█████▏    | 437/840 [19:53<21:13,  3.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1016 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 52%|█████▏    | 438/840 [19:57<23:09,  3.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1301 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 52%|█████▏    | 439/840 [19:58<16:54,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.2402 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 52%|█████▏    | 440/840 [20:01<18:10,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3211 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 52%|█████▎    | 441/840 [20:03<16:59,  2.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3211 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 53%|█████▎    | 442/840 [20:06<17:59,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6435 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 53%|█████▎    | 443/840 [20:08<16:55,  2.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3815 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 53%|█████▎    | 444/840 [20:10<16:18,  2.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2896 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 53%|█████▎    | 445/840 [20:13<16:52,  2.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6134 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 53%|█████▎    | 446/840 [20:16<17:54,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0892 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 53%|█████▎    | 447/840 [20:19<18:25,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2630 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 53%|█████▎    | 448/840 [20:23<19:38,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.4518 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 53%|█████▎    | 449/840 [20:26<19:12,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2836 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 54%|█████▎    | 450/840 [20:28<18:40,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0925 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 54%|█████▎    | 451/840 [20:31<18:39,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3079 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 54%|█████▍    | 452/840 [20:34<18:29,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3970 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 54%|█████▍    | 453/840 [20:37<18:24,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.7099 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 54%|█████▍    | 454/840 [20:40<17:58,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4271 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 54%|█████▍    | 455/840 [20:43<18:22,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4421 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 54%|█████▍    | 456/840 [20:45<17:37,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2062 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 54%|█████▍    | 457/840 [20:47<16:46,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2445 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 55%|█████▍    | 458/840 [20:50<15:52,  2.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4813 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 55%|█████▍    | 459/840 [20:51<14:12,  2.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6265 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 55%|█████▍    | 460/840 [20:54<14:35,  2.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2466 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 55%|█████▍    | 461/840 [20:57<15:32,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1577 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 55%|█████▌    | 462/840 [21:00<16:53,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2025 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 55%|█████▌    | 463/840 [21:04<19:34,  3.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0856 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 55%|█████▌    | 464/840 [21:04<14:11,  2.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.2934 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 55%|█████▌    | 465/840 [21:08<16:43,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3338 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 55%|█████▌    | 466/840 [21:10<15:45,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0661 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 56%|█████▌    | 467/840 [21:13<16:49,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1662 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 56%|█████▌    | 468/840 [21:18<20:47,  3.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3368 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 56%|█████▌    | 469/840 [21:24<25:01,  4.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3608 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 56%|█████▌    | 470/840 [21:27<24:29,  3.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1915 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 56%|█████▌    | 471/840 [21:31<23:34,  3.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4217 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 56%|█████▌    | 472/840 [21:33<20:39,  3.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4423 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 56%|█████▋    | 473/840 [21:35<17:18,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4785 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 56%|█████▋    | 474/840 [21:37<16:11,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2914 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 57%|█████▋    | 475/840 [21:41<18:15,  3.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4079 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 57%|█████▋    | 476/840 [21:44<19:07,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3984 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 57%|█████▋    | 477/840 [21:47<18:42,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0854 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 57%|█████▋    | 478/840 [21:51<19:39,  3.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1976 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 57%|█████▋    | 479/840 [21:54<18:40,  3.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1334 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 57%|█████▋    | 480/840 [21:57<18:15,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1948 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 57%|█████▋    | 481/840 [22:00<18:36,  3.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3243 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 57%|█████▋    | 482/840 [22:02<16:28,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1755 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 57%|█████▊    | 483/840 [22:04<15:57,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.3817 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 58%|█████▊    | 484/840 [22:05<12:21,  2.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.2074 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 58%|█████▊    | 485/840 [22:10<17:04,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1684 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 58%|█████▊    | 486/840 [22:13<17:11,  2.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2343 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 58%|█████▊    | 487/840 [22:15<16:36,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3322 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 58%|█████▊    | 488/840 [22:18<16:38,  2.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4936 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 58%|█████▊    | 489/840 [22:21<16:31,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1917 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 58%|█████▊    | 490/840 [22:24<16:06,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3797 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 58%|█████▊    | 491/840 [22:26<15:10,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3399 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 59%|█████▊    | 492/840 [22:28<14:57,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3725 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 59%|█████▊    | 493/840 [22:31<14:59,  2.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0895 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 59%|█████▉    | 494/840 [22:33<14:08,  2.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1050 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 59%|█████▉    | 495/840 [22:36<15:15,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2616 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 59%|█████▉    | 496/840 [22:40<16:35,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3947 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 59%|█████▉    | 497/840 [22:42<15:34,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0787 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 59%|█████▉    | 498/840 [22:45<15:48,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6500 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 59%|█████▉    | 499/840 [22:48<16:27,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.7856 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 60%|█████▉    | 500/840 [22:53<19:03,  3.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2525 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 60%|█████▉    | 501/840 [22:55<16:57,  3.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0149 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 60%|█████▉    | 502/840 [22:57<15:44,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1553 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 60%|█████▉    | 503/840 [22:59<14:35,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2751 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 60%|██████    | 504/840 [23:02<14:12,  2.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0541 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 60%|██████    | 505/840 [23:04<14:23,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4887 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 60%|██████    | 506/840 [23:07<13:58,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0520 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 60%|██████    | 507/840 [23:10<15:11,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5007 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 60%|██████    | 508/840 [23:12<14:45,  2.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2024 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 61%|██████    | 509/840 [23:15<14:23,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5228 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 61%|██████    | 510/840 [23:18<14:41,  2.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3558 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 61%|██████    | 511/840 [23:20<14:49,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4181 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 61%|██████    | 512/840 [23:23<15:00,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1969 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 61%|██████    | 513/840 [23:25<13:24,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1225 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 61%|██████    | 514/840 [23:28<14:24,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3351 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 61%|██████▏   | 515/840 [23:30<12:16,  2.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5853 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 61%|██████▏   | 516/840 [23:32<12:37,  2.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5995 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 62%|██████▏   | 517/840 [23:35<13:09,  2.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3000 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 62%|██████▏   | 518/840 [23:35<09:48,  1.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.2697 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 62%|██████▏   | 519/840 [23:37<10:07,  1.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6053 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 62%|██████▏   | 520/840 [23:40<11:32,  2.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2371 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 62%|██████▏   | 521/840 [23:42<10:53,  2.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5802 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 62%|██████▏   | 522/840 [23:44<11:44,  2.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2999 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 62%|██████▏   | 523/840 [23:48<14:35,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0866 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 62%|██████▏   | 524/840 [23:51<14:55,  2.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3413 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 62%|██████▎   | 525/840 [23:56<17:11,  3.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1222 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 63%|██████▎   | 527/840 [23:58<11:32,  2.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5598 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 63%|██████▎   | 528/840 [24:01<13:05,  2.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2840 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 63%|██████▎   | 529/840 [24:03<12:53,  2.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2261 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 63%|██████▎   | 530/840 [24:04<10:08,  1.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.2219 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 63%|██████▎   | 531/840 [24:07<11:47,  2.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2362 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 63%|██████▎   | 532/840 [24:10<12:57,  2.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1361 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 63%|██████▎   | 533/840 [24:11<09:44,  1.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.2229 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 64%|██████▎   | 534/840 [24:13<10:45,  2.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2086 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 64%|██████▎   | 535/840 [24:16<11:07,  2.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3462 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 64%|██████▍   | 536/840 [24:19<12:30,  2.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5263 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 64%|██████▍   | 537/840 [24:21<12:22,  2.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1132 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 64%|██████▍   | 538/840 [24:24<12:16,  2.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1206 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 64%|██████▍   | 539/840 [24:27<13:36,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1177 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 64%|██████▍   | 540/840 [24:29<11:59,  2.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2628 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 64%|██████▍   | 541/840 [24:30<10:45,  2.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2772 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 65%|██████▍   | 542/840 [24:30<07:53,  1.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.2442 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 65%|██████▍   | 544/840 [24:33<07:31,  1.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4004 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 65%|██████▍   | 545/840 [24:36<09:14,  1.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2241 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 65%|██████▌   | 546/840 [24:42<14:07,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2574 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 65%|██████▌   | 547/840 [24:45<14:00,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0879 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 65%|██████▌   | 548/840 [24:48<14:47,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0871 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 65%|██████▌   | 549/840 [24:49<11:31,  2.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3571 | Agent Decision: \n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 65%|██████▌   | 550/840 [24:52<11:46,  2.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3599 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 66%|██████▌   | 551/840 [24:57<15:22,  3.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4876 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 66%|██████▌   | 552/840 [24:59<14:22,  3.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2496 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 66%|██████▌   | 553/840 [25:03<15:28,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3070 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 66%|██████▌   | 554/840 [25:03<11:18,  2.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.2167 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 66%|██████▌   | 555/840 [25:05<10:48,  2.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2185 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 66%|██████▌   | 556/840 [25:09<13:14,  2.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1274 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 66%|██████▋   | 557/840 [25:13<14:54,  3.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2635 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 66%|██████▋   | 558/840 [25:16<14:35,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3035 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 67%|██████▋   | 559/840 [25:19<14:04,  3.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2382 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 67%|██████▋   | 560/840 [25:23<15:45,  3.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1077 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 67%|██████▋   | 561/840 [25:24<11:24,  2.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1524 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 67%|██████▋   | 562/840 [25:28<13:58,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2092 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 67%|██████▋   | 563/840 [25:30<12:44,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1780 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 67%|██████▋   | 564/840 [25:32<12:04,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0702 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 67%|██████▋   | 565/840 [25:35<12:18,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2201 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 67%|██████▋   | 566/840 [25:38<11:53,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3138 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 68%|██████▊   | 567/840 [25:40<11:25,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.8610 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 68%|██████▊   | 568/840 [25:40<08:20,  1.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.2408 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 68%|██████▊   | 569/840 [25:43<08:55,  1.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0567 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 68%|██████▊   | 570/840 [25:45<09:31,  2.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2207 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 68%|██████▊   | 571/840 [25:48<10:58,  2.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1848 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 68%|██████▊   | 572/840 [25:51<10:47,  2.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1487 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 68%|██████▊   | 573/840 [25:53<10:57,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3281 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 68%|██████▊   | 574/840 [25:56<11:04,  2.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1887 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 68%|██████▊   | 575/840 [25:58<10:14,  2.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2882 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 69%|██████▊   | 576/840 [26:00<10:02,  2.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5284 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 69%|██████▊   | 577/840 [26:02<10:20,  2.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2892 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 69%|██████▉   | 578/840 [26:06<11:41,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2119 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 69%|██████▉   | 579/840 [26:08<10:28,  2.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2378 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 69%|██████▉   | 580/840 [26:11<11:50,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1294 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 69%|██████▉   | 581/840 [26:14<11:43,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2911 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 69%|██████▉   | 582/840 [26:17<12:48,  2.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2055 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 69%|██████▉   | 583/840 [26:20<12:40,  2.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0427 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 70%|██████▉   | 584/840 [26:22<10:38,  2.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1878 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 70%|██████▉   | 585/840 [26:25<11:27,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1417 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 70%|██████▉   | 586/840 [26:27<10:23,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2868 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 70%|██████▉   | 587/840 [26:28<09:12,  2.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0764 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 70%|███████   | 588/840 [26:31<10:24,  2.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3512 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 70%|███████   | 589/840 [26:34<10:30,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2729 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 70%|███████   | 590/840 [26:39<12:59,  3.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2855 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 70%|███████   | 591/840 [26:41<12:25,  3.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1157 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 70%|███████   | 592/840 [26:44<11:39,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2078 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 71%|███████   | 593/840 [26:47<11:44,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.4371 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 71%|███████   | 594/840 [26:51<13:55,  3.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5677 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 71%|███████   | 595/840 [26:52<10:31,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1330 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 71%|███████   | 596/840 [26:57<13:16,  3.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2338 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 71%|███████   | 597/840 [26:59<12:21,  3.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1019 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 71%|███████   | 598/840 [27:03<12:55,  3.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3111 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 71%|███████▏  | 599/840 [27:07<14:11,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2070 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 71%|███████▏  | 600/840 [27:10<13:03,  3.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0954 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 72%|███████▏  | 601/840 [27:13<12:42,  3.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1480 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 72%|███████▏  | 602/840 [27:15<11:27,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.8152 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 72%|███████▏  | 603/840 [27:17<10:00,  2.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.6927 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 72%|███████▏  | 604/840 [27:17<07:20,  1.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1446 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 72%|███████▏  | 605/840 [27:19<07:42,  1.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5922 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 72%|███████▏  | 606/840 [27:23<09:20,  2.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0955 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 72%|███████▏  | 607/840 [27:26<10:05,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2180 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 72%|███████▏  | 608/840 [27:29<11:13,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2018 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 72%|███████▎  | 609/840 [27:32<10:22,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2588 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 73%|███████▎  | 610/840 [27:36<12:34,  3.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0838 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 73%|███████▎  | 611/840 [27:38<11:22,  2.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2278 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 73%|███████▎  | 612/840 [27:41<10:21,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6205 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 73%|███████▎  | 614/840 [27:43<07:24,  1.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0710 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 73%|███████▎  | 615/840 [27:44<06:35,  1.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0812 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 73%|███████▎  | 616/840 [27:47<07:30,  2.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4296 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 73%|███████▎  | 617/840 [27:49<07:28,  2.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6628 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 74%|███████▎  | 618/840 [27:52<08:28,  2.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2608 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 74%|███████▎  | 619/840 [27:54<08:59,  2.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5195 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 74%|███████▍  | 620/840 [28:00<11:52,  3.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5585 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 74%|███████▍  | 621/840 [28:03<11:56,  3.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3169 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 74%|███████▍  | 622/840 [28:06<11:14,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1759 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 74%|███████▍  | 623/840 [28:07<09:32,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.2575 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 74%|███████▍  | 624/840 [28:11<11:08,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0645 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 74%|███████▍  | 625/840 [28:16<12:30,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2914 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 75%|███████▍  | 626/840 [28:18<10:31,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2008 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 75%|███████▍  | 627/840 [28:23<12:49,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2220 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 75%|███████▍  | 628/840 [28:25<10:51,  3.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.2741 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 75%|███████▍  | 629/840 [28:27<10:40,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4168 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 75%|███████▌  | 630/840 [28:32<11:49,  3.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3318 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 75%|███████▌  | 631/840 [28:34<10:45,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4853 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 75%|███████▌  | 632/840 [28:37<10:43,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2033 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 75%|███████▌  | 633/840 [28:40<10:10,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1135 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 75%|███████▌  | 634/840 [28:43<10:33,  3.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3782 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 76%|███████▌  | 635/840 [28:46<09:59,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1326 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 76%|███████▌  | 636/840 [28:48<09:18,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3721 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 76%|███████▌  | 637/840 [28:52<10:12,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6296 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 76%|███████▌  | 638/840 [28:54<09:43,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0957 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 76%|███████▌  | 639/840 [28:59<11:40,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4663 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 76%|███████▌  | 640/840 [29:01<10:15,  3.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2270 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 76%|███████▋  | 641/840 [29:04<09:58,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1837 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 76%|███████▋  | 642/840 [29:07<09:30,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4993 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 77%|███████▋  | 644/840 [29:09<06:38,  2.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3033 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 77%|███████▋  | 645/840 [29:12<07:16,  2.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2613 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 77%|███████▋  | 646/840 [29:15<08:10,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1631 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 77%|███████▋  | 647/840 [29:17<07:50,  2.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2431 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 77%|███████▋  | 648/840 [29:20<08:13,  2.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3961 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 77%|███████▋  | 649/840 [29:22<07:30,  2.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0857 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 77%|███████▋  | 650/840 [29:25<07:54,  2.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2393 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 78%|███████▊  | 651/840 [29:28<08:09,  2.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5996 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 78%|███████▊  | 652/840 [29:28<05:59,  1.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1935 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 78%|███████▊  | 653/840 [29:28<04:33,  1.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.3051 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 78%|███████▊  | 654/840 [29:31<05:59,  1.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3038 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 78%|███████▊  | 655/840 [29:35<07:12,  2.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1938 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 78%|███████▊  | 656/840 [29:38<07:44,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3544 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 78%|███████▊  | 657/840 [29:41<08:59,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2331 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 78%|███████▊  | 658/840 [29:45<09:35,  3.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2626 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 78%|███████▊  | 659/840 [29:48<09:18,  3.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4553 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 79%|███████▊  | 660/840 [29:50<08:34,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2737 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 79%|███████▊  | 661/840 [29:53<08:34,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1425 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 79%|███████▉  | 662/840 [29:58<10:15,  3.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2176 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 79%|███████▉  | 663/840 [30:02<10:15,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3477 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 79%|███████▉  | 664/840 [30:04<09:05,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4564 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 79%|███████▉  | 665/840 [30:07<09:01,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2248 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 79%|███████▉  | 666/840 [30:10<08:47,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6323 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 79%|███████▉  | 667/840 [30:12<07:51,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.7938 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 80%|███████▉  | 668/840 [30:16<08:57,  3.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1958 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 80%|███████▉  | 669/840 [30:18<07:48,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2186 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 80%|███████▉  | 670/840 [30:20<07:22,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1806 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 80%|███████▉  | 671/840 [30:23<07:23,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3846 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 80%|████████  | 672/840 [30:26<07:31,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1971 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 80%|████████  | 673/840 [30:30<09:21,  3.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2126 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 80%|████████  | 674/840 [30:34<09:05,  3.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0899 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 80%|████████  | 675/840 [30:37<09:15,  3.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2591 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 80%|████████  | 676/840 [30:39<07:44,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3606 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 81%|████████  | 677/840 [30:41<07:14,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3180 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 81%|████████  | 678/840 [30:44<07:24,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1690 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 81%|████████  | 679/840 [30:46<06:36,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4165 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 81%|████████  | 680/840 [30:48<06:19,  2.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6388 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 81%|████████  | 681/840 [30:52<07:21,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2574 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 81%|████████  | 682/840 [30:54<07:04,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2304 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 81%|████████▏ | 683/840 [30:56<06:47,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5000 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 81%|████████▏ | 684/840 [30:59<06:22,  2.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3179 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 82%|████████▏ | 685/840 [31:01<06:30,  2.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2631 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 82%|████████▏ | 686/840 [31:04<06:35,  2.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1829 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 82%|████████▏ | 687/840 [31:07<06:37,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3624 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 82%|████████▏ | 688/840 [31:10<07:32,  2.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1539 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 82%|████████▏ | 689/840 [31:13<07:26,  2.95s/it]"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2216 | Agent Decision: Discharge\n"]},{"name":"stderr","output_type":"stream","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":["--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 82%|████████▏ | 690/840 [31:14<05:44,  2.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1323 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 82%|████████▏ | 691/840 [31:16<05:26,  2.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5453 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 82%|████████▏ | 692/840 [31:19<05:43,  2.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2258 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 82%|████████▎ | 693/840 [31:21<05:36,  2.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1398 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 83%|████████▎ | 694/840 [31:25<07:07,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0858 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 83%|████████▎ | 695/840 [31:27<06:28,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2782 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 83%|████████▎ | 696/840 [31:30<06:32,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3938 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 83%|████████▎ | 697/840 [31:33<06:33,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4791 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 83%|████████▎ | 698/840 [31:35<06:03,  2.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2011 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 83%|████████▎ | 699/840 [31:37<05:46,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3428 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 83%|████████▎ | 700/840 [31:40<05:52,  2.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3245 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 83%|████████▎ | 701/840 [31:43<06:22,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1908 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 84%|████████▎ | 702/840 [31:47<07:00,  3.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2118 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 84%|████████▎ | 703/840 [31:49<06:11,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3633 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 84%|████████▍ | 704/840 [31:52<05:58,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2477 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 84%|████████▍ | 705/840 [31:54<05:41,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3467 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 84%|████████▍ | 706/840 [31:56<05:36,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0751 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 84%|████████▍ | 707/840 [31:57<04:09,  1.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.4568 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 84%|████████▍ | 708/840 [31:59<04:28,  2.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1513 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 84%|████████▍ | 709/840 [32:01<04:40,  2.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2669 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 85%|████████▍ | 710/840 [32:05<05:32,  2.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1976 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 85%|████████▍ | 711/840 [32:05<04:03,  1.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.7973 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 85%|████████▍ | 712/840 [32:09<04:59,  2.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3540 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 85%|████████▍ | 713/840 [32:11<04:55,  2.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1000 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 85%|████████▌ | 714/840 [32:13<04:56,  2.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6025 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 85%|████████▌ | 715/840 [32:16<05:18,  2.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2205 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 85%|████████▌ | 716/840 [32:19<05:15,  2.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2229 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 85%|████████▌ | 717/840 [32:22<05:24,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1893 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 85%|████████▌ | 718/840 [32:25<05:24,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1604 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 86%|████████▌ | 719/840 [32:28<05:48,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3417 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 86%|████████▌ | 720/840 [32:31<05:57,  2.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.7392 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 86%|████████▌ | 721/840 [32:34<06:04,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3376 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 86%|████████▌ | 722/840 [32:38<06:04,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6105 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 86%|████████▌ | 723/840 [32:40<05:34,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1689 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 86%|████████▌ | 724/840 [32:43<05:36,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1041 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 86%|████████▋ | 725/840 [32:45<05:20,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1486 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 86%|████████▋ | 726/840 [32:49<05:38,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1529 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 87%|████████▋ | 727/840 [32:51<05:24,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2742 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 87%|████████▋ | 728/840 [32:55<05:52,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1309 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 87%|████████▋ | 729/840 [32:57<05:18,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5961 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 87%|████████▋ | 730/840 [33:00<05:14,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3341 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 87%|████████▋ | 731/840 [33:04<05:35,  3.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2406 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 87%|████████▋ | 732/840 [33:06<05:14,  2.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2133 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 87%|████████▋ | 733/840 [33:09<05:08,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1493 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 87%|████████▋ | 734/840 [33:13<05:47,  3.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1414 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 88%|████████▊ | 736/840 [33:17<04:19,  2.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2991 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 88%|████████▊ | 737/840 [33:20<04:43,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2593 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 88%|████████▊ | 738/840 [33:24<05:08,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1680 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 88%|████████▊ | 739/840 [33:26<04:52,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1823 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 88%|████████▊ | 740/840 [33:29<04:42,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1249 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 88%|████████▊ | 741/840 [33:32<04:53,  2.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6576 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 88%|████████▊ | 742/840 [33:35<04:35,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5109 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 88%|████████▊ | 743/840 [33:37<04:24,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3013 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 89%|████████▊ | 744/840 [33:40<04:14,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0895 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 89%|████████▊ | 745/840 [33:40<03:06,  1.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.3659 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 89%|████████▉ | 746/840 [33:43<03:36,  2.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2872 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 89%|████████▉ | 747/840 [33:45<03:27,  2.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.5553 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 89%|████████▉ | 748/840 [33:49<04:07,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2974 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 89%|████████▉ | 749/840 [33:53<04:39,  3.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2745 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 89%|████████▉ | 750/840 [33:55<04:16,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2145 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 89%|████████▉ | 751/840 [33:59<04:32,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.7015 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 90%|████████▉ | 752/840 [34:01<04:12,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2157 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 90%|████████▉ | 753/840 [34:04<03:51,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4084 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 90%|████████▉ | 754/840 [34:07<04:01,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3921 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 90%|████████▉ | 755/840 [34:09<03:51,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1484 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 90%|█████████ | 756/840 [34:13<04:14,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4956 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 90%|█████████ | 757/840 [34:16<04:20,  3.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2065 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 90%|█████████ | 758/840 [34:19<03:59,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1556 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 90%|█████████ | 759/840 [34:21<03:37,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0751 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 90%|█████████ | 760/840 [34:26<04:21,  3.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2929 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 91%|█████████ | 761/840 [34:29<04:24,  3.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3094 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 91%|█████████ | 762/840 [34:32<04:19,  3.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6002 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 91%|█████████ | 763/840 [34:37<04:37,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1140 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 91%|█████████ | 764/840 [34:41<04:40,  3.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4244 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 91%|█████████ | 765/840 [34:44<04:30,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1864 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 91%|█████████ | 766/840 [34:47<04:17,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3790 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 91%|█████████▏| 767/840 [34:50<04:09,  3.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2137 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 91%|█████████▏| 768/840 [34:52<03:37,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1879 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 92%|█████████▏| 769/840 [34:55<03:29,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6163 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 92%|█████████▏| 770/840 [34:58<03:16,  2.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1736 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 92%|█████████▏| 771/840 [35:02<03:54,  3.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.2426 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 92%|█████████▏| 772/840 [35:05<03:38,  3.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0900 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 92%|█████████▏| 773/840 [35:10<04:08,  3.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1893 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 92%|█████████▏| 774/840 [35:13<03:41,  3.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1213 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 92%|█████████▏| 775/840 [35:16<03:29,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2059 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 92%|█████████▏| 776/840 [35:18<03:13,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4790 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 92%|█████████▎| 777/840 [35:21<03:04,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2959 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 93%|█████████▎| 778/840 [35:23<02:40,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2491 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 93%|█████████▎| 779/840 [35:25<02:39,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0871 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 93%|█████████▎| 780/840 [35:27<02:26,  2.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3710 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 93%|█████████▎| 781/840 [35:32<02:59,  3.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2026 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 93%|█████████▎| 782/840 [35:34<02:48,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1326 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 93%|█████████▎| 783/840 [35:36<02:28,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4602 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 93%|█████████▎| 784/840 [35:40<02:44,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1163 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 93%|█████████▎| 785/840 [35:42<02:25,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2753 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 94%|█████████▎| 786/840 [35:45<02:26,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1654 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 94%|█████████▎| 787/840 [35:47<02:17,  2.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1554 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 94%|█████████▍| 788/840 [35:50<02:13,  2.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1690 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 94%|█████████▍| 789/840 [35:52<02:09,  2.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2217 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 94%|█████████▍| 790/840 [35:55<02:10,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1519 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 94%|█████████▍| 791/840 [35:59<02:32,  3.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3223 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 94%|█████████▍| 792/840 [36:02<02:20,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2748 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 94%|█████████▍| 793/840 [36:02<01:45,  2.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.3378 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 95%|█████████▍| 794/840 [36:04<01:41,  2.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2330 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 95%|█████████▍| 795/840 [36:08<01:51,  2.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2301 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 95%|█████████▍| 796/840 [36:10<01:54,  2.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2509 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 95%|█████████▍| 797/840 [36:13<01:47,  2.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0633 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 95%|█████████▌| 798/840 [36:16<01:54,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2723 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 95%|█████████▌| 799/840 [36:18<01:46,  2.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2508 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 95%|█████████▌| 800/840 [36:19<01:17,  1.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1895 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 95%|█████████▌| 801/840 [36:19<00:56,  1.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.3293 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 95%|█████████▌| 802/840 [36:22<01:07,  1.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1241 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 96%|█████████▌| 803/840 [36:24<01:16,  2.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.6470 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 96%|█████████▌| 804/840 [36:28<01:27,  2.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2368 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 96%|█████████▌| 805/840 [36:28<01:07,  1.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1953 | Agent Decision: \n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 96%|█████████▌| 806/840 [36:31<01:11,  2.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.0433 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 96%|█████████▌| 807/840 [36:31<00:52,  1.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.4045 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 96%|█████████▌| 808/840 [36:35<01:10,  2.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1583 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 96%|█████████▋| 809/840 [36:38<01:15,  2.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1463 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 96%|█████████▋| 810/840 [36:38<00:56,  1.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1875 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 97%|█████████▋| 811/840 [36:41<01:00,  2.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0186 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 97%|█████████▋| 812/840 [36:43<01:00,  2.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4092 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 97%|█████████▋| 813/840 [36:46<01:00,  2.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2901 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 97%|█████████▋| 814/840 [36:50<01:13,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1423 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 97%|█████████▋| 815/840 [36:52<01:07,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.5372 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 97%|█████████▋| 816/840 [36:55<01:07,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4990 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 97%|█████████▋| 817/840 [36:58<01:04,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4454 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 97%|█████████▋| 818/840 [37:02<01:10,  3.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3358 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 98%|█████████▊| 819/840 [37:07<01:14,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1090 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 98%|█████████▊| 820/840 [37:10<01:11,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1145 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 98%|█████████▊| 821/840 [37:13<01:04,  3.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2825 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 98%|█████████▊| 822/840 [37:16<00:55,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.3186 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 98%|█████████▊| 823/840 [37:19<00:51,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1387 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 98%|█████████▊| 824/840 [37:21<00:43,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1283 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 98%|█████████▊| 825/840 [37:23<00:41,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2130 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 98%|█████████▊| 826/840 [37:27<00:41,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1902 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 98%|█████████▊| 827/840 [37:30<00:37,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2334 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 99%|█████████▊| 828/840 [37:32<00:31,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1753 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 99%|█████████▊| 829/840 [37:35<00:30,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2504 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 99%|█████████▉| 830/840 [37:37<00:27,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2310 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 99%|█████████▉| 831/840 [37:41<00:27,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1621 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 99%|█████████▉| 832/840 [37:41<00:17,  2.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> LLM Fusion Agent failed. Falling back to simple weighted logic.\n"," -> Final P(Admit) Score: 0.1508 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 99%|█████████▉| 833/840 [37:44<00:16,  2.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.4387 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 99%|█████████▉| 834/840 [37:47<00:15,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0853 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r 99%|█████████▉| 835/840 [37:50<00:13,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1216 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r100%|█████████▉| 836/840 [37:53<00:10,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0946 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r100%|█████████▉| 837/840 [37:58<00:10,  3.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.2608 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r100%|█████████▉| 838/840 [38:02<00:07,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0954 | Agent Decision: Admit\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["\r100%|█████████▉| 839/840 [38:04<00:03,  3.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.0914 | Agent Decision: Discharge\n","--- 4. Fusing Inputs with LLM Agent ---\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 840/840 [38:08<00:00,  2.72s/it]"]},{"name":"stdout","output_type":"stream","text":[" -> Final P(Admit) Score: 0.1828 | Agent Decision: Admit\n","Agent evaluation complete.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"data":{"text/html":["\n","  <div id=\"df-01e8b767-1c7a-4fbe-9193-de3f19e8cc51\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>true_label</th>\n","      <th>ml_prob</th>\n","      <th>llm_prob</th>\n","      <th>agent_prob</th>\n","      <th>ml_decision</th>\n","      <th>llm_decision</th>\n","      <th>agent_decision</th>\n","      <th>rationale</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.637178</td>\n","      <td>0.144875</td>\n","      <td>0.489487</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>AGENT: The final admission decision is based o...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.249396</td>\n","      <td>0.360190</td>\n","      <td>0.282634</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>FALLBACK: No JSON object found in LLM response...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0.042610</td>\n","      <td>0.263442</td>\n","      <td>0.108860</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>AGENT: Based on the data from the ML and LLM m...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.071299</td>\n","      <td>0.051142</td>\n","      <td>0.065252</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>AGENT: The final decision is to discharge the ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0.075542</td>\n","      <td>0.899719</td>\n","      <td>0.322795</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>FALLBACK: No JSON object found in LLM response...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","      \n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01e8b767-1c7a-4fbe-9193-de3f19e8cc51')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","      \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","    \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-01e8b767-1c7a-4fbe-9193-de3f19e8cc51 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-01e8b767-1c7a-4fbe-9193-de3f19e8cc51');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","  \n","    </div>\n","  </div>\n","  "],"text/plain":["   true_label   ml_prob  llm_prob  agent_prob  ml_decision  llm_decision  \\\n","0           0  0.637178  0.144875    0.489487            1             0   \n","1           1  0.249396  0.360190    0.282634            0             0   \n","2           0  0.042610  0.263442    0.108860            0             0   \n","3           0  0.071299  0.051142    0.065252            0             0   \n","4           0  0.075542  0.899719    0.322795            0             1   \n","\n","   agent_decision                                          rationale  \n","0               1  AGENT: The final admission decision is based o...  \n","1               0  FALLBACK: No JSON object found in LLM response...  \n","2               0  AGENT: Based on the data from the ML and LLM m...  \n","3               0  AGENT: The final decision is to discharge the ...  \n","4               0  FALLBACK: No JSON object found in LLM response...  "]},"metadata":{},"output_type":"display_data"}],"source":["print(f\"Running Head-to-Head evaluation on {len(test_patients)} test patients...\")\n","\n","results = []\n","neutral_human_prompt = \"No human note provided.\"\n","\n","# Use tqdm for a progress bar\n","for i, patient_data in enumerate(tqdm(test_patients)):\n","\n","    try:\n","        # We now have the raw patient_data dict from our CSV test set\n","\n","        # --- 1. Check Severity Gate ---\n","        # We must run this just as the agent would\n","        vitals = VitalSigns(**patient_data) # Validate the data\n","        is_severe = (\n","            (vitals.oxygen_saturation is not None and vitals.oxygen_saturation < 88) or\n","            (vitals.bp_systolic is not None and vitals.bp_systolic < 80) or\n","            (vitals.resp_rate is not None and (vitals.resp_rate > 35 or vitals.resp_rate < 8))\n","        )\n","\n","        ml_prob = 0.5\n","        llm_prob = 0.5\n","        agent_prob = 0.5\n","        agent_decision = 0\n","        agent_rationale = \"N/A\"\n","\n","        if is_severe:\n","            # If the gate catches it, all systems \"Admit\"\n","            ml_prob = 1.0\n","            llm_prob = 1.0\n","            agent_prob = 1.0\n","            agent_decision = 1 # 1 for Admit\n","            agent_rationale = \"Critical vital signs detected. Bypassed ML/LLM.\"\n","        else:\n","            # --- 2. Run Individual Models ---\n","            # Run ML Model (using the helper that renames age_bucket -> age_band)\n","            ml_prob = ml_predict_proba(patient_data)\n","\n","            # Run LLM Model (using the helper that formats the string)\n","            llm_text = format_for_llm_classifier(patient_data)\n","            llm_prob = llm_predict_proba(llm_text)\n","\n","            # --- 3. Run Fusion Agent Logic ---\n","            # We manually call the fusion_node function\n","            fusion_input_state = {\n","                \"ml_score\": ml_prob,\n","                \"llm_score\": llm_prob,\n","                \"human_prompt\": neutral_human_prompt\n","            }\n","            agent_state = fusion_node(fusion_input_state)\n","            agent_prob = agent_state['p_final']\n","            agent_decision = 1 if agent_state['decision'] == 'Admit' else 0\n","            agent_rationale = agent_state['rationale']\n","\n","        # --- 4. Store all results ---\n","        results.append({\n","            'true_label': true_labels[i], # Get the matching true label\n","            'ml_prob': ml_prob,\n","            'llm_prob': llm_prob,\n","            'agent_prob': agent_prob,\n","            'ml_decision': 1 if ml_prob >= 0.4 else 0,\n","            'llm_decision': 1 if llm_prob >= 0.4 else 0,\n","            'agent_decision': agent_decision,\n","            'rationale': agent_rationale\n","        })\n","\n","    except Exception as e:\n","        print(f\"Error processing patient {i}: {e}\")\n","        # Log error and continue\n","        results.append({\n","            'true_label': true_labels[i],\n","            'ml_prob': 0.5, 'llm_prob': 0.5, 'agent_prob': 0.5,\n","            'ml_decision': 0, 'llm_decision': 0, 'agent_decision': 0,\n","            'rationale': f\"ERROR: {e}\"\n","        })\n","\n","# Convert results to a DataFrame for easy analysis\n","results_df = pd.DataFrame(results).dropna()\n","\n","print(\"Agent evaluation complete.\")\n","display(results_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JRrxAM2gTsfE","outputId":"b19dc1f1-2b6e-4fdd-f9ef-29d05cf76f69"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- AGENT FUSION Performance (Test Set n=840) ---\n","Agent AUC: 0.8109\n","\n","Agent Classification Report (Threshold 0.4):\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.33      0.47       584\n","           1       0.36      0.85      0.50       256\n","\n","    accuracy                           0.49       840\n","   macro avg       0.59      0.59      0.49       840\n","weighted avg       0.69      0.49      0.48       840\n","\n","\n","Agent Confusion Matrix:\n","True Positives (TP): 217\n","True Negatives (TN): 192\n","False Positives (FP): 392\n","False Negatives (FN): 39\n"]}],"source":["from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n","\n","# Extract predictions and probabilities from the results DataFrame\n","agent_probabilities = results_df['agent_prob'].tolist()\n","agent_predictions = results_df['agent_decision'].tolist()\n","# Filter true_labels to match the (potentially dropped) rows in results_df\n","true_labels_filtered = results_df['true_label'].tolist()\n","\n","# --- 1. Agent Performance (vs. True Labels) ---\n","print(f\"--- AGENT FUSION Performance (Test Set n={len(true_labels_filtered)}) ---\")\n","\n","# Calculate AUC\n","agent_auc = roc_auc_score(true_labels_filtered, agent_probabilities)\n","print(f\"Agent AUC: {agent_auc:.4f}\")\n","\n","# Classification Report\n","print(\"\\nAgent Classification Report (Threshold 0.4):\")\n","print(classification_report(true_labels_filtered, agent_predictions))\n","\n","# Confusion Matrix\n","print(\"\\nAgent Confusion Matrix:\")\n","cm = confusion_matrix(true_labels_filtered, agent_predictions)\n","tn, fp, fn, tp = cm.ravel() # Now cm should be 2x2, raveling to 4 values\n","print(f\"True Positives (TP): {tp}\")\n","print(f\"True Negatives (TN): {tn}\")\n","print(f\"False Positives (FP): {fp}\")\n","print(f\"False Negatives (FN): {fn}\")\n","\n","# --- 2. (Optional) Create a results DataFrame to inspect ---\n","# This DataFrame is already created as results_df in the previous cell,\n","# but we can display it here for completeness if needed.\n","# print(\"\\n--- Sample of Agent Decisions ---\")\n","# display(results_df.head(10))\n","\n","# print(\"\\n--- Sample of 'Admit' Decisions ---\")\n","# display(results_df[results_df['Agent_Decision'] == 1].head(5))\n","\n","# print(\"\\n--- Sample of 'Discharge' Decisions ---\")\n","# display(results_df[results_df['Agent_Decision'] == 0].head(5))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cdfmuhtMUbQe","outputId":"d64efe58-d4fe-4bc5-db44-3620efd6912a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Results exported to: /content/drive/MyDrive/Work/Capstone-TeamFolder/Capstone_Organized/5-Evaluation_Reports/agent_eval_results.csv\n"]}],"source":["RESULTS_PATH = os.path.join(BASE_PATH, \"5-Evaluation_Reports/agent_eval_results.csv\")\n","\n","results_df.to_csv(RESULTS_PATH, index=False)\n","print(f\"Results exported to: {RESULTS_PATH}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ba5b8c97a16b44459c82604d40be0c57":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2926f9e3e7d64030af4eb85ddf05e180","IPY_MODEL_5cbf75615fa74e4e80c95a0d96099b9a","IPY_MODEL_f0900ccf5b4b45649f98d42b32662005"],"layout":"IPY_MODEL_11437132ecaa4ae9892ceebaf63c8a73"}},"2926f9e3e7d64030af4eb85ddf05e180":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b4b7edadb7443a2af3c43118f9e5900","placeholder":"​","style":"IPY_MODEL_eae73de69ae744d38fa4ae3c372f5677","value":"config.json: 100%"}},"5cbf75615fa74e4e80c95a0d96099b9a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_82e61d81dce04da49232663856082750","max":704,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8a94a9e851f14a098da94c2e4b58ec3a","value":704}},"f0900ccf5b4b45649f98d42b32662005":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f018630ac426479195d2f96f2a1c6885","placeholder":"​","style":"IPY_MODEL_595a724531ff4d3c979f42b4b3c86032","value":" 704/704 [00:00&lt;00:00, 93.0kB/s]"}},"11437132ecaa4ae9892ceebaf63c8a73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b4b7edadb7443a2af3c43118f9e5900":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eae73de69ae744d38fa4ae3c372f5677":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82e61d81dce04da49232663856082750":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a94a9e851f14a098da94c2e4b58ec3a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f018630ac426479195d2f96f2a1c6885":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"595a724531ff4d3c979f42b4b3c86032":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4163a2ed8bff4834b95bc074bd2ea0b6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0c13027362d6459da668c5f4f5ba5aab","IPY_MODEL_66417661c2754bd6bee7a5e14fd90890","IPY_MODEL_94c3ef593b1248d4abca0893590c7112"],"layout":"IPY_MODEL_0bf374a3b7e24f839f8e7a890dca5585"}},"0c13027362d6459da668c5f4f5ba5aab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e45cb6477ad248308302628e0f764ae5","placeholder":"​","style":"IPY_MODEL_29ef63cf8b9c4c4c8be0372b8c665d1a","value":"pytorch_model.bin.index.json: "}},"66417661c2754bd6bee7a5e14fd90890":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b2d4c1033cb4a5e8df96c6ea2f82147","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6fdda9bacbf847dd9abeee4b2d7d5e37","value":1}},"94c3ef593b1248d4abca0893590c7112":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_16950daeefd14719a4dc579d8bbd73d9","placeholder":"​","style":"IPY_MODEL_f6cc8f8077c448bfa78ff8e317e0e8b5","value":" 23.9k/? [00:00&lt;00:00, 2.64MB/s]"}},"0bf374a3b7e24f839f8e7a890dca5585":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e45cb6477ad248308302628e0f764ae5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29ef63cf8b9c4c4c8be0372b8c665d1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6b2d4c1033cb4a5e8df96c6ea2f82147":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"6fdda9bacbf847dd9abeee4b2d7d5e37":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"16950daeefd14719a4dc579d8bbd73d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6cc8f8077c448bfa78ff8e317e0e8b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f886651e3284558871ac79a9a6be5d5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_91bc304385034143a9761aa31106ee2f","IPY_MODEL_7c711fe88284466180d0ae97d20b60e2","IPY_MODEL_28e54731441d4ae6b7d8325e4785de94"],"layout":"IPY_MODEL_d85325e8dc73482c8b6408a0a5a68292"}},"91bc304385034143a9761aa31106ee2f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8526ace9dc341ffbb0cbe6fcd0d2490","placeholder":"​","style":"IPY_MODEL_060dc633e9b94b68b51f5466951b80a8","value":"Fetching 4 files: 100%"}},"7c711fe88284466180d0ae97d20b60e2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b199aeaf16ba4b209e6ec8f4a070148a","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ccad5026f9e242fc954b752c826c0ce3","value":4}},"28e54731441d4ae6b7d8325e4785de94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7cd58420be0448cc9fbf19cbbc97297a","placeholder":"​","style":"IPY_MODEL_d3ea3761c61e40aca12dd6e06221e7b7","value":" 4/4 [00:40&lt;00:00, 10.68s/it]"}},"d85325e8dc73482c8b6408a0a5a68292":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8526ace9dc341ffbb0cbe6fcd0d2490":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"060dc633e9b94b68b51f5466951b80a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b199aeaf16ba4b209e6ec8f4a070148a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ccad5026f9e242fc954b752c826c0ce3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7cd58420be0448cc9fbf19cbbc97297a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3ea3761c61e40aca12dd6e06221e7b7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ba9d9dd762364ee59bb02a69e2c7f1c7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_efb3e415fb854a19b739c280faa9503a","IPY_MODEL_03a4d9f4cec44d9fa33ffbf80cecbbf6","IPY_MODEL_7b1ea16658254d54b766622ad6f05f8a"],"layout":"IPY_MODEL_04525b71a6994024a4cfa824e645e8b8"}},"efb3e415fb854a19b739c280faa9503a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_38b4858ccca5480ebcc2060392398e5e","placeholder":"​","style":"IPY_MODEL_1890f8f86c81478cb0f3ee51c1373644","value":"pytorch_model-00004-of-00004.bin: 100%"}},"03a4d9f4cec44d9fa33ffbf80cecbbf6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_20198b1b842f45139356a8379d0d5704","max":1168140873,"min":0,"orientation":"horizontal","style":"IPY_MODEL_57d86a558bf746a18e374022fcafe61f","value":1168140873}},"7b1ea16658254d54b766622ad6f05f8a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8291f2132c8448cd915add9767b9a6e2","placeholder":"​","style":"IPY_MODEL_5bd865b317224f8791116f921b048f5b","value":" 1.17G/1.17G [00:23&lt;00:00, 23.9MB/s]"}},"04525b71a6994024a4cfa824e645e8b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38b4858ccca5480ebcc2060392398e5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1890f8f86c81478cb0f3ee51c1373644":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20198b1b842f45139356a8379d0d5704":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57d86a558bf746a18e374022fcafe61f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8291f2132c8448cd915add9767b9a6e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bd865b317224f8791116f921b048f5b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0133333d86ad482aaf7d31c123668e77":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7f63de97c365449d9095c82f7c365e2e","IPY_MODEL_5df8e80c82cf4d548781457fb7dd6b1f","IPY_MODEL_18de533ea0054a20be12739b0ee1aab1"],"layout":"IPY_MODEL_bf8ea643010b43aeab317346a3b416c1"}},"7f63de97c365449d9095c82f7c365e2e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_116160384c04409580ae62325361fb26","placeholder":"​","style":"IPY_MODEL_b7de788d62a44bb98c25ecdfe1055304","value":"pytorch_model-00001-of-00004.bin: 100%"}},"5df8e80c82cf4d548781457fb7dd6b1f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_82ee80f38e384112a72669ea67312de8","max":4976718466,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2edb52a2a1f24977810f1da1f8435485","value":4976718466}},"18de533ea0054a20be12739b0ee1aab1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3210269fabbd4a7e8853ac1d8e64b566","placeholder":"​","style":"IPY_MODEL_b9ed1d90b27947bbb740079c6b9fb235","value":" 4.98G/4.98G [00:40&lt;00:00, 134MB/s]"}},"bf8ea643010b43aeab317346a3b416c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"116160384c04409580ae62325361fb26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7de788d62a44bb98c25ecdfe1055304":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"82ee80f38e384112a72669ea67312de8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2edb52a2a1f24977810f1da1f8435485":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3210269fabbd4a7e8853ac1d8e64b566":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9ed1d90b27947bbb740079c6b9fb235":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cddded1b6ef648468dd42737ff1d4813":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_32a6309896794788bad68119aa8e499e","IPY_MODEL_289c75f9f132465daee3a152e2eb092a","IPY_MODEL_b6a5019194d1474686ca3bb189ff9fd0"],"layout":"IPY_MODEL_f62bfa2d19c5430b88667bbf32835bd5"}},"32a6309896794788bad68119aa8e499e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0cb53af3f0d40d08f1648752ecf2046","placeholder":"​","style":"IPY_MODEL_c46e91ee845d4b66bcf7a10b08640e4c","value":"pytorch_model-00002-of-00004.bin: 100%"}},"289c75f9f132465daee3a152e2eb092a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_be430d1f92f94dc8bab8f9fb1beccbc6","max":4999827718,"min":0,"orientation":"horizontal","style":"IPY_MODEL_655094ee2ffd4e2c9efa2361279d9f82","value":4999827718}},"b6a5019194d1474686ca3bb189ff9fd0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f7cb8782145487b884f62a5c82ddff0","placeholder":"​","style":"IPY_MODEL_d24638d52bbd4cf9b9407ae375e78735","value":" 5.00G/5.00G [00:40&lt;00:00, 134MB/s]"}},"f62bfa2d19c5430b88667bbf32835bd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c0cb53af3f0d40d08f1648752ecf2046":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c46e91ee845d4b66bcf7a10b08640e4c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be430d1f92f94dc8bab8f9fb1beccbc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"655094ee2ffd4e2c9efa2361279d9f82":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1f7cb8782145487b884f62a5c82ddff0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d24638d52bbd4cf9b9407ae375e78735":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1288ca4417ab4b9382578b85b992682a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5a7c5ac48da942da9d144e88f4210da8","IPY_MODEL_76b4b5f295bf4caeadb341955a7a93fa","IPY_MODEL_e81d2d9c636c43c287b9fdb551e9dddf"],"layout":"IPY_MODEL_500b397067ab4c18ab2923b945df23b0"}},"5a7c5ac48da942da9d144e88f4210da8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81ada5e65a6d4de9bb6af5bc992e3d36","placeholder":"​","style":"IPY_MODEL_45d61093bed544b5919f65606a4931b5","value":"pytorch_model-00003-of-00004.bin: 100%"}},"76b4b5f295bf4caeadb341955a7a93fa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b387af0b95d94bfab3a6bd0ec0c4023a","max":4915940170,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8643a3f4955b4df68b7ad94e9059e14f","value":4915940170}},"e81d2d9c636c43c287b9fdb551e9dddf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60098fb016fb413484a4fbb19c128013","placeholder":"​","style":"IPY_MODEL_78f9aa02bc0d4b94873641fc12d33cf2","value":" 4.92G/4.92G [00:40&lt;00:00, 340MB/s]"}},"500b397067ab4c18ab2923b945df23b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81ada5e65a6d4de9bb6af5bc992e3d36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45d61093bed544b5919f65606a4931b5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b387af0b95d94bfab3a6bd0ec0c4023a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8643a3f4955b4df68b7ad94e9059e14f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"60098fb016fb413484a4fbb19c128013":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78f9aa02bc0d4b94873641fc12d33cf2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c8ca533e28c4b68a8db4db92e93cab5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_86ca425c82af4115b73b3b3fa4451fdb","IPY_MODEL_4d3ebd3b7f464f9c93ea00946748dffc","IPY_MODEL_39ecf00a4f9c4f2cb1b98f44428c6a75"],"layout":"IPY_MODEL_4990de143024475784568bcc14391483"}},"86ca425c82af4115b73b3b3fa4451fdb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f2d476402b084ba7800a186ec70a3acb","placeholder":"​","style":"IPY_MODEL_4588d95e926e473bbd135cf54cdcb1a0","value":"Loading checkpoint shards: 100%"}},"4d3ebd3b7f464f9c93ea00946748dffc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0e7ade5d0fd4a599f36d4e84c3ca745","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a564cdcd8ad447668772c8c157f7ad18","value":4}},"39ecf00a4f9c4f2cb1b98f44428c6a75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a1f6c01a4d843fb9b8c03f9fb23f434","placeholder":"​","style":"IPY_MODEL_dd41bf30af7041f9899707ea010e0778","value":" 4/4 [00:04&lt;00:00,  1.43s/it]"}},"4990de143024475784568bcc14391483":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2d476402b084ba7800a186ec70a3acb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4588d95e926e473bbd135cf54cdcb1a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a0e7ade5d0fd4a599f36d4e84c3ca745":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a564cdcd8ad447668772c8c157f7ad18":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a1f6c01a4d843fb9b8c03f9fb23f434":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd41bf30af7041f9899707ea010e0778":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a00229253a9e4526bdee50b9f41ef5a4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a84465b4390f4b71bdc5d6796e3c567e","IPY_MODEL_0f4cca56dfb2487e81edb381d1df744e","IPY_MODEL_f8686dd5bd6142d085f128979811138a"],"layout":"IPY_MODEL_34898a3b0c01422cab3213b80c1a4d7a"}},"a84465b4390f4b71bdc5d6796e3c567e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0c992475cd55439c86b160710913a7e3","placeholder":"​","style":"IPY_MODEL_7fef1d06c29e437bb391eb8db1e9f1d3","value":"Loading checkpoint shards: 100%"}},"0f4cca56dfb2487e81edb381d1df744e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf2d7d838d864fbab5c7d9d64650f5df","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_76db97d578e24c55911ccc68fcc8f9e3","value":4}},"f8686dd5bd6142d085f128979811138a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_284dc723b99048c2a36aff1cc53e578c","placeholder":"​","style":"IPY_MODEL_fa85d316f629432c8508bfeb5c8dfd3f","value":" 4/4 [00:17&lt;00:00,  3.55s/it]"}},"34898a3b0c01422cab3213b80c1a4d7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c992475cd55439c86b160710913a7e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fef1d06c29e437bb391eb8db1e9f1d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cf2d7d838d864fbab5c7d9d64650f5df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"76db97d578e24c55911ccc68fcc8f9e3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"284dc723b99048c2a36aff1cc53e578c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa85d316f629432c8508bfeb5c8dfd3f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29d9aa787b014a7c9017b485fc5e4790":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_28569bdf415142a889b7c52e493ec810","IPY_MODEL_7c0e7a7a1fe441ea86b3f58cae42d3e0","IPY_MODEL_277f4be200c743668dccc1f9a63bda82"],"layout":"IPY_MODEL_13c9888d973e4e739cb888f11ddffb28"}},"28569bdf415142a889b7c52e493ec810":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7140e3f0d891473a8b24e19788d3e893","placeholder":"​","style":"IPY_MODEL_8d3cabe7ee0940d683edc77838571ebd","value":"generation_config.json: 100%"}},"7c0e7a7a1fe441ea86b3f58cae42d3e0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f30ac89d8e14e1286afe1d74d13f8cc","max":147,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9cec50d27b554633881bdba24fb0ba11","value":147}},"277f4be200c743668dccc1f9a63bda82":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a8de97f43974a98b5aafcf633b26459","placeholder":"​","style":"IPY_MODEL_86d4ff4ee86f41c38207026ec215a405","value":" 147/147 [00:00&lt;00:00, 18.7kB/s]"}},"13c9888d973e4e739cb888f11ddffb28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7140e3f0d891473a8b24e19788d3e893":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d3cabe7ee0940d683edc77838571ebd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f30ac89d8e14e1286afe1d74d13f8cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cec50d27b554633881bdba24fb0ba11":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6a8de97f43974a98b5aafcf633b26459":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86d4ff4ee86f41c38207026ec215a405":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"df57689962ef48309aa2fd780bb4dcbc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2dc0217e5d8b4060ba3aa1ac5e6705c3","IPY_MODEL_3e1fb829107244c39adb7262269387bc","IPY_MODEL_29da525d20a54b05b57ba6683aad9812"],"layout":"IPY_MODEL_c5d829ca90c94616985a06cb71232ca8"}},"2dc0217e5d8b4060ba3aa1ac5e6705c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f41eaeacdddf430d923f606ead05d63c","placeholder":"​","style":"IPY_MODEL_c6cfc9365b344d3fb9b1fc02e8b50794","value":"tokenizer_config.json: "}},"3e1fb829107244c39adb7262269387bc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_922d44f0c3654f699f08ac35b40a05bd","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2b919a3206f141729ebb80896d982176","value":1}},"29da525d20a54b05b57ba6683aad9812":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90fd6167faf74031aa1d0069c904a899","placeholder":"​","style":"IPY_MODEL_0d72e26fe3f243e9a8b37306ab184041","value":" 50.6k/? [00:00&lt;00:00, 5.35MB/s]"}},"c5d829ca90c94616985a06cb71232ca8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f41eaeacdddf430d923f606ead05d63c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6cfc9365b344d3fb9b1fc02e8b50794":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"922d44f0c3654f699f08ac35b40a05bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"2b919a3206f141729ebb80896d982176":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"90fd6167faf74031aa1d0069c904a899":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d72e26fe3f243e9a8b37306ab184041":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f264b147cc6849bd889c2a5be6799027":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0a29bb8465e741bd8b0904d1bb0c77f3","IPY_MODEL_7edc0f02dcc94317ae506716a81a1c2d","IPY_MODEL_571cc8213aac4c6bb844df8b4252eaf4"],"layout":"IPY_MODEL_0f644461640c43429d27467311d75f71"}},"0a29bb8465e741bd8b0904d1bb0c77f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0892506629694c978ed16c2823ec5239","placeholder":"​","style":"IPY_MODEL_3d543eeacab44af5869265528e0b638b","value":"tokenizer.json: "}},"7edc0f02dcc94317ae506716a81a1c2d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_47a3b86bd268498b9ebeb8d02a7029e2","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_00dd3a24ab2b4c20ad98f049fcb93bd2","value":1}},"571cc8213aac4c6bb844df8b4252eaf4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2cf1050a4944237a3fe070cd0a4af45","placeholder":"​","style":"IPY_MODEL_1299781f55aa40709701bc6650a8160c","value":" 9.08M/? [00:00&lt;00:00, 10.5MB/s]"}},"0f644461640c43429d27467311d75f71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0892506629694c978ed16c2823ec5239":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d543eeacab44af5869265528e0b638b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47a3b86bd268498b9ebeb8d02a7029e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"00dd3a24ab2b4c20ad98f049fcb93bd2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e2cf1050a4944237a3fe070cd0a4af45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1299781f55aa40709701bc6650a8160c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08663c7aee824341b1e62eda002807dc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f56a19995f61473eaadc3aacb50caf17","IPY_MODEL_7449fb113aec474b9c74c464b59d97f8","IPY_MODEL_2f4571d448e446649747374fcdcae125"],"layout":"IPY_MODEL_2a9d74fd064b4776add64f0450d9217b"}},"f56a19995f61473eaadc3aacb50caf17":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6de7fe1a74904ae59f24e134c4f8c916","placeholder":"​","style":"IPY_MODEL_8a80f95fe1a943879265e59e5978445b","value":"special_tokens_map.json: 100%"}},"7449fb113aec474b9c74c464b59d97f8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab4aae237d5a472e881bbf90a1d9f04f","max":449,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e1f2bab5cfcd4d81b55bed160ab9cbc0","value":449}},"2f4571d448e446649747374fcdcae125":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d63dcc23004a4b698199fd64d5952ab5","placeholder":"​","style":"IPY_MODEL_ec1b0fbd06d445ca8e46972421deedfc","value":" 449/449 [00:00&lt;00:00, 57.6kB/s]"}},"2a9d74fd064b4776add64f0450d9217b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6de7fe1a74904ae59f24e134c4f8c916":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a80f95fe1a943879265e59e5978445b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab4aae237d5a472e881bbf90a1d9f04f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1f2bab5cfcd4d81b55bed160ab9cbc0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d63dcc23004a4b698199fd64d5952ab5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec1b0fbd06d445ca8e46972421deedfc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}