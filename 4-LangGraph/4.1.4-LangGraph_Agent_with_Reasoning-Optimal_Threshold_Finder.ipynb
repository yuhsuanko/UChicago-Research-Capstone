{"cells":[{"cell_type":"markdown","metadata":{"id":"AQUhljnxNacw"},"source":["## Notebook Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SMFaX8MxFpNl","outputId":"e1ef8995-4bf9-456d-d783-88df2810a5c3","executionInfo":{"status":"ok","timestamp":1764611189333,"user_tz":300,"elapsed":4414,"user":{"displayName":"Alvin Yao","userId":"12743048314903098274"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rDRKdKT-xn0v"},"outputs":[],"source":["!pip -q install --upgrade langgraph transformers peft accelerate bitsandbytes \"scikit-learn==1.6.1\" joblib \"pandas==2.2.2\" langchain-core langchain"]},{"cell_type":"markdown","source":["## Notebook Setup"],"metadata":{"id":"zFxKHUs3p0pg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kXen0tRTxqum"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import joblib\n","import json\n","import os\n","import sqlite3\n","import torch\n","from typing import TypedDict, Optional, Dict, Literal\n","from pydantic import BaseModel, field_validator\n","from math import exp\n","from datetime import datetime\n","\n","from langgraph.graph import StateGraph, START, END\n","from langgraph.checkpoint.memory import MemorySaver\n","\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM, BitsAndBytesConfig\n","from peft import PeftModel\n","\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.compose import ColumnTransformer\n","from sklearn.ensemble import GradientBoostingClassifier"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"31be_UzEIJuO","outputId":"3ffbcfc8-f675-40e4-a5ea-24f668300514","executionInfo":{"status":"ok","timestamp":1764611205332,"user_tz":300,"elapsed":5,"user":{"displayName":"Alvin Yao","userId":"12743048314903098274"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tBO5jLVjyEDK","outputId":"5883b16a-1d50-48c8-a9c8-451c81a83947","executionInfo":{"status":"ok","timestamp":1764611205354,"user_tz":300,"elapsed":20,"user":{"displayName":"Alvin Yao","userId":"12743048314903098274"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["All model artifacts and simulation DB paths are verified.\n"]}],"source":["# DEFINE PATHS\n","\n","BASE_PATH           = \"/content/drive/MyDrive/Work/Capstone-TeamFolder/Capstone_Organized\" # CHANGE THIS WHEN YOU USE THE NOTEBOOK, ENSURE THE FINAL DESTINATION IS Capstone_Organized\n","ML_ARTIFACT_PATH    = BASE_PATH + \"/3-Model_Training/3.1-Traditional_ML/3.1.0-Traditional_ML_Artifacts\"\n","LLM_ARTIFACT_PATH   = BASE_PATH + \"/3-Model_Training/3.2-LLM_Classification/3.2.0-FineTune_OpenBioLLM\"\n","\n","DB_PATH             = os.path.join(BASE_PATH + \"/1-Data/ED_Simulated_Database_Fixed.db\")\n","\n","ML_MODEL_PATH       = os.path.join(ML_ARTIFACT_PATH, \"gb_model.joblib\")\n","ML_PREPROCESSOR_PATH= os.path.join(ML_ARTIFACT_PATH, \"ml_preprocessor.joblib\")\n","ML_FEATURES_PATH    = os.path.join(ML_ARTIFACT_PATH, \"ml_feature_columns.json\")\n","\n","LLM_MODEL_ID        = \"aaditya/Llama3-OpenBioLLM-8B\"\n","LLM_MODEL_PATH      = os.path.join(LLM_ARTIFACT_PATH, \"OpenBioLLM_Final\")\n","LLM_OFFLOAD_PATH    = os.path.join(LLM_ARTIFACT_PATH, \"OpenBioLLM_Offload\")\n","os.makedirs(LLM_OFFLOAD_PATH, exist_ok=True)\n","\n","assert os.path.exists(ML_MODEL_PATH), f\"ML Model not found: {ML_MODEL_PATH}\"\n","assert os.path.exists(ML_PREPROCESSOR_PATH), f\"ML Preprocessor not found: {ML_PREPROCESSOR_PATH}\"\n","assert os.path.exists(ML_FEATURES_PATH), f\"ML Features JSON not found: {ML_FEATURES_PATH}\"\n","assert os.path.exists(LLM_MODEL_PATH), f\"LLM Checkpoint not found: {LLM_MODEL_PATH}\"\n","assert os.path.exists(DB_PATH), f\"Simulation DB not found: {DB_PATH}\"\n","\n","print(\"All model artifacts and simulation DB paths are verified.\")"]},{"cell_type":"markdown","source":["## Log Setup"],"metadata":{"id":"8HskWGmSpdMp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BYHrm0_Bc9wq"},"outputs":[],"source":["import json\n","import os\n","import uuid\n","import time\n","import traceback\n","from datetime import datetime\n","from typing import Optional, Dict, Any\n","from contextlib import contextmanager\n","\n","LOG_PATH = \"/content/drive/MyDrive/Work/Capstone-TeamFolder/Capstone_Organized/4-LangGraph/4.0-LangGraph_Logs/trace_log.jsonl\" # adjust path\n","ERROR_LOG_PATH = \"/content/drive/MyDrive/Work/Capstone-TeamFolder/Capstone_Organized/4-LangGraph/4.0-LangGraph_Logs/error_log.jsonl\" # adjust path\n","\n","# Global execution context for traceability\n","_execution_context = {\n","    \"execution_id\": None,\n","    \"visit_id\": None,\n","    \"start_time\": None,\n","}\n","\n","def init_execution_context(visit_id: int):\n","    \"\"\"Initialize execution context for a new workflow run.\"\"\"\n","    _execution_context[\"execution_id\"] = str(uuid.uuid4())\n","    _execution_context[\"visit_id\"] = visit_id\n","    _execution_context[\"start_time\"] = time.time()\n","    return _execution_context[\"execution_id\"]\n","\n","def get_execution_id() -> Optional[str]:\n","    \"\"\"Get current execution ID for traceability.\"\"\"\n","    return _execution_context.get(\"execution_id\")\n","\n","def _make_json_safe(obj):\n","    \"\"\"\n","    Recursively convert objects into JSON-serializable forms.\n","\n","    Rules:\n","    - dict     → clean keys and values\n","    - list/tuple → clean each element\n","    - basic types (int, float, str, bool, None) → keep as-is\n","    - anything else (custom classes like VitalSigns) → convert to str(obj)\n","    \"\"\"\n","    # Basic scalar types that JSON can handle directly\n","    if isinstance(obj, (int, float, str, bool)) or obj is None:\n","        return obj\n","\n","    # dict: clean each key/value\n","    if isinstance(obj, dict):\n","        return {str(k): _make_json_safe(v) for k, v in obj.items()}\n","\n","    # list or tuple: clean each element\n","    if isinstance(obj, (list, tuple)):\n","        return [_make_json_safe(v) for v in obj]\n","\n","    # Fallback: custom object, dataclass, pydantic model, etc.\n","    # We serialize it via its string representation.\n","    return str(obj)\n","\n","\n","def log_event(step: str, input_state: dict, output_state: dict, meta: dict = None,\n","              execution_id: Optional[str] = None, duration_ms: Optional[float] = None,\n","              error: Optional[str] = None):\n","    \"\"\"\n","    Enhanced logging utility with execution tracking and performance metrics.\n","\n","    Args:\n","        step: Name of the step/node\n","        input_state: Input state dictionary\n","        output_state: Output state dictionary\n","        meta: Additional metadata\n","        execution_id: Unique execution ID for traceability\n","        duration_ms: Execution duration in milliseconds\n","        error: Error message if any\n","    \"\"\"\n","    execution_id = execution_id or get_execution_id()\n","\n","    record = {\n","        \"timestamp\": datetime.now().isoformat(),\n","        \"execution_id\": execution_id,\n","        \"step\": step,\n","        \"input_state\": _make_json_safe(input_state),\n","        \"output_state\": _make_json_safe(output_state),\n","        \"meta\": _make_json_safe(meta or {}),\n","    }\n","\n","    # Add performance metrics\n","    if duration_ms is not None:\n","        record[\"duration_ms\"] = duration_ms\n","        record[\"meta\"][\"performance\"] = {\"duration_ms\": duration_ms}\n","\n","    # Add error information if present\n","    if error:\n","        record[\"error\"] = error\n","        record[\"meta\"][\"error\"] = error\n","\n","    # Append one line per event\n","    try:\n","        with open(LOG_PATH, \"a\") as f:\n","            f.write(json.dumps(record) + \"\\n\")\n","    except Exception as e:\n","        print(f\"[WARNING] Failed to write to log file: {e}\")\n","\n","    # Optional console debug\n","    log_msg = f\"[LOG] execution_id={execution_id} step={step}\"\n","    if duration_ms is not None:\n","        log_msg += f\" duration={duration_ms:.2f}ms\"\n","    if error:\n","        log_msg += f\" ERROR={error[:100]}\"\n","    print(log_msg)\n","\n","\n","def log_error(step: str, error: Exception, state: dict = None, execution_id: Optional[str] = None):\n","    \"\"\"\n","    Log errors with full context for debugging.\n","\n","    Args:\n","        step: Name of the step where error occurred\n","        error: Exception object\n","        state: State at time of error\n","        execution_id: Unique execution ID\n","    \"\"\"\n","    execution_id = execution_id or get_execution_id()\n","\n","    error_record = {\n","        \"timestamp\": datetime.now().isoformat(),\n","        \"execution_id\": execution_id,\n","        \"step\": step,\n","        \"error_type\": type(error).__name__,\n","        \"error_message\": str(error),\n","        \"traceback\": traceback.format_exc(),\n","        \"state\": _make_json_safe(state or {}),\n","    }\n","\n","    try:\n","        with open(ERROR_LOG_PATH, \"a\") as f:\n","            f.write(json.dumps(error_record) + \"\\n\")\n","    except Exception as e:\n","        print(f\"[WARNING] Failed to write to error log file: {e}\")\n","\n","    print(f\"[ERROR] execution_id={execution_id} step={step} error={type(error).__name__}: {str(error)}\")\n","\n","\n","@contextmanager\n","def track_performance(step_name: str):\n","    \"\"\"Context manager to track execution time of a step.\"\"\"\n","    start_time = time.time()\n","    try:\n","        yield\n","    finally:\n","        duration_ms = (time.time() - start_time) * 1000\n","        print(f\"[PERF] {step_name} took {duration_ms:.2f}ms\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2dkrFvBmiHm8"},"outputs":[],"source":["import copy\n","from functools import wraps\n","\n","def make_logged_node(fn, name: str, max_retries: int = 0, retry_delay: float = 0.1):\n","    \"\"\"\n","    Enhanced node wrapper with:\n","    - Comprehensive logging with execution IDs\n","    - Performance tracking\n","    - Error handling with graceful degradation\n","    - Retry logic for transient failures\n","    - State validation\n","\n","    Args:\n","        fn: Node function to wrap\n","        name: Name of the node for logging\n","        max_retries: Maximum number of retries for transient failures (0 = no retries)\n","        retry_delay: Delay between retries in seconds\n","    \"\"\"\n","    def _to_serializable_dict(obj):\n","        \"\"\"Recursively converts Pydantic BaseModel instances to dictionaries within a dict/list.\"\"\"\n","        if isinstance(obj, BaseModel):\n","            return obj.model_dump()\n","        elif isinstance(obj, dict):\n","            return {k: _to_serializable_dict(v) for k, v in obj.items()}\n","        elif isinstance(obj, list):\n","            return [_to_serializable_dict(elem) for elem in obj]\n","        return obj\n","\n","    def _validate_state(state: dict, required_keys: list) -> tuple[bool, Optional[str]]:\n","        \"\"\"Validate that required keys exist in state.\"\"\"\n","        missing = [key for key in required_keys if key not in state or state[key] is None]\n","        if missing:\n","            return False, f\"Missing required state keys: {missing}\"\n","        return True, None\n","\n","    @wraps(fn)\n","    def wrapped(state):\n","        execution_id = get_execution_id()\n","        start_time = time.time()\n","\n","        # Create a deep copy of the state and convert Pydantic objects for logging input\n","        serializable_input_state = _to_serializable_dict(copy.deepcopy(state))\n","\n","        # Log input\n","        log_event(\n","            f\"{name}_INPUT\",\n","            serializable_input_state,\n","            {},\n","            execution_id=execution_id\n","        )\n","\n","        # Retry logic for transient failures\n","        last_error = None\n","        for attempt in range(max_retries + 1):\n","            try:\n","                # Run original node\n","                with track_performance(f\"{name}_node\"):\n","                    out = fn(state)\n","\n","                # Validate output\n","                if out is None:\n","                    out = {}  # Ensure we always return a dict\n","\n","                # Calculate duration\n","                duration_ms = (time.time() - start_time) * 1000\n","\n","                # Create a deep copy of the output and convert Pydantic objects for logging output\n","                serializable_current_state_for_output_log = _to_serializable_dict(copy.deepcopy(state))\n","                serializable_output_from_node = _to_serializable_dict(copy.deepcopy(out))\n","\n","                # Log output with performance metrics\n","                log_event(\n","                    f\"{name}_OUTPUT\",\n","                    serializable_current_state_for_output_log,\n","                    serializable_output_from_node,\n","                    execution_id=execution_id,\n","                    duration_ms=duration_ms\n","                )\n","\n","                return out\n","\n","            except Exception as e:\n","                last_error = e\n","                duration_ms = (time.time() - start_time) * 1000\n","\n","                # Log error\n","                log_error(name, e, state, execution_id)\n","\n","                # If this is the last attempt, handle the error\n","                if attempt == max_retries:\n","                    # Log failed attempt\n","                    log_event(\n","                        f\"{name}_ERROR\",\n","                        serializable_input_state,\n","                        {},\n","                        execution_id=execution_id,\n","                        duration_ms=duration_ms,\n","                        error=f\"{type(e).__name__}: {str(e)}\"\n","                    )\n","\n","                    # For critical nodes, we might want to raise\n","                    # For non-critical nodes, return a safe default\n","                    if name in [\"fetch_data\", \"severity_gate\"]:\n","                        # Critical nodes - re-raise\n","                        raise\n","                    else:\n","                        # Non-critical nodes - return safe defaults\n","                        print(f\"[WARNING] {name} failed after {max_retries + 1} attempts, using safe defaults\")\n","                        return _get_safe_default_output(name, state)\n","                else:\n","                    # Wait before retry\n","                    time.sleep(retry_delay * (attempt + 1))  # Exponential backoff\n","                    print(f\"[RETRY] {name} attempt {attempt + 1}/{max_retries + 1}\")\n","\n","        # Should never reach here, but just in case\n","        return _get_safe_default_output(name, state)\n","\n","    return wrapped\n","\n","\n","def _get_safe_default_output(node_name: str, state: dict) -> dict:\n","    \"\"\"\n","    Return safe default outputs for nodes that fail.\n","    This allows the workflow to continue with degraded functionality.\n","    \"\"\"\n","    defaults = {\n","        \"ml_model\": {\"ml_score\": 0.5},  # Neutral probability\n","        \"llm_model\": {\"llm_score\": 0.5},  # Neutral probability\n","        \"human_input\": {},  # No output needed\n","        \"fusion\": {\n","            \"fused_prob\": 0.5,\n","            \"p_final\": 0.5,\n","            \"fusion_decision\": \"Error\",\n","            \"fusion_rationale\": \"Fusion failed, using default neutral probability.\"\n","        },\n","        \"confidence_check\": state,  # Pass through\n","        \"human_review\": {\n","            \"fused_prob\": state.get(\"fused_prob\", state.get(\"p_final\", 0.5)),\n","            \"p_final\": state.get(\"fused_prob\", state.get(\"p_final\", 0.5))\n","        },\n","        \"finalize\": {\n","            \"decision\": \"UNKNOWN\",\n","            \"rationale\": f\"Workflow encountered errors. Node {node_name} failed.\",\n","            \"p_final\": state.get(\"fused_prob\", state.get(\"p_final\", 0.5))\n","        }\n","    }\n","    return defaults.get(node_name, {})"]},{"cell_type":"markdown","metadata":{"id":"Tn4CtpaAvH_V"},"source":["## Load Artifacts & Define Helper Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1jh6I0kl2kwy","outputId":"141b3395-c354-4ea9-fe35-c129980ecc52","executionInfo":{"status":"ok","timestamp":1764611205474,"user_tz":300,"elapsed":101,"user":{"displayName":"Alvin Yao","userId":"12743048314903098274"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Successfully loaded ML model and preprocessor (142 features).\n"]},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.12/pickle.py:1760: UserWarning: [17:46:45] WARNING: /workspace/src/collective/../data/../common/error_msg.h:83: If you are loading a serialized model (like pickle in Python, RDS in R) or\n","configuration generated by an older version of XGBoost, please export the model by calling\n","`Booster.save_model` from that version first, then load it back in current version. See:\n","\n","    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n","\n","for more details about differences between saving model and serializing.\n","\n","  setstate(state)\n"]}],"source":["# LOAD ML ARTIFACTS\n","\n","# Define function for joblib pointer\n","def clean_text_for_ml(text: str) -> str:\n","    \"\"\"\n","    Cleans the triage notes for TF-IDF.\n","    This version removes the [AGE] tags and all non-alpha characters.\n","    (Copied from 3.1.1-Traditional_ML_Training.ipynb)\n","    \"\"\"\n","    if not isinstance(text, str):\n","        return \"\"\n","    text = re.sub(r'\\\\[.*?\\\\]', ' ', text)    # Remove tags like [AGE]\n","    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)  # Remove special characters\n","    text = text.lower()                       # Convert to lowercase\n","    text = re.sub(r'\\s+', ' ', text).strip()  # Consolidate whitespace\n","    return text\n","\n","# Load joblib files\n","ml_model = joblib.load(ML_MODEL_PATH)\n","ml_preprocessor = joblib.load(ML_PREPROCESSOR_PATH)\n","\n","with open(ML_FEATURES_PATH, 'r') as f:\n","    ml_feature_names = json.load(f)\n","\n","print(f\"\\nSuccessfully loaded ML model and preprocessor ({len(ml_feature_names)} features).\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240,"referenced_widgets":["6c968c302eaf41ada08114e5b41ecc8b","cb9be678825b40b0863248614c79f9a2","6b77c33c9c8e4543a37cd9c67055ba95","10abf9ec39a04f5ab30a48016b7dd1e7","eda86da6021f481c8ff516629988b750","bb88da358f1b41eaaf64748c79b85ce8","51e4b09439c34119bfa27a99cf978589","89c099656d244bf5aeabf36fc7d1f63e","cc7c23bab7a946a8a86a20bc15f3d328","4b863d4c805c43e8b83c8990883c2377","a727b1e79c3b4dbd9b1dee4e868d7de0"]},"id":"h7uQmKHDF524","outputId":"1fca1fd4-5a5b-44a6-80fd-327681faa1d4","executionInfo":{"status":"ok","timestamp":1764611215578,"user_tz":300,"elapsed":10103,"user":{"displayName":"Alvin Yao","userId":"12743048314903098274"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","`torch_dtype` is deprecated! Use `dtype` instead!\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c968c302eaf41ada08114e5b41ecc8b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at aaditya/Llama3-OpenBioLLM-8B and are newly initialized: ['score.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["\n","Successfully loaded fine-tuned OpenBioLLM model.\n"]}],"source":["from peft import AutoPeftModelForSequenceClassification\n","\n","classifier_tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL_PATH)\n","if classifier_tokenizer.pad_token is None:\n","    classifier_tokenizer.pad_token = classifier_tokenizer.eos_token\n","\n","# Use AutoPeftModelForSequenceClassification to load the fine-tuned model\n","llm_classifier_model = AutoPeftModelForSequenceClassification.from_pretrained(\n","    LLM_MODEL_PATH,\n","    num_labels=2,\n","    torch_dtype=torch.float32,\n","    trust_remote_code=True,\n","    device_map=\"auto\", # Requires a GPU!\n","    offload_folder=LLM_OFFLOAD_PATH\n",")\n","llm_classifier_model.eval()\n","\n","print(\"\\nSuccessfully loaded fine-tuned OpenBioLLM model.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["3edcee4e862e4a5e92df9f374e74b2be","6576356cd91148ba9710871c532224e1","754b080cc7134f429759f942f0d56cbf","cc7d972002924afe81e27784cddceaad","f8d3f055da5046a494831fc078b543ba","8172cfc1b0c74bce8e96b9a41487fdf1","0d2529b09c294eb48fb90d6bcfbd49c9","cd5f313624f2427692ca498e36bd1c92","80694199ae9b45ee958029d6d093c973","259c1d215ce6450cafd1e7acd0c63884","3c1852504042458293f847866d5cbe59"]},"id":"hh3A6OOWmwPG","outputId":"490276a8-4680-4cd1-d285-64cc2a475423","executionInfo":{"status":"ok","timestamp":1764611235750,"user_tz":300,"elapsed":20171,"user":{"displayName":"Alvin Yao","userId":"12743048314903098274"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3edcee4e862e4a5e92df9f374e74b2be"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Successfully loaded base OpenBioLLM *Fusion Agent* model.\n"]}],"source":["# LOAD LLM FUSION AGENT\n","\n","# 1. Configure 4-bit quantization to save memory\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.float16,\n",")\n","\n","# 2. Load the base model with AutoModelForCausalLM\n","llm_fusion_model = AutoModelForCausalLM.from_pretrained(\n","    LLM_MODEL_ID,\n","    quantization_config=bnb_config,\n","    trust_remote_code=True,\n","    device_map=\"auto\",\n",")\n","\n","# 3. Load its tokenizer\n","fusion_tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL_ID, trust_remote_code=True)\n","if fusion_tokenizer.pad_token is None:\n","    fusion_tokenizer.pad_token = fusion_tokenizer.eos_token\n","\n","print(\"\\nSuccessfully loaded base OpenBioLLM *Fusion Agent* model.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qBtG054a8UlO","outputId":"d7675155-550a-4623-b991-9d96d6268fef","executionInfo":{"status":"ok","timestamp":1764611235773,"user_tz":300,"elapsed":24,"user":{"displayName":"Alvin Yao","userId":"12743048314903098274"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model helper functions defined.\n"]}],"source":["# LOAD HELPER FUNCTIONS\n","\n","# --- Helper for LLM Prediction ---\n","def format_for_llm_classifier(patient_data: dict) -> str:\n","    \"\"\"Formats the raw DB row for the CLASSIFICATION model.\"\"\"\n","    return (\n","        f\"age range: {patient_data.get('age_bucket')} / \"\n","        f\"sex: {patient_data.get('sex')} / \"\n","        f\"heart rate: {patient_data.get('heart_rate')} / \"\n","        f\"systolic blood pressure: {patient_data.get('bp_systolic')} / \"\n","        f\"diastolic blood pressure: {patient_data.get('bp_diastolic')} / \"\n","        f\"respiratory rate: {patient_data.get('resp_rate')} / \"\n","        f\"temperature in Celsius: {patient_data.get('temperature_C')} / \"\n","        f\"oxygen saturation: {patient_data.get('oxygen_saturation')} / \"\n","        f\"ESI: {int(patient_data.get('ESI', 0))} / \"\n","        f\"recent admissions (in 30 days): {int(patient_data.get('recent_admissions_30d', 0))} / \"\n","        f\"{patient_data.get('triage_notes_redacted', '')}\"\n","    )\n","\n","def llm_predict_proba(text: str) -> float:\n","    \"\"\"Runs the formatted text through the CLASSIFIER and returns P(Admit).\"\"\"\n","    device = llm_classifier_model.device\n","    inputs = classifier_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n","    inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","    with torch.no_grad():\n","        logits = llm_classifier_model(**inputs).logits\n","        probs = torch.softmax(logits, dim=-1)[0]\n","        return float(probs[1].cpu().numpy())\n","\n","\n","# --- Helper for ML Prediction ---\n","def ml_predict_proba(patient_data: dict) -> float:\n","    \"\"\"Runs the raw data through the ML preprocessor and model.\"\"\"\n","    input_df = pd.DataFrame([patient_data])\n","    transformed_data = ml_preprocessor.transform(input_df)\n","    input_transformed_df = pd.DataFrame(transformed_data.toarray(), columns=ml_feature_names)\n","    prob_admit = ml_model.predict_proba(input_transformed_df)[0][1]\n","    return float(prob_admit)\n","\n","print(\"Model helper functions defined.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rAO01CsfnR9V","outputId":"e7f8d3da-82c9-4954-99db-ecb3375f35e4","executionInfo":{"status":"ok","timestamp":1764611235799,"user_tz":300,"elapsed":25,"user":{"displayName":"Alvin Yao","userId":"12743048314903098274"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Fusion helper functions defined.\n"]}],"source":["def run_fusion_agent(ml_prob: float, llm_prob: float, human_note: str) -> dict:\n","    \"\"\"\n","    Uses the generative LLM to synthesize inputs and make a\n","    final decision with rationale.\n","    \"\"\"\n","\n","    prompt = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n","You are an expert ER triage physician. Your job is to synthesize three signals to make a final, clinically sound admission decision.\n","\n","You are given three inputs:\n","1) p_ml:  probability of admission from a traditional ML model.\n","2) p_llm: probability of admission from an LLM classifier.\n","3) human_note: short free-text note from a nurse or physician providing real-time context.\n","\n","Your task:\n","- Interpret all three signals.\n","- Resolve disagreements between the signals.\n","- Produce ONE final admission decision.\n","- Provide ONE rationale explaining exactly WHY you chose \"Admit\" or \"Discharge\".\n","  * Your rationale MUST explicitly reference p_ml, p_llm, and human_note.\n","  * It MUST give a clear clinical justification (e.g., high risk → admit, stable symptoms → discharge).\n","\n","Output STRICTLY as a single valid JSON object with EXACTLY two keys:\n","{{\n","  \"decision\": \"Admit\" | \"Discharge\",\n","  \"rationale\": \"string (2–4 sentences explaining the reason for your decision based on p_ml, p_llm, and human_note)\"\n","}}\n","\n","Do NOT output anything else.\n","Do NOT add comments or markdown.\n","Return ONLY the JSON object.\n","<|eot_id|><|start_header_id|>user<|end_header_id|>\n","Please make a final decision based on this information:\n","- p_ml (ML model): {ml_prob:.2f}\n","- p_llm (LLM classifier): {llm_prob:.2f}\n","- human_note: \"{human_note}\"\n","\n","Return ONLY the JSON object described above:\n","<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n","\"\"\"\n","\n","    device = llm_fusion_model.device\n","    inputs = fusion_tokenizer(prompt, return_tensors=\"pt\").to(device)\n","\n","    # Generate the response\n","    with torch.no_grad():\n","        outputs = llm_fusion_model.generate(\n","            **inputs,\n","            max_new_tokens=150,\n","            eos_token_id=fusion_tokenizer.eos_token_id\n","        )\n","\n","    # Decode and clean the output\n","    response_text = fusion_tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)\n","\n","    # Extract the JSON part\n","    json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n","    if json_match:\n","        try:\n","            return json.loads(json_match.group(0))\n","        except json.JSONDecodeError:\n","            return {\"decision\": \"Error\", \"rationale\": \"Failed to parse LLM JSON response.\"}\n","    else:\n","        return {\"decision\": \"Error\", \"rationale\": \"No JSON object found in LLM response.\"}\n","\n","print(\"Fusion helper functions defined.\")"]},{"cell_type":"markdown","metadata":{"id":"SjfsIbvF8fbQ"},"source":["## Define Graph State"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pkepvlM58g3a","outputId":"23e0e1a6-2178-4fe7-bc4e-b014d85875a3","executionInfo":{"status":"ok","timestamp":1764611235830,"user_tz":300,"elapsed":4,"user":{"displayName":"Alvin Yao","userId":"12743048314903098274"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["LangGraph state defined with enhanced optional fields for robustness.\n"]}],"source":["class VitalSigns(BaseModel):\n","    \"\"\"Pydantic model for validating vital signs.\"\"\"\n","    sex: Optional[str] = None\n","    age_bucket: Optional[str] = None\n","    heart_rate: Optional[float] = None\n","    resp_rate: Optional[float] = None\n","    bp_systolic: Optional[float] = None\n","    bp_diastolic: Optional[float] = None\n","    oxygen_saturation: Optional[float] = None\n","    temperature_C: Optional[float] = None\n","    ESI: Optional[int] = None\n","    mental_status: Optional[str] = None\n","    recent_admissions_30d: Optional[int] = None\n","\n","\n","class ERState(TypedDict, total=False):\n","    \"\"\"Defines the state of our graph with optional fields for robustness.\"\"\"\n","    visit_id: int\n","    human_prompt: str\n","    patient_data: Dict\n","    vitals_validated: VitalSigns\n","    triage_text: str\n","    ml_score: Optional[float]\n","    llm_score: Optional[float]\n","    severe: Optional[bool]\n","    p_final: Optional[float]\n","    fused_prob: Optional[float]\n","    decision: Optional[str]\n","    final_decision: Optional[str]\n","    confidence: Optional[float]\n","    rationale: Optional[str]\n","    fusion_decision: Optional[str]\n","    fusion_rationale: Optional[str]\n","    human_override: Optional[float]\n","    execution_id: Optional[str]  # For traceability\n","    error_log: Optional[list]  # Track errors during execution\n","\n","print(\"LangGraph state defined with enhanced optional fields for robustness.\")\n","\n","\n","def validate_initial_state(state: dict) -> tuple[bool, Optional[str]]:\n","    \"\"\"\n","    Validate initial state before workflow execution.\n","\n","    Returns:\n","        (is_valid, error_message)\n","    \"\"\"\n","    required = [\"visit_id\"]\n","    missing = [key for key in required if key not in state]\n","    if missing:\n","        return False, f\"Missing required initial state keys: {missing}\"\n","\n","    if not isinstance(state.get(\"visit_id\"), int) or state[\"visit_id\"] <= 0:\n","        return False, f\"Invalid visit_id: {state.get('visit_id')}\"\n","\n","    return True, None\n","\n","\n","def validate_state_transition(state: dict, node_name: str) -> tuple[bool, Optional[str]]:\n","    \"\"\"\n","    Validate state before node execution based on node requirements.\n","\n","    Returns:\n","        (is_valid, error_message)\n","    \"\"\"\n","    node_requirements = {\n","        \"fetch_data\": [\"visit_id\"],\n","        \"severity_gate\": [\"vitals_validated\"],\n","        \"ml_model\": [\"patient_data\"],\n","        \"llm_model\": [\"patient_data\"],\n","        \"human_input\": [\"human_prompt\"],\n","        \"fusion\": [\"ml_score\", \"llm_score\"],\n","        \"confidence_check\": [\"ml_score\", \"llm_score\", \"fused_prob\"],\n","        \"human_review\": [\"fused_prob\"],\n","        \"finalize\": [\"fused_prob\"],\n","    }\n","\n","    required = node_requirements.get(node_name, [])\n","    missing = [key for key in required if key not in state or state[key] is None]\n","    if missing:\n","        return False, f\"Node {node_name} missing required state keys: {missing}\"\n","\n","    return True, None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OP99DR459VyA"},"outputs":[],"source":["# --- Node 1: Fetch Data from DB ---\n","def fetch_data_node(state: ERState):\n","    \"\"\"\n","    Fetch Data Node\n","    ---------------\n","    Takes a visit_id, connects to the DB, and fetches the patient's\n","    de-identified data from Visit_Details, Triage_Notes, and ESI.\n","\n","    According to the diagram flow:\n","    - START → fetch_data (solid arrow)\n","    - fetch_data → severity_gate (solid arrow)\n","\n","    Enhanced with:\n","    - Input validation\n","    - Better error messages\n","    - Execution ID tracking\n","    \"\"\"\n","    visit_id = state.get('visit_id')\n","    execution_id = get_execution_id()\n","\n","    # Validate input\n","    if not visit_id or not isinstance(visit_id, int) or visit_id <= 0:\n","        raise ValueError(f\"Invalid visit_id: {visit_id}\")\n","\n","    print(f\"--- 1. Fetching data for visit_id: {visit_id} (execution_id: {execution_id}) ---\")\n","\n","    # Initialize execution context if not already set\n","    if execution_id is None:\n","        init_execution_context(visit_id)\n","        execution_id = get_execution_id()\n","\n","    # Update state with execution ID for traceability\n","    state_update = {\"execution_id\": execution_id}\n","\n","    conn = None\n","    try:\n","        # Validate DB path exists\n","        if not os.path.exists(DB_PATH):\n","            raise FileNotFoundError(f\"Database file not found: {DB_PATH}\")\n","\n","        conn = sqlite3.connect(DB_PATH, timeout=10.0)  # Add timeout\n","        conn.row_factory = sqlite3.Row\n","\n","        query = \"\"\"\n","        SELECT\n","            v.visit_id, v.patient_id, v.sex, v.age_bucket,\n","            v.heart_rate, v.bp_systolic, v.bp_diastolic, v.resp_rate,\n","            v.temperature_C, v.oxygen_saturation, v.recent_admissions_30d,\n","            v.admitted,\n","            t.triage_notes_redacted,\n","            e.ESI\n","        FROM Visit_Details v\n","        LEFT JOIN Triage_Notes t ON v.visit_id = t.visit_id AND v.patient_id = t.patient_id\n","        LEFT JOIN ESI e ON v.visit_id = e.visit_id AND v.patient_id = e.patient_id\n","        WHERE v.visit_id = ?\n","        \"\"\"\n","\n","        cursor = conn.cursor()\n","        cursor.execute(query, (visit_id,))\n","        row = cursor.fetchone()\n","\n","    except sqlite3.Error as e:\n","        error_msg = f\"Database error for visit_id {visit_id}: {str(e)}\"\n","        log_error(\"fetch_data\", e, state, execution_id)\n","        raise RuntimeError(error_msg) from e\n","    except Exception as e:\n","        error_msg = f\"Unexpected error fetching data for visit_id {visit_id}: {str(e)}\"\n","        log_error(\"fetch_data\", e, state, execution_id)\n","        raise\n","    finally:\n","        if conn:\n","            try:\n","                conn.close()\n","            except Exception:\n","                pass  # Ignore errors during cleanup\n","\n","    if row is None:\n","        error_msg = f\"No data found for visit_id: {visit_id} in {DB_PATH}\"\n","        raise ValueError(error_msg)\n","\n","    patient_data = dict(row)\n","\n","    # Validate that we have essential data\n","    if not patient_data.get('visit_id'):\n","        raise ValueError(f\"Invalid patient data returned for visit_id: {visit_id}\")\n","\n","    # Validate vitals with error handling\n","    try:\n","        vitals_validated = VitalSigns(**patient_data)\n","    except Exception as e:\n","        log_error(\"fetch_data_vitals_validation\", e, {\"patient_data\": patient_data}, execution_id)\n","        # Try to create with minimal required fields\n","        vitals_validated = VitalSigns(\n","            sex=patient_data.get('sex'),\n","            age_bucket=patient_data.get('age_bucket'),\n","            heart_rate=patient_data.get('heart_rate'),\n","            resp_rate=patient_data.get('resp_rate'),\n","            bp_systolic=patient_data.get('bp_systolic'),\n","            bp_diastolic=patient_data.get('bp_diastolic'),\n","            oxygen_saturation=patient_data.get('oxygen_saturation'),\n","            temperature_C=patient_data.get('temperature_C'),\n","            ESI=patient_data.get('ESI'),\n","            recent_admissions_30d=patient_data.get('recent_admissions_30d')\n","        )\n","\n","    state_update.update({\n","        \"patient_data\": patient_data,\n","        \"vitals_validated\": vitals_validated,\n","        \"triage_text\": patient_data.get('triage_notes_redacted', '')\n","    })\n","\n","    return state_update\n","\n","# --- Node 2: Severity Gate ---\n","def severity_gate_node(state: ERState):\n","    \"\"\"\n","    Severity Gate Node\n","    ------------------\n","    Checks for any critical vital signs that would require immediate admission.\n","\n","    According to the diagram flow:\n","    - fetch_data → severity_gate (solid arrow)\n","    - severity_gate has two conditional paths:\n","      1. Early exit (dotted arrow labeled \"end\") → END\n","      2. Continue (dotted arrow) → run_models\n","    \"\"\"\n","    print(\"--- 2. Checking severity gate ---\")\n","    v = state[\"vitals_validated\"]\n","\n","    if (v.oxygen_saturation is not None and v.oxygen_saturation < 88) or \\\n","       (v.bp_systolic is not None and v.bp_systolic < 80) or \\\n","       (v.resp_rate is not None and (v.resp_rate > 35 or v.resp_rate < 8)):\n","        print(\" -> CRITICAL: Patient is severe. Bypassing models.\")\n","        return {\n","            \"severe\": True,\n","            \"decision\": \"Admit\",\n","            \"p_final\": 1.0,\n","            \"rationale\": \"Critical vital signs detected. Bypassed ML/LLM.\"\n","        }\n","\n","    print(\" -> OK: Patient is not severe. Proceeding to models.\")\n","    return {\"severe\": False}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mS07x5_A9an8"},"outputs":[],"source":["# --- Node 3a: ML Model ---\n","def ml_model_node(state: ERState):\n","    \"\"\"\n","    ML Model Node\n","    -------------\n","    Runs the patient data through the retrained ML pipeline.\n","\n","    According to the diagram flow:\n","    - run_models → ml_model (solid arrow, parallel execution)\n","    - ml_model → fusion (solid arrow, converges with other models)\n","\n","    Enhanced with:\n","    - Input validation\n","    - Error handling with fallback\n","    - Score validation (0-1 range)\n","    \"\"\"\n","    print(\"--- 3a. Running ML Model ---\")\n","\n","    # Validate input\n","    patient_data = state.get('patient_data')\n","    if not patient_data:\n","        raise ValueError(\"Missing patient_data for ML model\")\n","\n","    try:\n","        score = ml_predict_proba(patient_data)\n","\n","        # Validate score is in valid range\n","        if not isinstance(score, (int, float)) or score < 0 or score > 1:\n","            print(f\"[WARNING] ML model returned invalid score: {score}, clamping to [0, 1]\")\n","            score = max(0.0, min(1.0, float(score)))\n","\n","        print(f\" -> ML Score (P_Admit): {score:.4f}\")\n","        return {\"ml_score\": float(score)}\n","\n","    except Exception as e:\n","        log_error(\"ml_model\", e, state, get_execution_id())\n","        # Return neutral score on error\n","        print(f\"[WARNING] ML model failed, using neutral score: {e}\")\n","        return {\"ml_score\": 0.5}\n","\n","# --- Node 3b: LLM Model ---\n","def llm_model_node(state: ERState):\n","    \"\"\"\n","    LLM Model Node\n","    --------------\n","    Runs the patient data through the retrained LLM pipeline.\n","\n","    According to the diagram flow:\n","    - run_models → llm_model (solid arrow, parallel execution)\n","    - llm_model → fusion (solid arrow, converges with other models)\n","\n","    Enhanced with:\n","    - Input validation\n","    - Error handling with fallback\n","    - Score validation (0-1 range)\n","    \"\"\"\n","    print(\"--- 3b. Running LLM Classifier ---\")\n","\n","    # Validate input\n","    patient_data = state.get('patient_data')\n","    if not patient_data:\n","        raise ValueError(\"Missing patient_data for LLM model\")\n","\n","    try:\n","        formatted_text = format_for_llm_classifier(patient_data)\n","\n","        # Validate formatted text is not empty\n","        if not formatted_text or not formatted_text.strip():\n","            print(\"[WARNING] Empty formatted text for LLM, using default\")\n","            formatted_text = \"No patient data available.\"\n","\n","        score = llm_predict_proba(formatted_text)\n","\n","        # Validate score is in valid range\n","        if not isinstance(score, (int, float)) or score < 0 or score > 1:\n","            print(f\"[WARNING] LLM model returned invalid score: {score}, clamping to [0, 1]\")\n","            score = max(0.0, min(1.0, float(score)))\n","\n","        print(f\" -> LLM Classifier Score (P_Admit): {score:.4f}\")\n","        return {\"llm_score\": float(score)}\n","\n","    except Exception as e:\n","        log_error(\"llm_model\", e, state, get_execution_id())\n","        # Return neutral score on error\n","        print(f\"[WARNING] LLM model failed, using neutral score: {e}\")\n","        return {\"llm_score\": 0.5}\n","\n","# --- Node 3c: Human Input ---\n","def human_input_node(state: ERState):\n","    \"\"\"\n","    Human Input Node\n","    ---------------\n","    This node acknowledges and processes the human prompt/note.\n","\n","    According to the diagram flow:\n","    - run_models → human_input (solid arrow, parallel execution)\n","    - human_input → fusion (solid arrow, converges with other models)\n","    \"\"\"\n","    print(\"--- 3c. Acknowledging Human Input ---\")\n","    print(f\" -> Human Note: '{state['human_prompt']}'\")\n","    return {}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FNe6Npqmnq04","outputId":"a832275e-8f29-4551-9d24-d390907c12b4","executionInfo":{"status":"ok","timestamp":1764611483177,"user_tz":300,"elapsed":67,"user":{"displayName":"Alvin Yao","userId":"12743048314903098274"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Fusion & Logic nodes defined.\n"]}],"source":["# --- Node 4: Fusion ---\n","def fusion_node(state: ERState):\n","    \"\"\"\n","    Fusion Node\n","    -----------\n","    Fuses the outputs from human_input, llm_model, and ml_model.\n","\n","    According to the diagram flow:\n","    - human_input, llm_model, ml_model → fusion (solid arrows, all converge)\n","    - fusion → confidence_check (solid arrow)\n","\n","    Calls the generative fusion agent (run_fusion_agent) to produce:\n","      - fusion_decision    : \"Admit\" / \"Discharge\" / \"Error\"\n","      - fusion_rationale   : textual explanation (2–4 sentences)\n","\n","    Also computes a numeric fused probability:\n","      fused_prob = 0.5 * ml_prob + 0.5 * llm_prob\n","\n","    Returns a partial state update with:\n","      - fused_prob\n","      - p_final            (alias for fused_prob)\n","      - fusion_decision\n","      - fusion_rationale\n","    \"\"\"\n","\n","    print(\"--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\")\n","\n","    # Validate and extract inputs with defaults\n","    ml_prob = state.get(\"ml_score\")\n","    llm_prob = state.get(\"llm_score\")\n","    human_note = (state.get(\"human_prompt\") or \"\").strip()\n","\n","    # Validate scores exist and are valid\n","    if ml_prob is None:\n","        print(\"[WARNING] ml_score missing, using default 0.5\")\n","        ml_prob = 0.5\n","    if llm_prob is None:\n","        print(\"[WARNING] llm_score missing, using default 0.5\")\n","        llm_prob = 0.5\n","\n","    # Ensure scores are in valid range\n","    ml_prob = max(0.0, min(1.0, float(ml_prob)))\n","    llm_prob = max(0.0, min(1.0, float(llm_prob)))\n","\n","    execution_id = get_execution_id()\n","\n","    # 1) Call fusion agent with error handling\n","    fusion_output = None\n","    fusion_error = None\n","    try:\n","        fusion_output = run_fusion_agent(\n","            ml_prob=ml_prob,\n","            llm_prob=llm_prob,\n","            human_note=human_note,\n","        )\n","\n","        # Validate fusion output\n","        if not isinstance(fusion_output, dict):\n","            raise ValueError(\"Fusion agent returned non-dict output\")\n","\n","    except Exception as e:\n","        fusion_error = str(e)\n","        log_error(\"fusion_agent\", e, state, execution_id)\n","        print(f\" -> Fusion agent raised an exception: {e}\")\n","        fusion_output = {\n","            \"decision\": \"Error\",\n","            \"rationale\": f\"Exception during fusion agent call: {e}. Using weighted average.\",\n","        }\n","\n","    fusion_decision = fusion_output.get(\"decision\", \"Error\") if fusion_output else \"Error\"\n","    fusion_rationale = fusion_output.get(\n","        \"rationale\",\n","        \"No rationale returned by fusion agent. Using weighted average of ML and LLM scores.\"\n","    ) if fusion_output else \"Fusion agent failed. Using weighted average.\"\n","\n","    # 2) Numeric fused probability (always compute as fallback)\n","    fused_prob = 0.5 * ml_prob + 0.5 * llm_prob\n","\n","    # If fusion agent failed, use weighted average as decision\n","    if fusion_error or fusion_decision == \"Error\":\n","        if fused_prob >= 0.5:\n","            fusion_decision = \"Admit\"\n","        else:\n","            fusion_decision = \"Discharge\"\n","        fusion_rationale = f\"Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = {fused_prob:.3f}. Decision: {fusion_decision}.\"\n","\n","    print(\n","        f\" -> Final P(Admit) Score (numeric): {fused_prob:.4f} | \"\n","        f\"Fusion Agent Decision: {fusion_decision}\"\n","    )\n","    print(f\" -> Fusion Agent Rationale (inside fusion_node): {fusion_rationale}\")\n","\n","    # 3) VERY IMPORTANT: return all fields you want to keep in the state\n","    return {\n","        \"fused_prob\": float(fused_prob),\n","        \"p_final\": float(fused_prob),\n","        \"fusion_decision\": fusion_decision,\n","        \"fusion_rationale\": fusion_rationale,\n","    }\n","\n","\n","\n","# --- Conditional Edge: Severity Gate ---\n","def conditional_severity_gate(state: ERState):\n","    \"\"\"\n","    Conditional Severity Gate Routing\n","    ----------------------------------\n","    Routes the workflow based on severity assessment:\n","    - If severe (critical vitals) → \"end\" (early exit to END)\n","    - If not severe → \"run_models\" (proceed to parallel model execution)\n","\n","    This matches the diagram flow where severity_gate has two paths:\n","    1. Early exit path (dotted arrow labeled \"end\") → END\n","    2. Continue path (dotted arrow) → run_models\n","    \"\"\"\n","    if state.get(\"severe\", False):\n","        print(\"[Routing] Severe case detected → early exit to END\")\n","        return \"end\"  # Go straight to the end (early exit path)\n","    else:\n","        print(\"[Routing] Non-severe case → proceeding to run_models\")\n","        return \"run_models\"  # Proceed to parallel branches\n","\n","print(\"Fusion & Logic nodes defined.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z5Sy_dIi7sP1"},"outputs":[],"source":["ADMISSION_THRESHOLD = 0.5 #Use default threshold 0.5 (this will be tuned when we find the optimal threshold)\n","\n","def confidence_check_node(state: ERState):\n","    \"\"\"\n","    Confidence Check Node\n","    ---------------------\n","    This node is executed after the fusion step.\n","\n","    According to the diagram flow:\n","    - fusion → confidence_check (solid arrow)\n","    - confidence_check has two conditional paths:\n","      1. high_confidence (dotted arrow) → finalize\n","      2. low_confidence (dotted arrow) → human_review\n","\n","    Purpose:\n","    - Validate that ML and LLM scores exist in the state.\n","    - Print debugging information for verification.\n","    - Pass-through node (no state modification).\n","\n","    NOTE:\n","    The actual routing decision (high vs. low confidence)\n","    is performed by `conditional_confidence_routing`.\n","    \"\"\"\n","    ml = state.get(\"ml_score\")\n","    llm = state.get(\"llm_score\")\n","    fused_prob = state.get(\"fused_prob\", state.get(\"p_final\"))\n","    print(\"--- 5. Confidence Check Node ---\")\n","    print(f\"[ConfidenceCheck] ml_score={ml:.4f}, llm_score={llm:.4f}, fused_prob={fused_prob:.4f}\")\n","    return state\n","\n","def human_review_node(state: ERState):\n","    \"\"\"\n","    Human Review Node (HITL - Human In The Loop)\n","    ---------------------------------------------\n","    This node is executed when confidence_check routes to low_confidence.\n","\n","    According to the diagram flow:\n","    - confidence_check → low_confidence (dotted arrow) → human_review\n","    - human_review → finalize (solid arrow)\n","\n","    This node provides human oversight for low-confidence cases.\n","\n","    Workflow:\n","    1. On first pass, LangGraph stops *before* this node\n","       if interrupt_before=[\"human_review\"] is set.\n","    2. You manually inspect the state via get_state().\n","    3. You insert state[\"human_override\"] manually.\n","    4. The graph is resumed → this node executes.\n","\n","    Behavior:\n","    - If human_override exists → override fused_prob.\n","    - If not → use the original fused_prob.\n","\n","    This ensures fully traceable HITL correction.\n","    \"\"\"\n","    print(\"--- 6. Human Review Node (HITL) ---\")\n","    override = state.get(\"human_override\", None)\n","\n","    if override is not None:\n","        output = {\"fused_prob\": float(override), \"p_final\": float(override)}\n","        log_event(\"human_review_override\", dict(state), output)\n","        print(f\"[HITL] Human override applied → fused_prob={override:.4f}\")\n","        return output\n","\n","    # No override → retain original fused_prob\n","    fused_prob = state.get(\"fused_prob\", state.get(\"p_final\"))\n","    output = {\"fused_prob\": float(fused_prob), \"p_final\": float(fused_prob)}\n","    log_event(\"human_review_no_override\", dict(state), output)\n","    print(f\"[HITL] No override provided → using original fused_prob={fused_prob:.4f}\")\n","    return output\n","\n","\n","\n","# 2d. finalize node\n","def finalize_node(state: ERState):\n","    \"\"\"\n","    Finalize Node\n","    -------------\n","    This node produces the final admission decision and rationale.\n","\n","    According to the diagram flow:\n","    - finalize can be reached from two paths:\n","      1. confidence_check → high_confidence (dotted arrow) → finalize\n","      2. confidence_check → low_confidence → human_review → finalize (solid arrow)\n","    - finalize → END (solid arrow)\n","\n","    Decision rule:\n","      - ADMIT     if fused_prob >= ADMISSION_THRESHOLD\n","      - DISCHARGE if fused_prob <  ADMISSION_THRESHOLD\n","      - UNKNOWN   if fused_prob is missing\n","\n","    It writes the following fields into the state:\n","      - final_decision : canonical final decision\n","      - rationale      : canonical final rationale\n","      - decision       : backward-compatible alias\n","      - p_final        : backward-compatible alias for fused_prob\n","\n","    IMPORTANT:\n","      - We start from the existing state (`dict(state)`) so that\n","        previous fields like `fusion_rationale` are preserved.\n","    \"\"\"\n","\n","    print(\"--- 7. Finalize Node ---\")\n","\n","    # Prefer fused_prob, but fall back to p_final if needed\n","    fused = state.get(\"fused_prob\", state.get(\"p_final\", None))\n","\n","    if fused is None:\n","        decision = \"UNKNOWN\"\n","        rationale = (\n","            \"Missing fused_prob; unable to generate a final decision. \"\n","            \"Check fusion or human review steps.\"\n","        )\n","    else:\n","        # Use global threshold\n","        print(f\"[Finalize] Using Admission Threshold: {ADMISSION_THRESHOLD:.4f}\")\n","\n","        if fused >= ADMISSION_THRESHOLD:\n","            decision = \"ADMIT\"\n","            rationale = (\n","                f\"Fused probability {fused:.2f} ≥ threshold {ADMISSION_THRESHOLD:.2f}; \"\n","                \"patient should be admitted.\"\n","            )\n","        else:\n","            decision = \"DISCHARGE\"\n","            rationale = (\n","                f\"Fused probability {fused:.2f} < threshold {ADMISSION_THRESHOLD:.2f}; \"\n","                \"patient may be safely discharged.\"\n","            )\n","\n","    # Merge decision fields back into the *existing* state\n","    new_state = dict(state)\n","    new_state[\"final_decision\"] = decision\n","    new_state[\"rationale\"] = rationale\n","\n","    # Backward-compatible aliases\n","    new_state[\"decision\"] = decision\n","    new_state[\"p_final\"] = fused\n","\n","    log_event(\"finalize_node\", dict(state), new_state)\n","    print(f\"[Finalize] Decision={decision}, Rationale={rationale}\")\n","\n","    return new_state\n","\n","\n","# 2e. confidence routing function（decide high / low confidence）\n","def conditional_confidence_routing(state: ERState):\n","    \"\"\"\n","    Conditional Confidence Routing\n","    ------------------------------\n","    This function determines whether the workflow should:\n","    - Auto-complete the decision (high confidence), OR\n","    - Trigger a Human Review (low confidence)\n","\n","    According to the diagram flow:\n","    - confidence_check has two conditional paths:\n","      1. high_confidence (dotted arrow) → finalize\n","      2. low_confidence (dotted arrow) → human_review\n","\n","    It returns one of ONLY these keys (must match add_conditional_edges):\n","        - \"high_confidence\"\n","        - \"low_confidence\"\n","\n","    This ensures LangGraph can correctly route AND\n","    ensures the interrupt_before=[\"human_review\"] will fire\n","    when low confidence is detected.\n","\n","    Routing Logic:\n","    1. If ML or LLM score is missing → LOW CONFIDENCE (force review)\n","    2. Compute:\n","        - probability gap = |ml_score - llm_score|\n","        - average score   = (ml_score + llm_score) / 2\n","    3. High confidence if:\n","        - gap < 0.20  AND  avg > 0.70\n","    4. Otherwise → low confidence → human review\n","    \"\"\"\n","    ml = state.get(\"ml_score\")\n","    llm = state.get(\"llm_score\")\n","\n","    # Missing scores → force human review\n","    if ml is None or llm is None:\n","        print(\"[Routing] Missing ML/LLM scores → LOW confidence → human_review\")\n","        return \"low_confidence\"\n","\n","    prob_gap = abs(ml - llm)\n","    avg_prob = (ml + llm) / 2\n","\n","    HIGH_CONF_GAP = 0.20\n","    HIGH_CONF_THRESH = 0.70\n","\n","    # High confidence path (matches diagram: high_confidence → finalize)\n","    if prob_gap < HIGH_CONF_GAP and avg_prob > HIGH_CONF_THRESH:\n","        print(f\"[Routing] HIGH confidence (gap={prob_gap:.2f}, avg={avg_prob:.2f}) → finalize\")\n","        return \"high_confidence\"\n","\n","    # Low confidence path (matches diagram: low_confidence → human_review)\n","    print(f\"[Routing] LOW confidence (gap={prob_gap:.2f}, avg={avg_prob:.2f}) → human_review\")\n","    return \"low_confidence\"\n","\n","\n","# Define a router node for parallel execution\n","def run_models_node(state: ERState):\n","    \"\"\"\n","    Run Models Router Node\n","    ----------------------\n","    This is a router node that triggers the parallel model runs.\n","\n","    According to the diagram flow:\n","    - severity_gate → run_models (dotted arrow, when not severe)\n","    - run_models fans out in parallel to:\n","      1. human_input (solid arrow)\n","      2. llm_model (solid arrow)\n","      3. ml_model (solid arrow)\n","    - All three converge into fusion (solid arrows from each)\n","    \"\"\"\n","    print(\"--- 3. Fanning out to parallel models (human_input, llm_model, ml_model) ---\")\n","    return {}"]},{"cell_type":"markdown","metadata":{"id":"Bj5BKMY2Ngsd"},"source":["## Initiate the Graph"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XSWiayWf9kVg"},"outputs":[],"source":["# 1. Initialize the graph\n","workflow = StateGraph(ERState)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ya-2TyQC1PUW","outputId":"1f70c9a9-9edd-4a7d-900b-84d1f4690581","executionInfo":{"status":"ok","timestamp":1764611498368,"user_tz":300,"elapsed":8,"user":{"displayName":"Alvin Yao","userId":"12743048314903098274"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- LangGraph Compiled Successfully! ---\n","Graph flow matches the diagram:\n","  START → fetch_data → severity_gate → (end OR run_models)\n","    → run_models → [human_input, llm_model, ml_model] (parallel)\n","    → fusion → confidence_check → (high_confidence OR low_confidence)\n","    → (high_confidence → finalize) OR (low_confidence → human_review → finalize)\n","    → finalize → END\n"]}],"source":["# ============================================\n","# Graph Construction - Matching Diagram Flow\n","# ============================================\n","# Flow according to diagram:\n","# START → fetch_data → severity_gate → (end OR run_models)\n","#   → run_models → [human_input, llm_model, ml_model] (parallel)\n","#   → fusion → confidence_check → (high_confidence OR low_confidence)\n","#   → (high_confidence → finalize) OR (low_confidence → human_review → finalize)\n","#   → finalize → END\n","\n","# Add all the nodes with enhanced error handling and retry logic\n","# Critical nodes (fetch_data, severity_gate) have no retries - failures should be explicit\n","# Non-critical nodes can retry transient failures\n","\n","workflow.add_node(\"fetch_data\", make_logged_node(fetch_data_node, \"fetch_data\", max_retries=0))\n","workflow.add_node(\"severity_gate\", make_logged_node(severity_gate_node, \"severity_gate\", max_retries=0))\n","workflow.add_node(\"run_models\", make_logged_node(run_models_node, \"run_models\", max_retries=0))   # router node\n","workflow.add_node(\"ml_model\", make_logged_node(ml_model_node, \"ml_model\", max_retries=1, retry_delay=0.5))\n","workflow.add_node(\"llm_model\", make_logged_node(llm_model_node, \"llm_model\", max_retries=1, retry_delay=0.5))\n","workflow.add_node(\"human_input\", make_logged_node(human_input_node, \"human_input\", max_retries=0))\n","workflow.add_node(\"fusion\", make_logged_node(fusion_node, \"fusion\", max_retries=1, retry_delay=1.0))\n","workflow.add_node(\"confidence_check\", make_logged_node(confidence_check_node, \"confidence_check\", max_retries=0))\n","workflow.add_node(\"human_review\", make_logged_node(human_review_node, \"human_review\", max_retries=0))\n","workflow.add_node(\"finalize\", make_logged_node(finalize_node, \"finalize\", max_retries=0))\n","\n","# ============================================\n","# Define the graph flow (matching diagram)\n","# ============================================\n","\n","# START → fetch_data (entry point)\n","workflow.set_entry_point(\"fetch_data\")\n","\n","# fetch_data → severity_gate (solid arrow)\n","workflow.add_edge(\"fetch_data\", \"severity_gate\")\n","\n","# severity_gate → conditional routing (matches diagram: two dotted arrows)\n","#   - \"end\" (early exit) → END\n","#   - \"run_models\" (continue) → run_models\n","workflow.add_conditional_edges(\n","    \"severity_gate\",\n","    conditional_severity_gate,\n","    {\n","        \"run_models\": \"run_models\",  # Continue path (dotted arrow in diagram)\n","        \"end\": END,                   # Early exit path (dotted arrow labeled \"end\" in diagram)\n","    },\n",")\n","\n","# run_models → parallel fan-out (matches diagram: three solid arrows)\n","# All three models run in parallel\n","workflow.add_edge(\"run_models\", \"ml_model\")\n","workflow.add_edge(\"run_models\", \"llm_model\")\n","workflow.add_edge(\"run_models\", \"human_input\")\n","\n","# Converge into fusion (matches diagram: three solid arrows converging)\n","# All three parallel branches must complete before fusion runs\n","workflow.add_edge(\"ml_model\", \"fusion\")\n","workflow.add_edge(\"llm_model\", \"fusion\")\n","workflow.add_edge(\"human_input\", \"fusion\")\n","\n","# fusion → confidence_check (solid arrow)\n","workflow.add_edge(\"fusion\", \"confidence_check\")\n","\n","# confidence_check → conditional routing (matches diagram: two dotted arrows)\n","#   - \"high_confidence\" (dotted arrow) → finalize\n","#   - \"low_confidence\" (dotted arrow) → human_review\n","workflow.add_conditional_edges(\n","    \"confidence_check\",\n","    conditional_confidence_routing,\n","    {\n","        \"high_confidence\": \"finalize\",    # High confidence path (dotted arrow in diagram)\n","        \"low_confidence\": \"human_review\",  # Low confidence path (dotted arrow in diagram)\n","    },\n",")\n","\n","# human_review → finalize (solid arrow)\n","# This path is taken when confidence is low\n","workflow.add_edge(\"human_review\", \"finalize\")\n","\n","# finalize → END (solid arrow)\n","workflow.add_edge(\"finalize\", END)\n","\n","# ============================================\n","# Compile the graph\n","# ============================================\n","memory = MemorySaver()\n","graph = workflow.compile(\n","    checkpointer=memory,\n","    #interrupt_before=[\"human_review\"],  # Uncomment to enable HITL interrupt\n",")\n","\n","print(\"\\n--- LangGraph Compiled Successfully! ---\")\n","print(\"Graph flow matches the diagram:\")\n","print(\"  START → fetch_data → severity_gate → (end OR run_models)\")\n","print(\"    → run_models → [human_input, llm_model, ml_model] (parallel)\")\n","print(\"    → fusion → confidence_check → (high_confidence OR low_confidence)\")\n","print(\"    → (high_confidence → finalize) OR (low_confidence → human_review → finalize)\")\n","print(\"    → finalize → END\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":993},"id":"LPyIyHg59kxE","outputId":"1365cc5b-82a1-4082-f1f5-cd60f14a08db","executionInfo":{"status":"ok","timestamp":1764611502278,"user_tz":300,"elapsed":92,"user":{"displayName":"Alvin Yao","userId":"12743048314903098274"}}},"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAe4AAAPQCAIAAAB/mg/1AAAQAElEQVR4nOzdBWATZxsH8PeSOjXaUoqVQnF3d/9wdxluY7huyHAYsOGM4W7F2WA4w921ULwUaKl7ct+THIRUaUpyTS7/3/jyXe4ulzSXe+69/5kFz/MMAABMmQUDAAATh1IOAGDyUMoBAEweSjkAgMlDKQcAMHko5QAAJg+lXGz+z6PunQ/99D42Pk6piOMVCsZxTDgiVCbjqFuh4IU+Xx6pL69U8sII1EEjySwYvZb60EBeGKTqq3qtuifjlaoJ0hRkck4R//l4U+pWKnjV5GQ84z+P83kQTUf9IYRPopmswMKKs7DkbDPJsue1LVfflQGAkeFwXLk4nt4MPf9PYMgHBdVQmYxZ28ls7GRUS/k47mvllTPVzPhS3D/35+jp58Iq9KFHVYGOS1C1VaNRt4Jp9+Q5Xk7lO/7zZ5DJmVKhrvrq99Eu5arararujPEJpiCQWzIlz8fFKGKjWXwsb23HeeS2adYvBwMA44BSbnAv7of/uyUgJpLPnNWiWFWHktVMu1WrUChObnv//EFkdCTv4WXV9idPBgAZDaXcsLb99vzj23ivIjZN++Zk0uL/IvLIuoDIcEWd9q6FymdmAJBxUMoN6M9xTymL+GFSXiZdt84EnT8Q5FXU7n8/ZGcAkEFQyg2F6njuIraNuptFgftrvG/V5m5FKjszAMgIKOUGsWLM0wLl7Ou0z8rMxsoJT91zWbccKLUcCcAkyBjo26qffb2K25pVHSf9ZnoHvIg5u/cDAwDRoZTr2e7FL+WW8kbdzDE47jo+x+3/QhgAiA6lXJ9CgmLfPovtOSUPM0uZnGw88tismfyMAYC4UMr1yWfRa4/cVsyMtf4xZ3SE8tHNUAYAIkIp15uosJjIEGXbYeZ+ykzW3NYX9gUxABARSrneHFzz3sYB3ydr1MMjPCSeAYCIUHr0Jsg/Jl+JTExc48aN27dvH9Nd/fr137x5wwwgk6OlpRU7uf0dAwCxoJTrTVwsK99I7PPX79+/z3Tn7+//6dMnZjDOWSzfPI1mACAWlHL9uHshWCZnmewNtc/z3Llz/fv3r1atWsuWLSdPnvzx40fqWa5cubdv306bNq1WrVr0NDw8fMWKFT169BBG+/3336OjP9fTunXrbt26tW/fvvSS06dPN2vWjHq2aNFi5MiRzADcclhHRSgZAIgFpVw/3r+ItrDkmGE8fPhw6NCh5cuX37Vr15gxYx4/fjxlyhSmru/0OHHixFOnTlHHtm3b1q1b161btz/++IPGP3r06MqVK4UpWFpa7tmzp2DBgkuXLq1atSqNQD0pmZk/fz4zAHdPK0UcSjmAeHDrCf2IjuQtDLZavHnzpo2NTa9evWQymYeHR5EiRXx9fZOO1rVrV2p958nz+aj2W7dunT9//qeffmKqe1BwTk5Oo0aNYqLI7G6rVBhqxQYASaGU6wvPc4aq5aVKlaKoZNiwYRUrVqxRo0auXLkoJ0k6GjW9L1y4QPELNdvj41XHkLi4uGiG0gqAiYVTlXFc2wdAPAhY9MPSWhYfb6hIoVChQosWLcqSJcvixYtbtWo1aNAganEnHY2GUqJCI+zdu/fq1as9e/bUHmplJd65SyEfYxkAiAilXD/cslsJd2gzkCpVqlAmfuDAAUrJQ0JCqIUutLs1eJ738fHp0KEDlXIKYahPWFgYyyDvX0bJLRkAiAalXD9K13Yx3NWCr127Rqk3dVDDvGnTpiNHjqQy7e/vrz1OXFxcVFSUu7u78DQ2NvbMmTMsgwS8iLG2wU8LQDxY3vRGJmPnD75nBkBxypgxY3bv3v3p06e7d+9u27aNanq2bNmsra2pdl+8eJHiFNoj6uXltX///tevXwcHB0+dOpUS9tDQ0IiIiKQTpDHp8ejRozQ1ZgBB7+OyeFozABALSrneOGWxfHIjghlA165dKTaZN29e/fr1+/XrlylTJsrELSxUu6x79ep15coVaqdTk3zmzJk2NjZt27Zt2bJlhQoVfvzxR3par169t2/fJppgzpw5mzVrtmLFCorXmQEo4li9juZ1uXaAjIW7COnNmyeRe5a9/fH3fMy8HVz1xv9ZdN+Z3gwAxIJWud7kyG9nYcXtX2mQC5uYkOf3o4pXw00+AUSF48r1qXY7t6ObU7wjWnx8PMUdyQ6ivZSWlpYcl8xpNXnz5l2zZg0zjHVqyQ6yt7cPDw9PdlCJEiUWLVqU7KB/1r6hfQaVGrsyABARAhY9Wz/Nz8KS6zLOK9mhKR0gGBMTQ/swkx1E9Z2qKjMMel9aiyQ7iPqndCi6XC63s7NLdtCS4b6th2TLnlfsK0QCmDmUcv1bPtq3UhOX0rVcmJlZPfGZazarloNyMgAQF7Jy/Rv4W77z+4MUCgUzJxtm+lnayFDHATIEWuUGQd/q0hFPm/Rxz1PUkZmBNVOeZc9j26hHNgYAGQGl3IAoOM7mbdXmR4nf7XPVL09tM8m7jPdiAJBBUMoN689xvoznKjTOXLqmBKPz3Ute+T+LyVcqU8PuaI8DZCSUcoM7sSPg4eUwuQWXp6hdg25SKHlPb4de+Tc4yD/WzlH+w+Q8DAAyGkq5SI5ueffyQWRUuJKTMRs7uYOLLJOThaWFXPvKuDIZU355KuN4Jc9p9/mMV++r5lXXBNfMOuqmySoVn7s1/WVyTqngtXvKZLxSyakPYP8852liyi8jaB/Xrv27kDMWExsfHaGMCFE90iBHF4ta7d1z5rNjAGAEUMrFdmpXwBvf6MjwOKqh8QpOqXWpWirHvKZwq4otVV5OqUwyg9R1l8qxZt6pSrOM59WlnFf99/lkIwu5LF6hFEYQRhbeQj30Sx/1oCSlPMEPw8KKXshZ28icsljmKZapeBWczAlgXFDKpWbgwIE9e/asUKECAwCzgRP3pSY+Pl64aCIAmA8s81KDUg5ghrDMSw1KOYAZwjIvNXFxcZaWuLEmgHlBKZcatMoBzBCWealBKQcwQ1jmpQalHMAMYZmXGmTlAGYIpVxq0CoHMENY5qUGpRzADGGZlxqUcgAzhGVealDKAcwQlnmpUSgUKOUA5gbLvKRQk1wulzMAMDMo5ZKCdAXAPGGxlxSUcgDzhMVeUnB+EIB5QimXFLTKAcwTFntJQSkHME9Y7CUFpRzAPGGxlxSUcgDzhMVeUrDbE8A8oZRLClrlAOYJi72kcByXJUsWBgBmBqVcUqiUBwQEMAAwMyjlkkLpCmUsDADMDEq5pKCUA5gnlHJJQSkHME8o5ZKCUg5gnlDKJQWlHMA8oZRLCko5gHlCKZcUlHIA84RSLiko5QDmCaVcUlDKAcwTSrmkUClXKBQMAMyMjIG0yOVyNMwBzA1KudQgYwEwQwhYpAalHMAMoZRLDUo5gBlCKZcalHIAM4RSLjUo5QBmiON5noHpK1mypFwu5ziOupVKJXXQnG3WrNnUqVMZAEgdjmCRiGLFijH1XYQI1XSZTJYtW7bu3bszADADKOUS0aNHj0yZMmn3KV++fL58+RgAmAGUcolo0KCBduHOkiVLu3btGACYB5Ry6ejWrZujo6PQXaRIESFyAQBzgFIuHXXq1MmfPz91ODk5denShQGA2cARLN/F91aI34OouOivfTiO0TcqPKqfC18x93kQ/R+fZGTtfpz6KZ9ghETjJ30jzePHj4G3b9+mUl6mTJkk7/L5Y6RlOsLQRO8ukKl2rCoVSi7B9LX+Lu1XWcqZdSZWo7UHAwBDQilPv1UTfeNimIWlLC5GqxQL1VDG8Upe/VRdy5XqQTJVvUtamoUDBzV9VJVS+eWpjNFrNbVeu0rKZKrRPo+Q4E15lrBkJ/OoflVy46g+ydcP/6VDe21D70vPFEqtP1mm/vzJlXILK9UfHx/HsuW2aj3EkwGAYaCUp9Oy0b5exW2rt8jB4FvCw6P2L3njXcK+Xic0zwEMAqU8PZaP9S1V26FY5awM0mzH70+zZLNu3j8nAwB9w25Pnf27xd/CgqGO66p0rcyvfaMZABgASrnO3r+IcchsxUBH+Uu7UJ7+4mEYAwB9QynXWUykascgA93xSi4qDIEegP7hyog6UyqYElceTBfV4TEMAPQPpRwAwOShlAMAmDyU8nRAVp5uHMM3B2AAKOW643AwfnpxPENaDmAAKOW64xNcRwV0kOgaNACgJyjlOpPJObkcTUsAMCIo5TpTKniFAk3L9OCRlAMYBko5iIdDugJgGCjlIDI0zAH0D6VcZ5yMlyErTz80zAH0D6VcZ7ySUyIrBwBjgstpieHZM9+x44bUb1hp85a17Pu8fv2ydt1yV65eZN8hOPgTTeTkqaNMZFgDAhgGSrnOOE51UzSdXnL8xOHbd278Onlu3TqNUhnNz+9px85NmdHQ/+dBLgVgGAhYdMbzTKnUrXkZERHu4ZG9SpUaqY/26PF9ZkwM8nk4lHMA/UMp1xkn43Ta7TlkaO+7d29RB2UafXoP7tK55+EjB/Yf8PHz882TJ1+d2g3atO7EcdzadSs2bFwljDZo4PB2bbuEhoX++efCv//Z5+TkXK5sxb59hmTN+vXemPMXzDh4aI+rq1uN6nV+GjLmmx/j+Ikja9cup2nSGqVDu27ag3bv2X7x4n8PHty1srYuWaJM796Dc2TPmfTzXLjw34mTR2jzIjQ0pHChYt269SldqhzTFa55AGAA8ilTpjDQxbVjQZY28gJlHdM4fuP/tQgODoqJid7jc7RE8dLHjh+eNXty1So1pv06L2/efH+tWvIuwL9ihSpUFmmcDx8DDu4/VbRIifj4+JGjByoUipEjfqZXXb9x+e9/9jZt0io8PGzP3u2v37ysVbN+q1Ydsnlk37hptaenV5483ql8BgrrR48Z3KZN5wkTprm4uKre9N3bmjXr5fHyvnPn5q9TxzWo36Rjxx5VqtS8cuUCZehNGrdM9Hmio6OHDO3lnsWjb58f69ZtRH/RX6sW/69RC1tbO5Zmt04Fepewd8tuzQBAr9AqTwfue5qWf/+9t0SJ0sOGjqPuzJldevYYMHfe1K6de1G39mgXL52lZvL6tbuoTNPTXLly79i5KSgoUBhKdbZ+vf8JHbv3bLtz5wa17lN50337d2Z19+jerY/wEprOjZtXhUFFihRfu3pHzpyeFhaqH0N8XNyEX4aHhIY4OTppT8HGxmbVym22tra0iUBPqVW+b/+uO3dv1qxRl+kAJwkBGARKuc5kcpbua7Aolcq7925179ZX06d06fLUk1KLRDXx6dMndnZ2Qh0nBfIX+mXCdKY+goUeixcrpRnTydE5JiYm9fd98+aVl1azvVChoppuuVz+9u3rpcvmP3h4NyIiQugZ/CkoUSknkZERq1YvuXnrWmDgx8+jBX9iOkNWDqB/KOU6UypYuq/BEhsbGxcXt3rNMvqn3f/Tp6BEY9KeUmtrm5SmI7fQbcZRuk3tbs1TWxtbTfe5c6d/mTSSEvz+/YZ6e+e/eu3SmLE/Jp1CQMC7ocP7lCldYeLP7RdprwAAEABJREFUM6khT+F+/YaVGAAYB5RynXEyxqX3MAyKKaitTcF0jYRt8OzZciYa084uU1RUJDXYZTI9HDDq6OgUHROteUrta033wb/3FC9eivbHCk8pi092CqdOH6X10Lixv1LGwtLZHhcgYQHQPxxXnh7fc0Cdt3eBsPAwCqyFf8WKlnR1cXN3z5potEIFi9CexkePHwhPX758PmxEP0pdWLpkzZqNkndaMQhPL1z8TzOIGuxZ3Nw1T//770SyU6DRHBwchTpOTp85znTHq+49gYAFQP9QynXGK3U+rlxb394/njt36u9/9lFhvXPn5tRp40eMGkANXhpEGQjF0GfPnnr16kW5cpVy5Mi1cuWi/86evHL14h8LZ394H5A7dx6WLrVq1ad29OIlv/E8Tzs89+7doRmUz7sATZ96xsfH79y1Wej5LsA/0efJmzc/de8/4EOjXbp8/vr1y7T/8/37d0wXnOoeQmiVA+gfSrnOZBYc/WPpRWnGyhWbb9++0apN/VFjBlEmPn3aAmtr1fF5lSpWo/2ZEyePOn7iiIWFxby5y5S8ctLk0RRe29jazpq50MIinYFY+XKVBvQfevny+Tr1ys+ZO4VyEqY6wltVVXv1GlSxQpVfJo5o0KgyBeI0iDYIxo3/6djxw9qfp26dht269t6w8S+KyH18tvw0ZEz9eo23bF23fMUfDAAyGm5TqbO/JvjZO1s07Z+LgY7WT/Gt3zlrwfIODAD0Crs9dfY9ByMCdnsCGAJKuc6+52BEwxn/87C7d24mO6hx45YDBwxjRoC2ALHbE8AQUMp1Rq1yzvha5aNG/BIbF5vsIDtdzq03KI7D6Z4ABoFSrjNqlfPG1yp3dXVjAGCuUMp1ZmHFWVjiyJ904XDePoBBoJTrLD6Wj49TMkgHHns9AQwCpVxncgv6h7YlABgRlHKdKeLpH9qW6cPhiwMwBJRynVGrXIZWeTrx+OIADAGlXGfUKleiVZ5+KOYA+odSrjsOV675HlgLAugfSrnOZDJjPEUIAMwZSrnOjPPEfQAwZyjlOrOyZhbWiFjSg/YY83KsBQH0D6VcZzb2XGRYLAPd0R7j/CXtGQDoG1qXOitbzzkqVMFAR6d2+ds6yORyOQMAfUMp11m+ks5O7vItc3wZpFlUVOyLexHN+rszADAA3EUonU7s8H9yPSJ7frscBeysLCyTjsCpD7vjEh58xyVzLB6f9FDrRL141Zk1aTtmhkvtYD+a2YxLcr4lp9vxgapJqG/R+fnK4wlfzslU9z7Vfsvg91EvH0YFBcQOnJsHTXIAA0EpT7+TuwOe3YyIjVYq4pIZyqmrXaKq/LnntyQaTV2BUxtNM8I3y3LSD5DoJTIZU6blWmFf/q5EE0z0VHUfVBnv6GrZeUxuBgAGg1IuNYMGDerRo0fFihUZAJgNHMEiNfHx8RYWmK0A5gXLvNSglAOYISzzUoNSDmCGsMxLTVxcnKWlJQMAc4JSLjVolQOYISzzUoNSDmCGsMxLDUo5gBnCMi81yMoBzBBKudSgVQ5ghrDMSw1KOYAZwjIvNSjlAGYIy7zUoJQDmCEs81JDpRy7PQHMDUq5pFAdxzXBAcwQSrmkIF0BME9Y7CUFpRzAPGGxlxSUcgDzhMVeUlDKAcwTFntJQSkHME9Y7CUFpRzAPGGxlxSUcgDzhMVeUnBZRADzhFIuKWiVA5gnLPaSwvN83rx5GQCYGZRySZHJZE+fPmUAYGZQyiWF0hXKWBgAmBmUcklBKQcwTyjlkoJSDmCeUMolBaUcwDyhlEsKSjmAeUIplxSUcgDzhFIuKSjlAOYJpVxSUMoBzBNKuaSglAOYJ5RySaFSrlAoGACYGRkDaZHL5WiYA5gblHKpQcYCYIYQsEgNSjmAGUIplxqUcgAzhFIuNSjlAGYIpVxqUMoBzBDH8zwD01e6dGmO46iDHpVKpUwmo8fKlSsvW7aMAYDU4QgWicidO7dMjUq5XC6nx8yZM/ft25cBgBlAKZeIFi1aUB3X7lOoUCFqqjMAMAMo5RLRvXv3HDlyaJ5mypSpS5cuDADMA0q5RFCo0rlzZ3oUnubJk6dq1aoMAMwDSrl0tGvXztPTkzqsra27devGAMBs4GDEb/O9FUq7EtMyJscx9RFBnLrj2+OrRmVpxTOeS3l09cErrM3/Bvvs2pXF3d0rS8WntyNSGVnz6XhO9V/S/l9H/vq3JP95tV/1eWRO/WFTmODXv4jnbexkOfPbMQD4PjgYMTVrf30WEaKUWzBFHMtwOtX91CWosHqcru7TlFmoqn92L+sWg3IxAEgvlPIULRnpmzO/Td1OORkY0tM7QRcPBOUuYvu/HjkYAKQLSnnylo32rdvNI3tuewai2D7P195J3nFUHgYAusNuz2Ts/ONlJmcL1HExdRiVL9BfgftmAKQPSnkyggNiPfLYMBCXhRU7ufM9AwDd4QiWZMTHcw7OVgzEZSG3iA5D3AeQHijlyVAoeA4lRXTxscr4WHzvAOmBUg4AYPJQysFYcDL6p/dD3AHMAko5GAte9Q+lHCA9UMqTh5qSAVRfupIBgO5QypPBcSjkGYFnPCo5QLqglCdDfQIsDqUAAJOBUg5GQ47dngDphFKeDE7zAGJSUMCCjSGA9EApTwaveQARqXZRoFUOkC4o5clAqzxD8Dxa5QDphFKeDLTKMwRa5QDphisjmqpnz3xr1y13+/YNJhVK+oer5wOkC0q5qXJ2zty9Wx93dw/haas29d/6v2Hi0u+bcvg5AqQXAhZT5eLi2vOHAUL3u3f+wcGfmLj0/6Y8Q6McIH3QDEqG+l7xuoW2Fy+dGz6i//+aVOvSreWsOZMDAz8K/YOCAqfP+Llj56YtW9ebMWviq1cvqOeVqxcpG7l795bm5Q8e3qM+NBHqvnfv9pixPzZvUbtbj9bLlv8eEREhjOOze1ubdg3PnjtVt36FxUvnaQKWGzevdurSjEbo0rXF+J+H0WfYtHmNZsoKhaJ5yzp/rlyU+ue/f/9Ov/5dGjetPnb8T/QBhgzt/fsfs4RBu/dsp8/TrHktevep08a/efuaemq/6S+TRjLVRd7j6V169m7fpFkNmsjFi2cZAIgFpTwFujQPHz95OH7C0NKly69bs+unIWOePn08Z+4Upi6jw0f2v3nr2vBhE9as2p7Z2WXQ4B5UCsuULu9g73DmvxOaKZw9e5L6lC9X6fWbV6PGDIqOiV6yeO20X6lePxk+oh9VSRrHysoqMjJi//5d48dNbdWivea1pUuVmzXjD+rYvGkfddSu1eDY8X80Q6nmhoWFNmrYLJXPHx0dPeGX4Zkzu6xZtaN3r0FLly/48CGAU6/M7ty5uXjJb0WLlpw6dd64sb9++hQ0Y+Yvid50+tT51LFo8dxdPltateywZfOBmjXqTv51zOkzx5kuOBmTyfGDBEgPLDnJ0PUIlrt3btrY2HTt0itrVo+KFarM/215p04/MHUdfPny+YTx06gn5SEDBwxzdHL28dkil8tr125w5r+vlY7Ket26jaj/sWP/WFpYUhH39PTy8so7auTEJ76PqCXOVNsJHNXcjh171KvbKGdOz5Q+TJPGLV+88KNXCU9Pnz5WqGCR3LlTu/3xxUtnQ0KC+/cb6uGRrUD+Qn37/BgQ8E4YVKRI8bWrd3Tp3JNqN61p2rfr+uDB3ZDQkERTiImJOfLvwc6dfmjerI2To1Pj/7WoW6fRho1/MV3wSqZU4CIsAOmBUp48nfKVYsVLUZGlcGPnrs3UrHZycqbCR/3v3L1paWlJbfAv0+RKlSx76/Z16q5Vqz6VS2rOU7ef39PXr19S7WOqdOVWoUJFaQrCS6i2Zs+e8/adr4epFCpYNPUPU7RoCSr0tEpgqiO1eWoa16/fJPWX+Pn52tvb582bT3hKH97BwVHoprXL27evaZujafOalOdQ4516Bn8KSjSFx48fxMbGli9XWdOH/lKKgDTpUFrgYESAdMNuz+TptP+NWrKzZy06c+b4yr8WU7pdtkyFH3r0L1asZHh4WFxcHFVA7ZGdnTMzdaWjQINeQq/97+zJLFncaXzqTy95+Oh+opd8CgrUdFPM8s3P07J5u01b1gzoP5TSlaioyHr1/pf6+GHhYXZ2mZJ+SHLu3GmKwqlVTm12b+/8V69dotw86RToY9MjJexJ+2fKlImlDU4RAkg3lPJkcLpfr5wiFPrX84cB165d8tm9dcLPw3b7HHV1dbO1tZ0x/XftMeUyOVO30CljoeSkT+/BFJTXr9dYGOri6la8eCnNoSkCJ0dnpov6DZqsWLmQyu6Fi/9VqVzD8UsTOyU21jbUptbuExj4Qeg4+Pce+jz0IYWnQslOytUtCz2OHPFzjhy5tPtrVgkAYFAo5cngdTxt/+bNazGxMVTK3dyyNGzY1MMj+7AR/d4F+Ht7F4iKinJ398iRPacw5lv/N85On6tbnVoNdu/edvHiWcq1KU8Xenrnzf/v0UMlS5SRyT5nX8+fP0slGU8W1e5aNetRSk6rilEjfvnm+FR/gyk0CQqkQJ+p95RGRkYKg0JDQzyyZtOM+Z/WrlptOXN4WltbM3U4I/ShHaQU7wg900gm52SWSPwA0gNLTkp02e1579aUX8ccOLibCuL9B3d379lGNZ0qICUtFSpUmTdvGsXitF9x776dAwZ2O3x4v/AqCrXd3bOuXbeCQmrawyn0bNu2i1KpXLJsPoXvr169+HPlol59Ojzz8039A+Ty9KLHU6eO0rsLfRo3bikcx1KpUjX2LZUqVqNMfPGS3yjapqx/48ZVFPgIg/J5F7hy9SIV9/j4eNoTIPSktVSiN7Wzs6NMifZz0p5eauBTQD9qzKA/Fs5mulAqeGUcdnsCpAda5XrQvl1XKuJLls5b8PtMyrLr1G74+4KVFhaq73bWjD/2H/CZOn38/ft3cuXKTbF169YdNS+sVbP+jp2bNPEFUzeoV6/avm3b+v4Du758+Zx2gY4eNZHy9NQ/ALX6GzVsRmuFYkVL/r7gT6ZuHdMHoNxG+BipoyBo+LDxq9csa9OuQf78hXp070dl3cLCkgb16jUoMjLil4kjaPOidauO48b+6u//Ztz4n36eML1e3Ubab9qxQ3faCtmybd3165czZbIvWqTEyJHf3iAAAL3geJxgl8SSEb5l6roWr2bCOe+jxw8GDuq+YZ1PGsOZN29fOzg4Cqk6/SSaNq/Z64eBbdp0YiLaMvOZR27rFoNyMADQEVrlyVAdFWeyB8X5+j4OCPBfuWpxp4490ljHKfwZNLgHZSm9ew/OnNll9eqlMk5Wq1Z9JjKcuA+QXijlyVAVFJMtKiv/WkTpdv36jXv1HKjpuWXruq1b1yU7fm6vvEsWrZk9c+Ffq5ZMmjwqNiamcOFiS5eso9SFiYzjZaa7CgXIUAhYkkEBS9m6LsWquTCpCAsPS+k4Qgu5hWYnZ8baOutZ1tw2LQZmZwCgI7TKkyex1qGDvSyiRw0AABAASURBVAP9Y8aNV+IUIYB0QilPBtVxJW4IBwCmA6U8GZQ5cTi+WXymvLcZIGOhlKeAw5a+6HAEC0B6oZSD0ZBJbh8FgFhQysFoKE34GFCAjIVSngxqGvK4Oo3oOJnqHwCkA0p5MlS7PRn2e4pNfTAiA4B0QCkHADB5KOUAACYPpTwZFpYcDiwXH2eplFngawdID5TyZFhYcCGB8QxExnOOrt++cykAJIVSnozM2SzePYtkIKKI8NjYaL5W26wMAHSHg7+S0eZHz6gI5c0zHxiI5cDylzaZI3777beAgAAGADpCKU9erZ5xd04HHVz5/MObCAaGdOPk+y2zfAuVd+wxrkiuXLnOnDlDPc+ePfvq1SsGAGmD65UnEBwcbGFhYW9v37Vr106dOgXeLBIWpOA4plAkP77q60vhXHOOp+w3uQE80+2qi6qj3Lk0Tj/tPZOZYPK3pk7cO/mpJf2j0vBncurTguSWLG8JuwadE1ym/L///ps/f/6UKVNKlSoVEhLi5OTEACBlKOVfLVmyZI+ao6Ojdv+ggNgEpVx1MuiXL42qGserzw792vPz8IS17HNF5DhOSS/iE08n8bOvFVP9wmTKrDBtPuEL6bOoX8UnGpPXPGp9zM+f6MvYyZZyGc+UCSuyTHVwT5IPw3955y/T1674n6es/q4Svk7hktVKLpezFISFhTk4OAwcOJC+tkWLFqXlltMA5sncS/n79+9XrVpFTb/GjRvfvn27RIkSDIzPpUuXSpYsSb9Vaqe3bdu2fPnyDAC0mGlWHhgYeO7cOeo4f/58wYIFGzZsSN2o40arYsWKNjY2tra29evXP3HiBPV5+vTptWvXGAComWOr3NfXd9CgQWPGjKlXrx4D0xQQEDBp0qTChQsPGzaMVsyurq4MwIyZUSmfNm0ateP27t2L3WiSER4eTvuofXx8tm/fPnPmzHz58jEAsyTxUh4cHEzLebNmzdzd3amIU0cqO9nAdFHeEhcXV6hQoXnz5nl6elKeLpPhQFswI5L9uQtHJc+aNSsmJsbFxYW6W7ZsiTouVd7e3lTHqaNNmzZ+fn6vX7+m7n///ZcBmAcJtsr/+++/4cOHr1y5skyZMgzM2JQpU86ePXvs2DEhh2EA0iWRUk5N73Xr1kVERIwYMeLJkyeUmXK4SyR88ebNm86dOw8dOrR169YMQIpMO2Ch9ZCwEf3s2TOq3T179qTu/Pnzo46Dthw5chw6dMjDw4O6qWPJkiWfPn1iABJiqqU8OjqaHitXrnz//n3qKFy4cL9+/TJnzswAkkMBS5UqVaijVq1amTJlEq70Qlnchw+4aBpIgekFLPv371+xYsX69euzZMnCAL7D4cOH//jjD2qkUyJHGZ21tTUDME2mUcqVSuXevXvd3Nxq1Khx5MiRUqVKZc2KC1uDfgg7Rdu2bevp6blgwQIGYIKMPWDx9fWlxw0bNjx48KBYsWLU3bBhQ9Rx0CPh4JZdu3a1aNGCqS/LM3ny5Hv37jEA02G8rfK3b9/+8MMPXbp06dGjBwMQ0cGDB6npMHr06EePHsXHxxctWpQBGDejK+U+Pj60M4oSTGocyeVyXFsDMtDz588nTZpUp04dalV8+vQJ+9XBaBlLwHLu3DnhWIKnT58OGjSIOtzd3VHHIWN5eXlRuNeyZUvq3rNnT/fu3YXzSAGMTQa3ykNDQx0dHceNGxcZGTlr1qxMmTIxAGNFAbq1tXW+fPlmz55duHBhIVsHMAYZ1ip/+PBh165dL1++TN0TJ05ctGgR6jgYOQrNhYsvNmvW7NatW4GBgZSknz59mgFkNLFb5adOnaJNVCrily5dovY4NW0YgMlSKpWjRo2iXfTbtm0TNjEZQEYQqVVOCTg93r9//8CBA2XLlmXq+8KgjoOpk8lkCxYsWLduHVMfc9WwYcOjR48yANEZtlWuUCjkcnmPHj0oPFm2bJnwlAFI1MePHx8/flylShUfHx9qpHfs2NHW1pYBGJ6hSvnNmzfXrl1L2565cuXy9fXF7V3ArAQHB2/atCl//vzUTj9z5kypUqWQvYBB6bmUU4QSGxtLP9w1a9YUKFCgWrVqDMC87dq1a+nSpVu2bMmWLRsDMAx9lvITJ0789ddf06dP9/b2ZgCgJTIy0s7Orl+/fvPmzUMLHfTOgulP1apV69SpwwAgCarj9MhxXFBQEEo56J0+W+Xv3r1zcHDA4eEAACLT58GIs2fPvn79OgOAFISEhMTHxzMAfdNnKae9OmiSA6RixIgRd+/eZQD6ps+sfOzYsQwAUubq6oobz4IhICsHADB5yMoBxBMaGhoXF8cA9A1ZOYB4pkyZcv78eQagb8jKAcTj4uKCrBwMAVk5AIDJQ1YOIJ7w8PDo6GgGoG/IygHEs3Dhwr///psB6BuycgDxODo6WlpaMgB9Q1YOAGDykJUDiCcyMjIqKooB6BuycgDxrF27duvWrQxA35CVA4iHsnKZTKR7o4NZQVYOYHBNmzZVKpUxMTH0qFAo4tRoYTl58iQD0Adk5QAGV7BgQX9//5CQkLCwMIrLqY5TE6pixYoMQE+QlQMYXJ8+fbJnz67dx83NrVOnTgxAT/RZyikrL1OmDAOAhAoXLly2bFntPtROL1myJAPQE32WcsrKIyIiGAAk0atXL3d3d6HbyckJTXLQL2TlAGLw8vKqUqWK0J0vX77KlSszAP1BVg4gkp49e9IyYmdnhyY56J0+D0YEyFj7/3r97llMfByvUCQ7nGMszb/2FMZVLTBJLjiu7pe0J0t6ZfJke6rfift2v+TG+ub0OZ7xXKpjaMaUMbmcObpYdBnnxcDU4LhykIidi16Ffoj1LuXgWdhJZpGwWglFkEoa9/nXrinUnHqQUlXevi4IqqFaI3+ZBidT9+C/TuRzneS/vlDVRzPZRIsWp56Kek2g9V7q0ZXc19E5XvUf4xN8JqFXgk+pVdk5zTPtwq0eXfvtEn0qTv03ak1QEfgm+tG10JAPcQPn5mNgUvRZyocNG9amTZvq1aszAHGt+/WZzIJv9aM3g+/29G7Qhb1BA39DNTclyMrB5F0+8iEmUok6ri/exVyc3C03z37GwHTgGixg8p7ciHDIgouA61Ohik6XDn5kYDpwXDmYvJhIhZ09Srk+5fR24BW4nbQpwXHlYPLiojlFDA7E0jOFAl+pKdFnwIKsHAAgQyArBwAwecjKweRxctXpLQDmDFk5mDxewXglAz1S3+kIWbkpQVYOJk/VJEerXK+UqlUjjmAxJcjKwfRx6nPQAcwYsnIweaqABVeFA/OGrBwAwOQhKwcAMHnIysHkyS04To6sXJ84Gb5PE4OsHEyeIp7ncZa5XvFKfJ8mBlk5mD6Ow4FzYOZwvXIweRzHc1Iv5X8snN2zd/tvjtaydb0NG1cxMD/IysHk8Uqc7QnmDlk5mDzV2Z4IWPRLJkt0a1MwcvpslVNWjnt7QgbQseY8e+bbu2/HWTP+mLdgurNz5lUrt47/eRj1pz7CCEeOHJw9d8qhA2fs7Owosuj5w4CQkOD1G1ba2tqWL1f5x8GjXF3dUn8LetUPPfq/fv3SZ/dWeovKlarTq2bOnnju3OlcuXJ37dyrQYMmwpjUh6b84qWfk5NzvnwFhw4ZmzWrB/WPjIycMeuXGzeu5MmTr0WzttoTj4+PX71m2cVLZ9+/f1esWKlWLdpXqlQt0QfgeZ7emv6QV69f5PbMU65cpV49B8rlcpZGSiXDCbQmBVk5mD6O6dQst7RU3XJow6ZVHdp3Gznil2+OvH37BplMtnfP8fVrfe7cvblu/Z8sDW+xbft6T0+vI/+c79N78D+H9w8f0a9unUZHj1ysXav+b/OnhYWH0WhXr12aNGU0lfUd2/6ePHF2QID/H4tmC1OYN38arQnm/bZ82q/z/J4/pcKtmfiixXN3+Wxp1bLDls0HataoO/nXMafPHE/0AXbv3rZp85q2bTpv23KwWbM2h/7eu237BgbSpc9STll5mTJlGEAG0KFlzql3kpYvV6ld2y6FCxX95vg5cuTq2qWXg70DNcapVf748QOWBvnzFWrerI2VlVWtmvXpadGiJaiIW1hY1K7VgJrVL1/4Uc81a5fXqF6HCi41yWmEQQNHXLx49uGj+x8/fjh56minjj2KFC7m4uLav99P1tY2wmRjYmKO/Huwc6cfaOJOjk6N/9eC1hAbNv6V6N1v3b5esGCRhg2b0jZB0yatli5ZV7FCVQbShawcTJ5qn6fuuW6B/IXTOmaBr2M6ODhGRISn5VXUJBc6hE1VLy9v4amtrR09hoWFMlXU86SQ1rqkYIEi9Pjw4T1//zfUkTt33q+DChYROmhFEhsbS2sUzaBSJctSZBQSGqL97sWKlbx27dLc36YePnKABuXInjNfvgIszSR/RJD0ICsHk0e7PdNx6wkra+s0jsmlq7AlepVMlvgjhoeHUxNb09wmFM0zVUoeERIarHqqLvoCWxvbL69SJTNDhvZONLVPQYHUSNc8pZa+nV2mc+dPz5n7K20K1KpVv3/fn9zcsrC0kmGnp2nBNVhACvRbdxRKBTM8GxtVEY+OjtL0iYhUbdS6urg5OTqrBsVEawZFRn7e3nVVl+ORI36m2Ed7au7uHtpPac1BuQr9e/782fXrl9dtWEkbEzOn/87ShueVaJebFhxXDiaPV1+xnH0HK0ur4JBPmqevXr1ghkeN5YIFCt+7d1vTR+jO653f2Skzddy9e6ugOtuJi4ujHaSUelN3zhye1urtidKlygmv+vQpiOd5oUWvceTIQcqF8uTx9vLKS/9oL+uhv/cwkC5k5WDyvr/9WLhwMUqoKXFm6qNKzp47xUTRqmUHei8fn62hYaE3bl5dtnxBmdLl8+crmCWLO4Xd69atoJUKhTDTZ/ysiWuoZP/Qoz/t57xz5yaF5qfPHB81ZtAfC2cnmvLxE4cnTRl9/vwZCsppV+p/Z08UK1qSgXQhKweTpz7b87silpYt2r98+bzfgC4KhaJO7QZdO/eaPXeKCLezaNCgyYeP77fv3Lhk2fysWT3Kla3Ut8+PwqDx46b+8ccs+kjUJG/UsFnj/7XQrGA6duju7V1gy7Z1lJxkymRftEiJkSMTH1I5csQvS5bO+3niCOp2cXGlpKVd264MpIvT4+91zpw59evXx/GIILK/Jvi5Zbeu1y07Az2JiuS3z/Ud8nt+BiYCWTmYPKWCF2U/pTnB2Z6mRp+lnLJyBwcHHMQCGUDcC4ZQTj1Bfa5/sjZt3Ovk5MwARISsHEwfr++jEb+lePFSW7YcSGmog70DAxAXjisHk6e+MqLYaQDqNRgVZOVg8tQn7uPkRH3iZDh138TguHIwfTJcM0TPeCXWjSYG9/YE06dEoxzMHbJyMHmcnNokaJaDWUNWDqaP/95rsEAiMr1ur4MIkJWDyVMqlTxDwqJPSob7XpsYZOVgksLDw//999/Jkyc3aNAgNiaOKVHKwawMSTJKAAAQAElEQVQhKwdTcu/evfNqz549q1KlStWqVX/66addc0NwkjmYOWTlYOyCg4MvXLhw7tw5esyRIwdV8OHDh5coUUIzgtwi1CLNt5KHNMLxnaYF12ABI3X79m2hfL9586Zy5crUAB81apSzczLXNrGw5uPicT0tfQoOjORkrGXLlpRfNWzY0Nvbm4Fx0+dFbocNG4ZrsMD3CAwMFBrgFKHkzZuXyjcV8aJFi6b+qiMb3r5+Et1+VF4GenJy+9sPb6Ib9LGkHRJHjhzhOI4KOpX1nDlzMjBKuF45ZLwbN24IDfAPHz4IDXBKUezt7dM+hRXjfEtUdypeLe23IYbUbJ7hW7WNa/GKmYWnvr6+VNCprDs5OTVUc3NzY2BMOB7nyUFGeP/+vaYBXqhQIaEBTh0svZaP8c3mbV23Yy4G3+HBxY9XjwU36Oaer4Rj0qG02/mImqenZ6NGjaidTpkqAyOgz1KOrBy+6erVq0L5Dg0N1TTAbW1tmT6smfg0Oorn5EwZn/w+O059NVyZTHVnhcSDuOTP/k/Un5YXTn2fTT7hIHUnl+xbckku9pX0A6inmGAK6rfgE9y4lPt8LV8uhWv6yjhe+eVQHuH/+C8jCx9Pu/vLm36dlIWV6iYe1LNiE5fSNVxYqq5fv3748GFqpxcrVkxop1tZWTHIOMjKweD8/f2pdgsVvGTJkkL5zpcvHzOA92+iHt8MVUandsIEz6n+Y+mjXReTDkgGd+XK5YKFCjlqt16TX28kKdEcr30rn+TeIEE/7b/rc7H+MkH1hLgvb6H1Kq335OW8R06rguV0u2kGbVoJ7XSap0KeziAjICsHQ7l06ZJQvqOjo4VjwOnR0tKSmRNavsqXL0/bIkzqTp06RQX96NGjwkEvNWvWZCAiZOWgT69fv9Y0wKmECeU7T548zFxRuExNnA0bNjDzQPVEOOiFVuRC8FKxYkUGhoesHL4X/YSE8k3b2kqlUtMAl8lwSSa2a9euJ0+ejB8/npkZ2hQTgpeHDx8KNb1UqVIMDAZZOaTT8+fPhUNQLl68KJRv2o3p6enJQMvUqVNp90CLFi2YuQoJCRFq+tu3byl7adSoUeHChRnoG67BAjqIj4/XNMAp9aba3aVLlyVLljBIwf379zt16sTMmJOTU3u19+/fU/YyY8aM8PBwnESqd8jK4duePn0qNMCvX7+uaYDnyJGDQapozUffFaXGDLS8evUKJ5HqHbJySB5lnZqLWNE8FY4Br1ChAoM0u3379u+//7527VoGydGcROrs7Cy003ESabohK4cEHj9+LFxF9t69e0L5pkcPDw8Gutu+ffuLFy/GjBnDIFV3794V2uk4iTTdkJUDi4iI0JxD7+LiQhFK//79y5Yty+D70OoQh+KlRTG1ESNGCCeRLl68mJ4KNR0nkaYRsnLz9eDBA6EB/uTJE8059NjC1aN27drNmTMnb15cslFn1LYQLgyAk0jTCFm5eQkNDdU0wCk2qaKGA34NgXY21K1bl75qBt8BJ5GmEbJys0BZpFC+X758qWmAZ86cmYHB3LhxY+nSpatWrWLw3XAS6TchK5esT58+aY4Bp71JVL5Hjx5NESQDUdy/f79IkSIM9EE4bJEIJ5GuX79+/PjxOIlUG7Jyqbl586aQgFPepTkG3NHRkYG4JkyYQGkA1RoGBqB9EqlQ0838JFJk5VLw8eNHzUWsChQoICTgOD06Y7Vq1WrhwoW4koGhvX//XqjpwkmkjRo1Ms/9zMjKTdi1a9eE/CQoKEhzESs7OzsGGY3KSpMmTU6fPs1ALMJJpIcPH5bJZGZ4EimychNDmz6aQ1Ao+Kby/euvv1JLnIExefDgAbaKRJYrV67easJJpIMHDzark0iRlZuGy5cvCw3wiIgIzSEo1tbWDIwS7ZejMPenn35ikHE0J5Hmzp1baKdL+CRSZOXG682bN5oGeJkyZYQdmLiYnEkYO3Zs/fr169Wrx8AIUBQpXOxFwieRIis3OpqLWMXFxWka4BYW+ozCwNCaN2++fPlyXDzS2GifREo1nVa3TCpwb0+j8PLlS00DvFKlSkID3MvLi4EJomilVatWJ06cYGCsTp06RTX92LFjkjmJFFl5hlEoFJryTfvchQY4YWDiLl68uHHjxqVLlzIwblI6iRRZudj8/PyEY8CvXr2qyU9w6X0pWbNmTVRU1ODBgxmYCM2dSB89eiS0003uJFJ9lvKpU6fWrVsX7cqU0KpuwIABlHoLx4DjIhJSNX369Dp16tBcZmBqgoODhXZ6aGgo7e0woaMY9XlPdGtra1tbWwYpoPCUdiTs2rVrxIgRqOMSRutsjuMYmCBnZ+f27duvXr26aNGiprW3Q5/HRYwdO5ZByqg9jiPBzQHN6Pj4eAamjLJi05qJ+myVU2MkIiKCQQqwhJsJzGgJMLmZqM9SPnv27OvXrzNIAZZwM4EZLQEmNxNxDRbxYAk3E5jREmDWpRxZeeqwhJsJzGgJoJkYExPDTAeycvFgCTcTmNESgKwcWXmKsISbCcxoCUBWjqw8RVjCzQRmtAQgK4cUYQk3E5jREmDWAQuy8tRhCTcTmNESgKwcWXmKsISbCcxoCTDrUo6sPHWWlpZxcXEMpA4zWgJMbiYiKxcPGmtmgmY0kkZTh6wcv+AUoZSbCcxoCUBWjqw8RVjCzQRmtATguHJk5SnCEm4mMKMlwORmIu7taXA9e/ak6Ekul9Mv48OHDx4eHjKZLDY29siRIwwkpE2bNlFRUbRA0SPNa2dnZ+pJ3cePH2dgIjp06BAWFsZxXExMTHh4uJubG3XTTDx27BgzbsjKDa5ly5b0m6Av5+PHj/SzCAgI8Pf3ZyA5+fLlo7lMa2ua3dHR0dT99u3bLFmyMDAd1apVCwwMpIU0ODiY1sc0E2lpdXR0ZEYPWbnBtWjRwtPTM9HWT/HixRlIC21+JbrdNm2kt23bloHp6NKlS+7cubX7KJXKmjVrMqOH48rF0KNHDzs7O81TFxeXzp07M5CWQoUKJbo1c44cOWhFzsB00LLZuHFjikM1fWj1bBLrY32W8rFjx5YpU4ZBEg0aNPD29qbVO3VT85yWeXxRktSxY0cq30I3Nclbt25taWnJwKS0b99eu2FetWpVzTw1ZsjKRdKrVy9hPxjlbrRrhYEUeXl5Va9eXeimjdRWrVoxMDW0AU3NcOGO6jQT27Vrx0wBsnKR1KhRg3aLKRSKAgUK0HqegUR17dqV2nS0f5s2xezt7RmYIGqYZ8+enTpKlSqVN29eZgr0eTDinDlz6tevL2Z0cOmfDw+uhMZGc3Exyf0VHMUZX5/J5EypEPrzjOdU/88x7b+eE8ZP2FP1QhlTRyOJx0z0lsLUPj9oj8k+96KvWskrZZyMlvMvr1W/X8IxE/UUPoz2ZD9/TI59HjfhB9B++ZfPT+/MJfij1N/A168n8SuYpTWztGF5iznUbO3OjJ7P4pefAmLj45gi/vNsZZ+/Sc1MV39hwpeo+u4TfBtfvweOfhZfB3HUzlF+/YKT/Dx41XzUno5M/atQ/VPSP5lMrn7Lz1NIOne+/vy+fIKvP1FhJK2f4pefXHK/jc9/V4KRNd00K61suILlMlVunJUZvZ1/vAz+GKeI4RXKJN/S10Xsy+8/ub+XyGWcQvllliZYRFRj0rzhGJfsC7+MoB4sLK208CdcNpK+JIXpJP6ZJTPml0KU0mSZKqZjcivmmt2y1UBPlioTPq78yEb/5/cjXLJaunjY8HxaNi80szVJ6dLgNYtsqtQzgOeUXJLppDRppWpJ51lqY6f2vtoj8l/K+DfH/DLhpD+TL2VJWB3wn8ufBlX/kI8xH97GunlYtR6Sixkr2sr5c5xfJkd5lpzWVnYW7PPyT4tIglmT8A9ULz8JF88vK0pevZ3KJ+r75WWMY9qrP5qKjGlV18SlXf0zUf9GtHp+Y45/7ZP4B8N/mWAy0+K+jpGETK4M8o/56B+bu6Dd/3pmZ8YqOkqxZpKfvbM8Sy5bCws5x6U45pfff4rLS4IFhE/4/Sf+MSQ7C5SaOZrotbpI8FtKwbdLDSfnosNi372Mio9l/Wd5pzamHks5ZeUODg7iHMSybd6L0E9xncbkY2BIO39/KreQ9fglDzM+VMeXj/ar1909Rx4TOOw3w22b+5QKZafRXsz4+L+I2r34Tevhnvb2VgySc/7vt363IgfMTrHimWRWfv3kx+APqONiaDfcOyZKeWKHMZ7TtO7XF15F7VDH06jjGO/QwPjL/35kxufAn28LV3BAHU9FlcbZXdytN8x4ntIIJnlc+d3zYc5ZcYyXSLJ62vjdM7oDk4I+hEdHKGu2Nd7EwAhlzmb58HIIMzKPbn2Kj+PLNzSBKD9jVWzuFhaU4mVhTPK48pgo3tHVmoEo3HLZxsXo83eiFy8exMstOAa6cHaziYk2ulkZ8CzWwtLoPpURcsliK+M4f7/IZIea5HHlcdFKPs5U99aaHI7JFTFKZmSU8ZwiFr8BHSllsVEKZmSUsTJaohmkgULBK2KTb8HguHIAM4INGanC9coBzAaX4PBKkBKTvLenTM7JZPhFikTGGePirzo0GD8BXXFaZ6cZDU7OZBbIytNENfM4wwcsomXlSgWvVCInFYmS55jxfdmq0yHwE9ARl8rJcRmHV9CeD2TlaaI+BziFc8GY/iArlyTVTwTtX0nglbhrmOlLYa2HrBy+QX1lXmZsZAhY0oEzyq9Mpr58DXwfE83KZRxmvliMM5VGwJYOFJQb43KjRFamg5SWRRPNylVXnmMgCuNNpbH864gWGiNcbngO+z3SSnWtLw7HlQOYN06munojMzKc6grMCMvSJPkr56qZZFbOCRefBjOWwuWdITVGuttThsVZD0wyK+exHIvIOLNy3kh34Rk3GS83whMylAzH1aQRn/Lv3iSzcvVaHPNeNMb4VdMPGnu+dab8ensdIyLjZXIGacGl3Io1yaycdnrqtBZ//fpl7brlrly9yEyBz+5tdetXYEaDN9ZThHTdgzfl17GjRg+ijmfPfOn3cOfOTWas/lg4u2fv9qmPk46/QrX+M8ZDODkDNcppUarXoCIT3clTR2nWBAd/Sn20lq3rbdi4iukopRaMSV6vXNqKFC7WrWsfZhi/Th339z/7GJglnme8Ea6WjfK4GqPFi3CKkGhZubQVLlyM/jHDePTofvnylXV6Ca52AmAkeD7F87z0WcrFu7en6qpA6aku8xfMOHhoj6urW43qdX4aMob6PHh4b9DgHsuWri9cqKgwTtduLatUqTlo4PA9e3ds3LRq7uwlP08cHhj4MXfuPCOH/0wbTbNmT4pXxJcvV3nE8AnOzpnpJX5+T/cf2HX9xpV379565c7buHHLFs3bCv179elAE9+yZe3Zc6eyZHGvXatBv75D5PLUokHaKly2fMHxo5eZuhFNf2m9uv+bPXdKVFRkkSLFB/QbKhT6ps1rdu7Uk0rzmf9O0HdeL/MprwAAEABJREFUvHjpCeOnOdg70KD/NanWo3u/jh26CxOc+9vUp08f/7liE2300dPf5k1bvuL3A/tOsTR+2ZLeJZX2uZwSYS4vWbRm5arFt2/f8MiarWPHHqVLlZs4eRQle4UKFR3y4+hCBYsII9MG9ZF/D378+N7d3aNUybLDh41X39OdRUZGzpj1y40bV/LkydeiWVvt6QcFBdLv4e69W9HR0bQa7t61T65cuVm6GGnAovvZnsJyUblS9d/mT6OlqVDBolMmz9m7b+f6DSsdHZ0aNmg6oP/QtJcICjp+6NGfZpbP7q00r2myPw4eNXP2xHPnTtNX3bVzrwYNmghjUh96ixcv/ZycnPPlKzh0yNisWT2EQSv+XPjv0UN2tnZ16zbKmTPBDDp85MD+Az5+fr40c+vUbtCmdad0H7Gjvoe8hK7Bkr4PvXbdihIlyiyYv6J9u660AJ84+W/q41taWoaHh63b8Oe8ucuo8MXFxc2cPemfw/tX/bVt88Z9d+7e3L5jozDm0mXzr1y5MPSnsbNnLaI6vnDRnIuXzglTYKr1x3Sau/8evvDz+Ok7dm6iHI2lmYWFxb37t48e+3vF8o3/HDprbWU9a85kYZBcbrFz1+amTVufOHaFKtHLl88XL/kt9akd/lv1qUaPmpj2Os7Ut343xh2fetpWSPtcTmUK9Lhk6TxafdK8KFqs5F+rFlPYPXbMlCP/nKdZtmjxXGFM+gXu3bdjYP9hu3Ye6d1r0KnTR2kOCoPmzZ9GpWTeb8un/TrP7/nTi5fOCv0VCsXwkf1v3ro2fNiENau2Z3Z2oZbHm7evWboYacDC6XyhU1ouaN1G/3Zu/2fFso3UMXR4X6VScXD/6cmTZtNSdkm9AKYRzcFt29d7enrR/OrTezDN/eEj+tWt0+jokYu1a9WntUVYeBiNdvXapUlTRlNZ37Ht78kTZwcE+P+xaLYwhX37d+3bv5MqwLJlG7Jly7Fh41+aiR87fnjO3F8L5C+0ZdN+mvguny1Lls1n30GMI1hEy8rVuz11/kVSQ6l+vf/RI5VyWpfeuXPjmy+hBZuWT1oz29raVqxQ1d//DTWj6LUuLq7UpKKmrjDaxImzfvttWZnS5Wni1B4vWKDw5SvnNROpWaNerZr16OdSsmSZ7NlyPH78gOkiKjJy9KhJ9EL6+dLP69WrF9SCEwbl8y5QvlwlWsNTa53e99Spo/SBmXnQ4+oljXM5dbS2ph8AzYtaNepFREQ0b96W9nnQLKtRo66v7yP6uVI52LptPe0FqVatFm080U+iVcsOmzavpnf/+PEDreA7dexBL6E37d/vJ2trG2GytFeTVtK0vVWxQhUaNHDAMEcnZx+fLSydOGM8glvBK+J1npuxsbHUdqbWMW1I5c2Tj9rmPX8YYGdnR8sgtayfPnui09Ty5yvUvFkbKyurWjXr09OiRUtQEafZR5vR8fHxL1/4Uc81a5fT1nzbNp3pTWmEQQNHXLx49uGj+zRo955ttJjXrFHX0cGxUcNm9EvQTPnvv/eWKFF62NBxmTO7UP+ePQbs3bvj06cgll5iHMEi2r09GUvPdmLxYqU03U6OzjExMWl5FQUmQgf9Smhm0OIkPLW1tQuPCP88Es/v3r2t+w9tKMGgfzR3g7VmVYEChTXd9vYO4eo1fNrl8vSit9a8nB7DwkKFp7SJpxktR/ZcVBTepre9ZnL0e1xNmuZyqnLl8hI6Mtnb0yMVl89TsLGl+UJ1h9bB1KG9F4R+GOHh4W/evKKVBz3N/eUzkIJfAhnaLKBGgKY0UCGmtcut2+nd9pUZZVbGpeccgRw5cgnbQ8TWzs5L69vLZJdJ16WMmuSfX6tujHp5eX+esq1q0ROWuGfPnhT6EsOSggVU8+jhw3u0nqaZ6OX19QNoFnmlUklbDBTTaQaVLl2eet5OQztSV6aZlbP0bCfKLdLzx2q3YpJt0dCMGTdhKC2tffv8WKpUOWpwDRnaW3sEIQxNt1Rermm7ERtbW3qMSFvd0Y1R7vbk9Hq4+zfn8jclmk1J51pQ0Ed6tNGaZUKZoF0gIaHB1GFna/d1kI2t0EEliVYAwk4OjdSz+9QomTGeXMen50N98wvXSaKZnnRqtNKlxp/2Eic0sCIjaRssgnIwW63ZZ/Nl9tEqnGbf6jXL6J/21NLdKk/le9JnKaesvE2bNtWrV2emjHZ26TT+4ycPac0877dlZct8PhicFr8sbu7M8LQLd3RUFNP6DWlTKL/rzrwy3hivXGeM91BIVaZMqtZ6VHSUpg9VAXp0cXGjTXjqiI6JTjSI0C56in1mTP9de1LydJ9RIzPK69yawkVubWxURTxaa/ZFqOeRq4sbNV4p3onRmn20eta8iip+g/pNKGfTnlr2bDlZuqQy80zyGiyqnSR6mvm0V4ppffW07qXgUpcJsJAQVZNKU7ufP39G//J82UAzqFu3rmm6n/g+omiPtjqp28rKWvMXEdq0Z99BSYua8V3tyOQOkfT2LkAL/L17tzTHSj14cJe24bJkcRfagHfv3iqo3jCndhztYROa3vSqqKgod3ePHNk/L/xv/d84O6W/VW6Ep8hTUmb812ChhYvmzr17tzV9hO683vnpw2fNmk31tN3nQZq91kw9B2k3CSX4wlOauZSnubtnZekmwm5P0bJy1d3g9HRSAe3sosXp73/20U+cGkez5052cHDUaQoU0tFs3r5jY2hYqHAYCe2KfBfgzwzvw8f3O3dtpo07et+Dh3bXrt3A2lq1ZqK9oKfPHKfVEnVv3LT648f3wvg0lArH1asXb9y8KrQETZipXRiVdojVr9d40+Y158+foZ/Kv/8e2rN3e9u2XaiO00wpVqzkunUraKVLW/HTZ/ysKW20qVehQpV586YFBLyjRsPefTsHDOx2+PB+JiE8LzOJ+zvSbuqz5075+Gyl2UdL0LLlC2gfRn71/iraR3rmvxPCwWm0c/v+/TuaV/Xt/eO5c6eowlASSzuxp04bP2LUAApeWLqJsNtTtGuw6BHtOZk4cRYlJHXqle/UpRntv86WLYdOLZesWT1+njD9/oM7LVrWmfDL8D69Bzdv3pYaXD16tmUG1rRJK2oL1GtQkd4rt2eeIT+OFvrTnn2XzK7NWtSq37ASbffVrdNI85IunXtdv3Fl4qSRadzra7RM8Vj3wYNGVq1Sc9qMCW3aNti8dW3nTj07d/pBGDR+3FTaI9pvQJcmzWpQY6Lx/1pofoSzZvxRs2a9qdPHt2xdb/eebfXq/a91644sXTjjvAYhb4xHSCbVoEGT3r0Gbd+5kZb0OXOnlCheetLEWcKgrl16N2nckppxtFfjwsX/Bg0cwdjnDaDixUutXLH59u0brdrUHzVmEIWi06ctEJpc+qXPi14OGzZMnKx82Sjf3IUy1WiXjZmxFq3qtmndqXs3Q53ir3H3fMj1ox8GL8jHjMm1EyEXD3zoPsW4PpWRu7D/w5ObIYPnG9eXdmr7h3uXQrpPxqz8tvVTfFsOyJGzYDK7xHBvT/gGzkQaTfBtUjnb02ylcpFbk7wGC6c6N8yEZ/6Wreu2bl2X7KDcXnmXLFrDjInSKHcvykS8TaVpza9U0HdmjDPTwJfTooR6ws/DUhq6aeNeJydnZiJUF7llEroGC6/aSWLC11Jr2aJ9wwZNkx1kkeaD3/ftOc7MmJLnRLucnl7mlzFQHcBtfEew8DLDrpUprV63dldKQ02ojn8mwg3hRDuuXEb7bkx5i8xOjcF3UN17RKwGJuaXQXFKg6+VXV3dmNSZZFauugYLLnBs3ozzhhiQHpwxnrdkcnC9cvgGjhnlyTgitsrBsLBbXR/M/bhy+Cb1FTKM8GBktMrTw0hXf5iVaSfC2Z6iXa9cLtf5AsfwHThjvPsE7m2ULsZ45XkOi7MuRLiLkGhZuULBm8SZvmBApnbivjEwzrsIqfZ8YXFOO6Xhj2BBVi5ZRniRW2TlujPSuwjhFCF9QFYOaWCE17hGVi4ZBj5FyEyYZFYOANLBGeVFvkyNSWblNOON7wLaksXzCiNs/vJKY/xURo7jFEZ5EyHjvDaEUaKATJb8nWRMMiu3ssFKXDxx0QorG2ZsbOyYhRUDncTG0/dmdIuOlR0nt2SQFjILlskx+XtImWRW7pBZ/jEgmoEo3r2ItLE3ut1Sxaq4KBQsNOg7LuFvfj6+jbTPnN6byRlMyep28bHYxPq2B5cCqQ3rktU22aEmmZW3H5E7PPC77lcJaRfkH1er7Xfcv8pgXD0sT2x9yyDNIgKVrftnZ0bG3smeGmeH/vqu2xaag3vnQ3PkT3EDWZ+lXMzrldfr4r5puu/rp2EMDObDu6gN03wr/c/Vs6AxXoa+46jcFpZs5x++DL7lzbNQWl7qdHSzsjfGWKr7L3liopR7VzxjkIKtc32z5LRq3i/F+ztzRnjRyzR6ejvsyMYACwuK/+TadzdT7RT98kepr6HIKxSJh3KqS3gIN23ntcf/PA4TznDktV/FvtzhidM6Nk8ukymUyi8v+vKmMk5zyoOmWzWFL1PU7vn1oybsqf0ZvnzaBG+jea2mQy7jFMpEf4jqhXI5p0i4j1DzFnySDyywtJLFxsTFx7JKTZzL1DLqq8ptmO4XEaqwtFHdhz7Z+5XSb0CZ5h/5529GeOQ/355a+/vXjMZYglsec0mO2BS+dvVsT/6TJJoLiT+J+k059Tsp+cS/Us2kZJzqlBHtiSQa09JSFhMVRz/Sup3dC5TS7b61Ils39VlUmJIWZ/qz4hWJFyuW8Icqt5Ap4lXjCN9woh85PY1XfD02IpV5Icxl7cVTKAxay9fnVyUYh32dTqKj9akiaX6HwqfXvFD7A1hacnFxWhMT5rbw12r90RZWnDJOGRulzJzNsuPI3Cxl+izlol2vXNvJXf7BAfFREYmXkM/dMvquZQrF18NWky7YnIzjlUlKuSzBsa6c+uJtyiRHv2p+Twl7cor4rx9AmI56LnEfPn5wdXWVyT9f1VM99Mvs04yp7hAuYpV05nz9YWlNWeiTtCILLCy4+Hjt/kJd+PqL4WSJD+y1tmFOWSzrdTKNW+69ehxx83RQZASvSC45T2b+fi2hXJKR1V/+5y8kpTIrzM3PS2nSJSguLo52Grm6OlMbQnvp5ZL8qLTnQkpvRG9Bs5VL+GNI9GtJ9BLtMa1tuMzZLOqYyN0TH90MeXQpPDpcGf+1Ln+dTVotp69L2Zf2CtNusdFTZTzT1HJhaMJ5oflVCO05rS9NfasenlcGBX5ydXPVKuUsQbH/PB1a0yZY01tYcvFxiRten1cPWjPL0oqLi9VuCnCf1whcghpFo9k6yCs2zpwlW/IR+dcpmOK9PU1XpUqV/vvvP0tL7LCXsqtXr/71119//vknA5NFDdPevXsfOnSImQjc21NU8fHxpnXfGUgHzGUJMLmZiGuwiEehUMhkMpzYJnko5RJgcjMR12ARD0WoiFbMAWa0BJh1Kcc1WNu6ZAQAABAASURBVFKHxpqZwIyWALMOWJCVpw5LuJnAjJYAZOWQIizhZgIzWgKQlSMrTxGWcDOBrFwCTG4mIisXD0q5mcCMlgBk5cjKU4Ql3ExgRksAsnJIEZZwM4EZLQHIypGVpwhLuJnAjJYAHFeOrDxF2BtmJjCjJcCsd3siK08dGmtmAjNaApCVQ4qwhJsJzGgJQFaOrDxFWMLNBGa0BCArR1aeIkSoZgIzWgJMbibiuHLxoLFmJjCjJQBZOaQIS7iZwIyWAGTlyMpThCXcTGBGSwCycmTlKUKEaiYwoyUAWTmy8hShsWYmMKMlAFk5pAhLuJnAjJYAsw5Y/P39kZWnQi6Xv379mvYoMJA0mtEIWExaYGDg8+fP7ezsmOnQ52pnzpw5bdq0qV69OoPktG3blkp57969nZ2da9SoUbNmzUKFCjGQnJiYGJ7nGZgaquDHjh07evToy5cvW7Zs2aJFC2Y6kJWLapjaw4cPz5w5M23atODgYKGmV6pUiYFU0IY5bZ4zMBFBQUFUvqmIv3jxol69eoMHDy5dujQzNRyaDxmIwhaq6adPn75586ZQ02vVqmVjY8PAlI0cObJZs2Y0KxkYMargQhucspT69etTES9TpgwzWfos5VSYHBwc0DBPh+joaKGmkxIlSlBZp0Lg4eHBwASNHTtWKA0MjI92Bad5RHPKpCu4hj4DltmzZyMrTx9qiTdQo+5Lly5RWe/Tp4+jo6NQ0xGpmxYELEbo06dPQori5+dHFXzgwIHSqOAayMqNTkW10aNHP3r0iGr69OnTqR0h1HRE6iYBpdx4UAUX2uDPnj2jBnj//v3Lli3LpAhZuQkICAgQ4pfr16/X/MLW1paBUaId2sWLF2/ZsiWDDBIcHCy0wZ8+fSqkKFKt4BrIyk1JTEwMFXQq66dOnaJiIdR02hhiYExmzZqVP3/+tm3bMhAXVXChDe7r61tfTfIVXANZuSmxtrbWROqXL1+mmt63b19afQo1vXDhwgyMAAIWkWlXcGqD9+vXz3wquAayclNVQW3UqFGPHz+mmj5jxozAwEChpleuXJlBxrG0tIyLi2NgYKjg2pCVS8f79++FwxmvXbumidRN6+RjaViyZAm1aXr27MnAAKiCHz9+/N9//xUqOKUo5cqVY2YPWbkExcbGnv6iaNGiQk3Pnj07A1GsWLFCLpdT9sVAf0JCQoQ2+JMnT+rWrUsxIyq4Nn2W8mHDhiErNzZXrlwRajqtYmvVqlWjRo0iRYowMKTVq1fTDupBgwYx+G6aCk5BotAGL1++PIMkkJVLXHk1itSpLUMFfdasWR8+fBBqepUqVRgYAO32xCVCv1OiCt67d29U8NQhKzc7VMqFdjo12IWaTvEL1sF6tHnz5oCAgBEjRjDQUWhoqHA8+KNHj9AG1wmycvMVFxenidQpdaGCTmU9R44cDL7P9u3bX7x4MWbMGAZpQxVcaIM/fPhQuHxNhQoVGOgCx5WbL0tLy3pq1H316tVTp04NHDjQzs5OqOm0v5RBuuC48jQKCwsT2uAPHjyg32HPnj1RwdNNn63yOXPmSOYyY2bL19eXavqZM2fev38v1PSqVasySJt27drFxsZShaItHmdnZ4VCQR1UrRho0VTw+/fvC23wihUrMvg+yMoheR8/fhRq+uXLl4XDGams29vbM0jBgAED6LuSyRLcZNHLy2vXrl0M1BVcSFFQwQ0BWTl8A2UFVNOFa78UKlRIqOk5c+ZkkNCFCxcmTZr06dMnTR9KWvr169erVy9mxsLDw4+qUQUX9mSighsCjisHHVCkLtR0GxsboaYXK1aMwRfDhw+nL4fjOOGpp6fn6tWrM2fOzMwPVXBqg//777/37t0TrmyFCm5QOK4cdFBObeTIkRSpU03/7bffaFNMiF8QqRPacXf37l2hYU4FvVatWuZWx4UKTm1w+h6oDd6jRw9UcHEgK4fvQpG6cDjjpUuXNBd+MedIffTo0SdOnKA6nitXriVLlpjJwZ2JKji1wXGbFJEhKwf9oEhdqOmUMBQoUECo6WYYqT969GjEiBH+/v5t27adMGECkzSq4MKVrVDBMxyyctC/a9euCTXdyspKqOnGE6lfPfrB91ZkbDQfG6P65ctknFKp6qB2tLAsyOWcQpGgj0zOKdV9LCxl8XFK7UGaKcg4TsnzQv+IiPC4uHhHR0eZClMqv76L5rWaPtTB858nxqkwzZgCuQWniE/Qx9qWObpZtuiXYavJiIgIoQ1+584d4cpWqOAZDseVgwE9ffpUqOlv374Vanq1atVYxlk31S8mUmHnbGFlKY+LVddrGeOV6mG0q/JLPf1SWb/0+TKOzEKmjBdKOdMsN5+HCiOrHzmqzlSOE/T58i4s4Tjql9PTL2/IJV0i5TJOkbC4W1gqI8P4qAhFgy7u+Us7MrFoKvjt27eFNjiujG88kJWDGAIDA4X45cKFC5pIneI4JqKNs/yUCtZ6SB4mCVFRsbsWvKzQIHO5eq7MkIQKTm7duoUKbrSQlYOoFAqF5sIv+fPnF2o67SFkBrZtwYv4KL7Fj15MQujL3DTdb+BveeRyOdO3yMhI4ZxMoYITXErTmCErhwxz/fp1oaZbWlpSQa9Vq5bhIvXlY3yrtcnqVUjU7QAR7PrDz9nNotVgva0LqYILKcrNmzeFczJRwU0CjiuHDFNGbfjw4c+ePaOCPm/evDdv3gg1Xb+R+ofXURStSK+Ok0zOViEfYtl3i4qKEtrgN27coPLdqVOnxYsXMzAdyMrBiAQFBQnt9HPnzgk1vUaNGo6O37tnL+B57M4/Xvb4NR+TnCNr3wa+i+4/Oy9LF6rgQhuctpCENjhO9TJR+myVIyuH7+Ti4tJKTalUCjV9/vz53t7eVNPFidTNhHYFp/LdoUOHRYsWMTBluF45GCOZTFZbjbppk59q+pAhQywsLISaXrx4cQYpOHDgwMKFC6lSJx0UHR0tXNkKFVx6kJWDsSutRjvV/fz8hHb669evhZqeUrtBuJHYzJkzmZl5+fLln3/+GRwc3Lx58/379ws9qYILV7a6du0afTOo4JKkz1I+duxYBmAwedR++OGHT58+UU338fGhXaZCTSfakXpgYCC1PePj4+fOncskjWc896X70qVLM2bMoJyTqU+pFyo4fQ9Xr15FG1zycFw5mDD69VJNFy6nTpG6UNM9PT3Lli2rPgmeq1ChwtKlSyW82/PoxrdB72L6TM9z5swZWm8JdVxgbW0tnNGTsWfYgjhwXDlIxM2bN4WaTvGL9q+6TJky0yYskfYRLBU7hk6bNu3Fixfag7Jnz67JWEDyZEx/kJVDBipVqhQ1Jvbs2aO584OA4oWp06Yy6VLEx//000+J6jhTn3DPwGwgKwepUSgUiar5w4cPC5dn0sTxFpbyBg0avHnzxt/fn/5w2kMQGhoaFhZGOwwYmA0cVw6S0rhxY/U1Y3knJyf6Kcpkspw5c7o7FmTRTJp4yki5X375RXhG1fzt27cBAQHUkbSdDhKG48pBUrJkyUJJS9GiRb28vHKqyeXyDy9it/1uFnUtmxoD84PjykFS1q9fn7Sn+uLhHJMkGc9J9C8DnSArBzBlqttW4DJKoNcjWCgrx05zMELpa7Zu2LiqbftGDRql5zYLz5751q5b7vbtG8zQVGcIoVkOei3llJVfv36dARiZdLRaY2Ji1q5bUa5cpbmzlzDdOTtn7t6tj7u7BwMQBbJygGRERUXSY8UKVUuVKst05+Li2vOHAQxALPpslVNWjns0gwS8fPm8VZv61DF12ngKWB48vEdpCT1qRujareWy5b8L3RcvnRs+ov//mlTr0q3lrDmTAwM/siQBy7lzp/v179Lwf1Xad2w84ZfhAQGfT6//deo4eovz5880b1mnfsNKQ4f3ffDgLtOFzILJLRCwALJygCQ8Pb32+ByljkkTZ/17+EIqYz5+8nD8hKGlS5dft2bXT0PGPH36eM7cKYnGuXrt0qQpoxs0aLJj29+TJ84OCPD/Y9FsYZCFhcW9+7ePHvt7xfKN/xw6a21lTSsDpgtewZQK7PYEZOUA3+HunZs2NjZdu/TKmtWjYoUq839b3qnTD4nGWbN2eY3qddq26ezk5Fy0aIlBA0dcvHj24aP7wtCoyMjRoyZlz5aDynrdOo1evXoRGRmZ5vdnvOoIFgagz1JepEgRe3t7BmBkZOna85kWxYqXio6OHv/zsJ27Nr9+84qKdelS5RKN8+zZk0KFimqeFixQhKmuJfA5rsnl6WVnZyd029ur7j4aFhbKAHSkz1Ler1+/0qVLMwAjozTYCUIF8heaPWuRm2uWlX8t7ta91ajRg+7evaU9Qnh4eExMjLW1jaaPULgjIz9HkTKZPpdBMFvIysEM6LtNHq+I13RTrjJ61MStmw+MGzMlNDRkws/D4uO/DqX4hanu4xOl6ROhLuKuLm5MHzg5k2NdAMjKAb6J9kayL4cnMnVD++PHD0L3zZvXLl0+Tx1ublkaNmw6eNDIsPCwdwH+mtdSAl6wQOF7925r+gjdeb3zM33glfQfA8D1ysEMfF+8kitXbgd7h7//2cfzPLW4Z8+d7ODw+eZzd+/dmvLrmAMHdwcHf7r/4O7uPduopntkTXBBq1YtO5w9d8rHZ2toWOiNm1eXLV9QpnT5/PkKMr1QXRmRAeAaLGAGvq/YWVpaTpw4a+GiOXXqladK3b/f0KCgQOHKJ+3bdaUivmTpvAW/z7SysqpTu+HvC1ZSS1z75Q0aNPnw8f32nRuXLJufNatHubKV+vb5kQHoFe7tCdIn4Xt7CjeE6z87LwPzhqwcwIRxFkwuZwC4BguAKVMw7PcEhqwczIGEb85A+aiSxzVYAMeVgxlQ7w9C0xWkDFk5mAGO4f4MIG3IysEMSLdFzsmYDLs9AVk5mAUJZ+VKplQwAGTlYAak2yrnsQ8A1JCVA5gwDvsAQA1ZOUifhA9GVN8QjgEgKwfpk/AFp5TxTOuCu2C+kJUDAJg8ZOUAACYPWTlIH2+pkOw1p+QKazscxALIysEMeOSw5WXs7bPw7Hmldhvx8E8KB2crBmYPWTmYBWd3iyuHPzDJiQiNb9gjMwOzh6wczELn0V5xcWz/Cj8mIZtn+pas4WjvJLVNDUgHZOVgLnpOyrNm8rMts3ydXK2sMlkoYxMMlcmYUpnkNdTUEXpyPOO5z08T9fyCk/G88vNTTs74L+fTa3d/HZlT3cCLk6kPlOQTTk3GM6X6vfjPfdT/pz4ZSD2mUs5HfoqNCFXUbOtWrJIzA9DvDeEAjN+Zfe9e3o+KjebjYhL0l8k5pSLBsiCcWKS9fKgqr/LzozBCgqFfnqqXKSXHfd7TKpdxiq93h+A/X6dRPbJ2Kde8/PMgrXcXXiNUf3pqY8fsM1s07O6C9jho4N6eAHp27dq1P//8c+XKlQxALMjKAfRMqVTKZPpcsgC+CVk5gJ4pFAo57p0M4sJx5QB6hlIO4sPZRkMsAAAQAElEQVRx5QB6hlIO4kNWDqBnyMpBfMjKAfQMrXIQH7JyAD1DKQfxISsH0DOUchAfsnIAPUNWDuJDVg6gZ/Hx8RYWuOEmiApZOYCeoVUO4kNWDqBnyMpBfMjKAfQMpRzEh6wcQM9QykF8yMoB9AxZOYgPWTmAnqFVDuJDVg6gZyjlID5k5QB6hlIO4kNWDqBnKOUgPmTlAHqGUg7iQ1YOoGco5SA+ZOUAeoZSDuJDVg6gZziuHMSXYikPDg5mOoqJiaHGSDquCefs7MwApAKtchBfimU3Pj6e6Sg8PNzW1pYBmDeUchCfPgMW+vlyHMcAzBtKOYhPn6Xc3t6eAZg9ZOUgPn3+4KgxwvM8AzBvuIsQiE+fpZyy8ri4uFRGOHPmTKNGjdKxQxXAhKBVDuJDVg6gZ8jKQXzIygH0DKUcxKdDKb9///7mzZsfPXrk5ORUsWLFrl272tnZUf8ZM2ZQY7xOnTrz58+PiooqVKhQnz596FF41apVq44fP25ra1urVq2cOXMyAKlDKQfxpTXRe/PmzYQJE6Kjo3///fdJkyb5+fmNHj1aOPac9vA8ePCA6jXV9B07dlhbW8+bN0941UG1QYMGLVy40MPDg9YEDEDqkJWD+NL6gzt58iSVbCriuXLlyp0797Bhw54+fXr+/HlhKDXGhw8fnj17dktLS2p9v379OjIykvrv27evupqDg0ODBg1KlSrFAKQOrXIQX1pLOaUrBQsWpGhFeJo1a9Zs2bLdvXtXeEr1ncIWysqplAuJeXh4OM/zb9++9fT01Ewkf/78DEDqUMpBfGnNyqk0P378uFGjRto9P336JHQIm5P0C9berqSGOfXRPpXfxsaGAUgdtWYQsIDI0lrKXVxcihYt2r17d+2ejo6O2k8TXYOF2unUNomJidH0oRyGAUgdNWLScQkjgO+R1lKeJ08e2rFZvHhxTXPjxYsXOXLk0B4n0XHl1O3u7k57RDV9Ll++zACkjhYE2h5lACJK62Zg69atab/8ihUroqOjaa/m6tWrBwwY8Pz5c+1xhKxcu0+NGjXOnj175swZ6t6xY8fDhw8ZgNRRc4cWFgYgorSWcgcHB6rjFHYPGTKkT58+t2/fHjZsWL58+bTHSXoNlk6dOlG8vnz5cnq8dOlSv379qCeu0wLSZmFhgYAFRMalVFg/fvzIdBQSEkJZuZWVFdORm5sbA5CKcePG1a1bt379+gxALLgGC4CeISsH8eEaLAB6hlIO4sP1ygH0DLs9QXyiXq8cwBygVQ7iQ1YOoGco5SA+ZOUAeoZSDuJLsZS7uroyHb17987BwSFTpkwMwIwhKwfxpZiVc7qbM2fOjRs3ON0xAAlBqxzEp8+AJVu2bGiSA6CUg/j0WcrHjh3LAMweSjmIT58HI1JWHhERwQDMG7JyEJ8+S/ns2bOvX7/OAMwbLqcF4tNnKUdWDsAQsEBGQFYOoGco5SA+ZOUAeoasHMSHrBxAz9AqB/HhuHIAPUMpB/EhKwfQMwQsID5k5QB6hlY5iA9ZOYCeoZSD+JCVA+gZSjmID1k5gJ4hKwfxISsH0DOcuA/iQ1YOoGdolYP4kJUD6EeXLl3u379PdZzneY7jjh49ytQLxcGDBxmAgemzVU5ZeZkyZRiAWerfv7+zszMVcarmwu2xqKaXL1+eARgesnIA/ahRo0bBggW1+1CTvHPnzgzA8JCVA+jNDz/8oH1/81KlSuXPn58BGB6uVw6gN5UqVdI0zD08PCg9ZwCiwHHlAPrUs2dPPz8/f3//YsWKFSlShAGIQrVnhukJZeUODg5omEPqzu5//+ldfHxcMoPUewq5lF5IAxL8WDme8bSTkfHKZCbCcUz4aatGUr30GxNXj8ASLg38l7dNMoiecFxKn+qp7zPaaZQnTx5HR4cki9fn0ZOd4OfPnXSayb5R8p85+dE0b6EZmvSFwos5xr5REmS8jS1XtLK9Z0FHBkZDn6V82LBhbdq0qV69OgNIzr2Ln87sDpTJmaWVPC46mR8eJ+N5ZQrVVuit9SKeU/2XtJQLxSyl/gk6Pk9HtVJQv3vCl2i9Y6JB/JeBLElN5GScUqnklbzqOJaUP0Myg7Qmm2yd/foSrc+v6fn1r+CSr8XCxDVDk/0AqkrPJdNfG80++hcTrbSz536Y7M3AOOC4chDJ4xuhJ3cG1myXxauwEwPTt2ex7/ppfj0m5mFgBPTZKgdIyYf34dvnvOsxKR8DCfl79YvoCCWquTHAceUghiNrP7hm0ecmIBiDxr1zh4cogt6FM8hoOK4cxBAZosia146B5FhZcTdOhTHIaMjKQQyx0YyTcwwkR6FgsTEMMhyOKwdxcJwSpVyKeIY5awyQlQNA+vE8w/V8jQGycgBIP06mOpSeQUZDVg4i4Tks8FLEM6bEAc0ZD1k5iITDGQxSRHMV89UYICsHMXy+jglIDs1VTp9VBNIJWTmIQdVwQ6tcqrDf0wggKwcxqFrk2DkmUTJsbxkBZOUgBh47xySK5qwC21tGAFk5iIGjiAWtckniGOarMUBWDmLgaXlHq1yKUMeNBLJyEAmHRFWSOE6GI1iMgD5nAmXlZcqUYQDJydjDHDZsXNW2faMGjSpTd4tWdelp0nGCgz/Vrlvu5KmjzLi16/C/VauXMn149syX/uTbt2+w9OKVvAJHsBgBfbbKcW9PSEUGniIUExOzdt2Khg2bNmrQjJ52aN+tSOHiDPSBtrWwE8QYICsH6YuKiqTHihWqlipVljo6d/pB6IDvp7qcFnaCGAFk5WCkQsNC//xz4d//7HNyci5XtmLfPkOyZvWg/pGRkQv+mHnz5tWwsFCv3Hn/978WLVu0o/5+fk979emwbOn6LVvWnj13KksW99q1GvTrO+T6jStjxv5II0ydNn7W7En/Hr5AAUub1p26d+tDPY+fOLJ27XJ6rypVanRo1037A9y7d3v9hpUPH95zcs5cuVL1Ht37CT/vX6eOo9y/Xt3/zZ47hVYSRYoUH9BvaOHCxYRXXbjw38LFcz58eJ/Pu0DLlu3/16i50P/wkQP7D/j4+fnmyZOvTu0G9AG+ufNAoVDs3LWZPgN102bEDz36Fy9eShhkYWG5e8/2FX/+YWVlVaxYqfHjpjo5qu6YGh8fv3rNsouXzr5//476t2rRvlKlaql/n9ood9qyde1ff27JlSs3SxtOzsmRlRsBZOVgjKgkjRv/08fADwvmrxjy4+j3HwLGTfiJetIg6nj79vW0qfN3bPu7Ro26CxfNefDwHvW3tLSkx/kLptet24jq9c/jp+/YuYmC7/LlKu3xUcXfkybOov7a70JJ8YyZvzRo0HTTxr0NGzRdvOQ3zaDXb16NGjMoOiZ6yeK1036d9+zZk+Ej+gkfwMLC4t7920eP/b1i+cZ/Dp21trKeNWey8Cqq4xMnj+rda/DsWYuqVas997epx44fpv70OGfurwXyF9qyaX+f3oN3+WxZsmz+N7+ElX8t3rdv59Rf5/0yYUaWLFnHjh/y8uVzYdDpM8ciIsLnzF48etSku3dv0tpI6L9o8VyaeKuWHbZsPlCzRt3Jv445feZ46t+nBn1IiqEm/jwz7XWc8Apk5UYBWTmIQX2lDh0iVWpXPnhwd/3aXZ6eXvSUigvV5aCgwGd+vnfu3FyzanuePN7Uv0vnnpcun6N26+yZC4UX1qxRr1bNetRRsmSZ7NlyPH78oF7dRim9y779O7O6ewjN89KlytH0b9y8Kgw6duwfSwtLKuLUhqWno0ZO7NSlGTX2hYlHRUZSDbWzU93irm6dRtQ8p20FekqlsEb1OvXr/Y/60yqEqm1kpOpMi7//3luiROlhQ8dRd+bMLj17DJg7b2rXzr2oO6XPFhIaQn8yvYSmQ08rVqxKkwoM+ih8IXZ2mbp17S2Mee786dt3VPstaZfAkX8PUnzUvFkbetr4fy3u3r21YeNfVNNT+j41b3fz5rU5c6f07/dT1ao1GZggfbbKV69efevWLQaQhOr6ebpEqk+fPqHKKNQdQu3ZXyZMd3fPSgGFjY2NUMe/DCr86NH9r08LFNZ029s7hIendtvJN29eeWlNqlChoprue/du0VOhjhMPj2zZs+cUKibJ5ekl1HHhXeiR0h6lUvn02RPtiQzoP5SqKvW/e+9W+XKVNf1Lly5PPTVTS9Zzv6faH4k2Bab++hutb4SnxYuV0ozp5OgcG6O6Jxutt2JjY7XfqFTJsrTlQWuFlL5P4enLV89/mTSC1kkdO3RnYJr02SqnXxstZgwgCWqQ87q0yqk9a22dzG8pMPCjjY2tdh+qUMJeTYFMl4OcQ0NDcub01Dy11ZoyrQMePrpfu2457fE/fWnGJvsu0dHRVKCTfmwqr3FxcRRh078EU/sUxFImrIRsrJNfoGhZ03RrMnfhJUOG9k40Mn3slL5PAYVUFLa4uLgyMFm4BguIgRrknC6tcgoQqEBTZUxUNCm+i46O0u4TERnh5pqFpYujoxOl4ZqnQhgicHF1o32MPX8YoD0+tX9TmZq1tTV9WiqaifpT+4bWNw3qN6FkX7t/9mw5U5lapkz2iT7SN7m6qb6HkSN+zpEjl3Z/d3ePlL5PAe0noOb//AUzypWrVKZ0eaYLTsZw/21jgGuwgDEqVLAINXIfPX4gPKXdfcNG9KOUoGABVf8nvo80Y1IErB2S6CRr1mz0cipwwtMLF//TDPLOm//9+3clS5ShTEP4l9nZRRNQJEsulxcsWOTO3ZuaPn+tWrJ02QLV1LwLhIWHaSZVrGhJVxc3Tb6RrHz5ClLT+9btz0f38jw/bsLQI0cOpvKSnDk8aXXC1Lm/8M8rd97cnnloRZLS9yk8pdVM0yatKOWnncCUxjBd8EqmwMGIRgDHlYMYVLs9dWm8UfOQmpYrVy767+zJK1cv/rFw9of3Ablz56lQoQpl1gsWzKD0g/baUWRBtTjRQYRpV6tW/eDgT4uX/EaFknZ47t27QzOobdsuVOKXLJtPFfDVqxd/rlzUq08H2uma+gRbNGt75cqF7Ts20tT27d+1ddt6Idbv2/vHc+dO/f3PPpom7badOm38iFEDKHhJZVL29vb16zXet2/nP4f309ToQ167dklzyGOyqGT/0KM/7eekt6CJnz5zfNSYQfTVsZS/T+2Xjxk9mVYes78cjQOmBceVgxhUuz11abxRTZk3d9msOZMmTR5NTytXrj5r5kIhIJ4+df6KP/8YNLiHlZVV3rz5p02dpznaWlfly1WiPZP79++qU6981qweP4+f/tOwPrz6rFRHB8fVq7Zv27a+/8Cu1Ial/GH0qIm0tzD1CTZs2DQ0LGT9hpW0eerq6tav75DG/2tB/ekTrlyxefOWtbRKoICoaJES06ctEFrQqRj601iquZR7KBSKfN4Fpk75LfXNAkL7LWkLYMu2ddevX6aIht5o5MhfWKrfpwYtvJMnzv7xp17nzp1O+3EsHK6MaBw4HtcaBsNbMuJpCXcIDQAAEABJREFUscpOZRu4MZCWTdOf5i6SqXFPDwYZClk5AKSfqlWOZrkR0GfAQll5mzZtqlevzgASws18k6JEe8LPw1IaumnjXs1R7cZMqeMZA2AgyMpBNGi8JaAK0FduSWmoSdRxJsxUNMuNAI4rB1HQPhm03ZLI5pGdAegDsnIQA48mOYAh4bhyEAOHG8JJFHZ7Gglk5SAGXh2xMJAgDitpY4CsHMSAVrlUqXaCYC+IEUBWDmJAqxzAoJCVgxh0vfUEmAqcuG8kkJWDGHicSCJRqjnLIOMhKwcAMHnIygEATB6ychCDlTUvs0CmKkGW1jK5JYMMh6wcxGBhyX0MiGIgObExiqyeqOUZD1k5iCFPsUxPbiJ8k5rb5wIt5KxUDdzfOeMhKwcx1G7vYWHFdizwZSAht05+qtzMhYER0OddhIYNG4brlUMqdi18GfwhPquXtUs2a45Lw1Y5xzRHunGqnyr3rbGSDuMZz2nG4FTHznGpTEL4/6Sjad4imUHqXuzLNXwTfRLtoSkNkqnudcwl82YJX5Vi99e3SPDZZJzqYuLUWFOyZP5clugP4dRfVZJPqD6zK8HfK5PxkaFxb/0iQj/Edxnv6eRqxcAIICsH8bQd6nl0q//LBxFvfKMVMSmW3y/VN2F1TK1gp4hXVyjtSpz8RBKNkMp7JVOStV7LUh6a2puq/+JkX5LqB1b/x6nu6ZHsX5fK35L0o6b04ZP2lHMWlry9k7z7RA97J9RxY4F7e4KxePv2bfbs2UeNGkWPQ4YMsbTEzrRvuHnz5rhx4w4fPszA7OmzlFNW7uDggIY56Ory5cujR4+ePXt25cqVGejiw4cPLi4uL168yJs3LwMzhuPKIWMoFIotW7YsWrSIuu3t7Q8dOoQ6ng5ZsmSRy+WxsbH9+/dXKpUMzJU+SzmyckiL8+fP0+OjR4/8/f3bt29P3UWKFKFqziC9ChUq1K9fP2pIxcTEMDBLyMpBJFRlrK2tGzduXLFixcmTJzMwgODg4GXLlk2YMIGBmUFWDgZ3+vTpP//8c+7cuTlz5gwPD0cD3KB8fHyio6O7dOnCwJwgKwdDOXPmzLlz56gjKCiImuFUx5k6FmdgSG3atGnWrBl17N+/n4HZQFYOehYQEECPO3fu3LNnj5eXF3W3atWqYMGCDMTi6OhIjx8/flywYAED84CsHPSGgtqhQ4cWLVp0zJgxtI1vY2PDIEPdu3ePZsfTp0+9vb0ZSBqycvhely5dOnz4MEUo1B7/8OFDsWLFGBiTrVu3vn79evTo0QykC1k5pJOfnx9twlPH7t27a9asSR1Zs2ZFHTdCnTp1ypUrl0KhiIrCdYYlC1k56IYqAj0uWbKEWnlyuZy658yZU6tWLQZGrGPHjjSzLl++vGvXLgZShKwc0ooCtIULF5YoUYJaea9evaKGHgNTM2vWrLZt2+bPn5+BtCArh294/vz53bt3mzZteubMGdqZ2aBBAwamjPZOx8bG0mytUKECA6lAVg7JE9bxtLts5MiRtra21F2jRg3UcQlwdnZ2d3dfu3bthQsXGEgFsnJIxty5c6tVq0Ydbm5uPj4+devWZSAty5cvF9bQQUFBDEwfsnL4jBbp7du3165du1ChQsePH0f5NhO9e/f+4YcfcPMvU4d7e5o7pVL55MkT6li9erWlpaVwLgnquPmg+f7s2TMGJg5ZuVmj+VWxYsX3799T9+jRo/v06YN795ihHj16MPVBpTdu3GBgmpCVm534+PgVK1b8/PPPTH3jgitXrlStWpWB2RsxYsTSpUtx/woThazcjBw8eLBp06b+/v7U0aZNGxcXFwaQEBWE8+fPFylSJHPmzAxMB7Jy6QsLC6PHJk2aCJvPtPHUt29f1HFIFsdxxYsXb9eunXBVBjAVyMql7MyZM82bN6dmOHUfOnRo4sSJDOBbHB0djx07FqLGwEQgK5egf/75hwo3U18vZfny5QUKFGAAOvL29ra2tq5Vq5awVxyMHLJy6fD19c2XLx8V8QsXLgwYMEC4aw+YOtoPmYG5ZWxs7MuXL+l3xSTNysqK1lvMlOEaLFJAi3rXrl0rV648ZswYmqEUdzKQCtq0+vTpE8tooaGhtHRL9adlY2Nj6rcqRFZuwigKHzRoEC3qVL4XLlxIdZypd1sxAH2zs7Ojas7AWCErNz23b99+/vw5dVy9erVHjx5yuZwaFJ6engzAYCwsLJycnKgjOjqagfFBVm4yIiMjqWX0559/Xrx4ce7cuVmyZGFgBowkYNGIi4uj5rmrqyuTEAQsCeC4cgOhL/bHH3/ctm0bdbdr127t2rWo4+asQ4cOW7ZsYRnE0tJSOHsoPj4+jS85f/48JYGNGjW6f//+9OnTx40bl+xo/fv3X7JkCYN0QVZuvOh3v2nTJup4//59ly5devXqRd04tQcynEz2uW4EBwenZfydO3cy9TVecufOXa1atTp16jDQNwumP8jK9YIWD9rWCw8PnzVr1g8//EB9SpQowQCMDKXntLxT3kIdqe9sp2ywePHiJUuWpG7cBtZA9FnKx44dy+D7UMvl33//PXz4MFXzjRs3MoBUUZVcvHjxrVu3aN1Pu74bNmzYrFmzQ4cO0T6V3bt3U5GlcRYtWvT333+vWLHCy8uLqc/7/euvv3bt2iUMTRYF9PTyzZs3U3ehQoW6du1arFgxYRBlO0ePHg0MDKSUjxoZQ4YMof1t9O59+vTp1q0bxei0KUnRc9myZQcMGEB7Sps2bUqvevHixcGDBxcsWECTpZFpC17oOW/evFevXtF0OnfurP0BgoKCVq5cSRumMTExNCkaKpwnsX///q1bt9K+Igpq6OV58uRp1aqV5uZWNKmFCxfevXuXmpVVq1bt3r27lZUVU2/g0t/y6NEj+jwVK1akP4d2OzFpQVae8eh7o58m5YnUXb9+/ePHj1McmcpiBqAxceJEf3//yZMn04qfsoulS5dSwSpdunRsbKyvr68wzr1799zd3R88eCA8pbpWpkyZ1H9ga9asocpLE6f2GZXsX375haok9d+wYcOBAwf69u1LBb1Hjx5nzpyh0kx5C/1i5XI5rR6oe8eOHbSqoDelmk7vQu0SylWooFNHkSJFNG9BzXmaLE2cSnbv3r3ptZr7GdGKhN739u3btJ5Yvny5s7Pz0KFD3759y9RJPa0Jli1bNmzYsH/++ad69eq///67cD5qQEDA8OHDixYtSuuJtm3bnjx5kkaj/m/evJkwYUJ0dDSNOWnSJD8/v9GjR6c96DcVyMozTEhIiPB1UTOcfuvUWKBuWsYYQNpcvnyZKiYVtYIFC1J7s2PHjlTIqIBmz55dU7s/ffr08uXLunXrUltVeBW9pFSpUqlMllrWPj4+tIOdmsOVK1emMkodVGephlLq3alTpypVqtBWY40aNZo3b05tZCrK1AynjIXet2XLljTI1dWVXiLc0iQl586d+/DhA+3qpI9Kv3/aL0rT13xCWnOMGTOmfPnytHOI1hyOjo579+4VhtLb0a6jwoUL0zvWq1ePtgmePn1K/ffs2WNtbU0tcfrrmjRpQmsa4eL7VNNpjUJFPFeuXPRG9HXR+ELLSUpwXHnGoOWKNgyFjRj68XXo0IEaNQxAF8+fP6caKsQmgvz58wsFlBrm1Ppm6l+at7c3VTehsn/8+JG2AlNvMVBwQY+0ehCeUh2k5jkl3a9fv6YySnmL9tvRb1hoLwtPlUqlUJEdHBwo/EnlXehV9OGzZs0qPKWSrTkui0o5VWHN+oZKNiUwd+7c0bxW89mEIwiFd6Tmdr58+TTLEaUugwcPZuqtEGFVJ/Snd6RKpVmxSQaycrHRskRbgh4eHidOnGAA34FaylQNtfvY2tpGRUVRB9VBiiaogyogxdxUf+lXR789Si2oYqZ+fR6hMia9JokQgGj3F270LLyjgDLoNGYX1PYXXq6hmTJ9AFpnNGrUSHsoxSya7mT3stJKRVOvWcI/5/Hjx4mmZlSH6uuFPks5rsGSFrSH6siRIxSOM4DvQ3Uz0bmX1BAWTt6hfINqJS2S1PykfYZUJQsUKHBPLfV0hQiLcNI2tdBf+x2FcRIdIEvtYirE7FsoM9FeB2i/I02QVlG//vprosmyb33sZLcDaGqUO9G2b6J3Z9KCrFxs1CaiHxYD+G5UnamwanZvEtrnSXEwU5eqvHnzXrx48dmzZ8WLF6c+9Kujsn7jxg2q8qlPlgIZClU0gQaF0RSwHD16lCZI9VTIbTRvRxGHm5ub9supVZ6Wwx8oIqcPT6mI8JTy68DAQKGb3ogG0ZJS8gsamXqyb30b9Nk02wSnTp0aP3487UHNkycPhfLC0ZACauBTbs6kBVm52Cj1E+6KC/CdypUrRwvdokWLKECg9GPdunUPHz5s06aNMJRa3/v27aPKLsQORYoUuXLlCiXUFKOnPllaiuvUqXPw4EHafKSNSApqaAVAEQ1tc1P/bdu20RoiLCzs2LFj+/fvb926teaMIQE9TcvxV7RD1crKauHChVS1qYjPmjVL01KmT0h/2h9//PH+/fuQkJADBw789NNPtC5JfYIUodDWAH0b1KCkfapr1qyhDRRa99AnpAR/xYoV9EYU969evXrAgAHCVYykBFm52ISsHA1z+H5UMSdPnrxq1aqhQ4dSWaTm56RJkzQHgFMp3717d5MmTYSn9JOjvIVa3MkGyonQDsMlS5ZQWaRWLTWHqVUuNGOpCFKlpu1vavzSWoR217dr1y7Ra4Xru33zLWiFQREKFVZa91D+07t3b+29R1OnTj106BDVd9pbS8l+7dq1W7RokfoEc+TIMW3aNFoB/PvvvzTBevXq9ezZk6l3wFId37Fjx5AhQ169ekW7QIcNGya9K7DjeuViO378OLJySDtju5zWN1FJoUIvHAhoKnA5rQSQlacFsnKQNlr3aI4QB9HgGixiK6HGADIO7f+kZCaloZQypyWESUkas3LQL1yvXGzIykEnBgpYKA5NaZCHhwczMxIIWHBcudhwXDkYA8PVa1PMyiUAWbnYkJWDtCmVyrCwMAbiQlYuNmTlIG0cx6FJLj5k5WJDVg66onYuA0Pi1JgpQ1YuNmTloKtEp1MaOQrKb9y4Ub58eQYiQlYuNmTlIG1RUVGjR49mIC5k5WJDVg7SZmVlVa5cOQbiQlYuNmTlAKB3uLen2CgrX79+PQOQKGodnjt3joG4kJWLDVk5SBuV8mHDhjEQF7JysSErB2mTyWRVq1ZlIC5k5WJDVg4AeoesXGzIykHyKCvHaU0iQ1YuNmTlIHljx46NiYlhICJk5WJDVg6SV716dVM/D97kICsXG7JyANA7ZOViQ1YOknfx4sX4+HgGIkJWLjZk5SB5kyZNCgkJYSAiZOViQ1YOkle5cmXc3lNkyMrFhqwcAPQOWbnYkJWD5F29ejU6OpqBiPS5EURZeZs2bapXr84gZcjKQapKlSolk8k4TrWtT6ibHqkgLFy4kMi+nx0AABAASURBVIGBISsXG7JykKpChQr5+voy9f3VhD5ubm69e/dmYHj6DFjGjh1bpkwZBqmirPzevXsMQHLatm1ra2ur3adIkSJouIgDWbnYkJWDVFEp9/T01DylJnnnzp0ZiALHlYsNWTlIWKdOnTQpa4ECBXCzZtHos5QjK08L2t7s0aMHA5Cipk2benl5UYeTkxOa5GLCceViw3HlkBb3r4TERCiVymQaWxyjhTb5i1Vx6mHJD2KMT9LNydQFgOe++ZK0vIv60BXO1/fx8ePHXd2ytG3TNvUPLIyftE/S/slORPXhlVwKE+dZop4cn9yfmXg0uTzes7C1i7s9MzX6LOWUlTs4OKBhnjr6lR85cmTu3LkMIDl7lr96+zRGJmOqK34rkhlBqHXJvjZJAfvWq6gQspSnlvIbpfbuquJKVZPTegtVIU1u+kn6c1+mwqfhw6hHS/ZDJv0ekv1mkvaUW3GKeN4mk+yHX3LLreTMdOC4crEhK4dUHNn49v3LmHpdsmbP68Agg5zxebt8nF+/GZ5WtlbMROC4crHhuHJIya5Fr0IDYzqPy8cgQ9Vok71o1ahVE18Ommcy8wJZudiQlUNKlo3ybTk4h4OLLQMjsGfxczt7WdthnswU4LhyseG4ckjWhUPvZXKGOm48suay/vQhlpkIHFcuNmTlkKzoCNUOSAZGw9bJShGnzwppUMjKxYasHJKliGfKOAZGRMkr4pTMROizlI8dO5bBtyArBwC9Q1YuNmTlAKB3yMrFhqwcwERwzHR2XiArFxuycgATwTPTOVQbWbnYkJVDsjgOB7AYF96kWuXIysWGrBySxfMMp+sZFc5sW+ViXoMlOjo6PDycmaAiRYrkz5+f2ubMBDk4OFhbWzMAs4CsHFJmqcYAwNghK4eUKdUsLPT5zQOA3qmuoSszmWY5snKxxcXFRUZGMgAwbqlcyd0I4bhysclkMjTJISkZjmCB7yCde3t26dJl7dq1Sfv7+fk1atTo7t27qb98zpw5I0eOZIZHQbmdnV2yg86fPz9o0CD6tPfv358+ffq4ceOSHa1///5LlixhIC1K3Y9gmTHzlyFDezOzMXnKmJGjBjLxICs3JsLtYrNkycKMQypZ+c6dO5l6pZI7d+5q1arFxprMBTYBRFCjRt24OCwUydNnKTfOe3u6uLh0796dGQ3KymNiYhwdHZMOogy9ePHiJUuWpO5atWoxANBSt05DBimQ1L09KbvYt2/fqlWrqKNo0aKjR4+mikkBy8CBA+fNm1esWDFqDi9dupRyDCsrK6qVNM6kSZO2bNlC5Z5eTi3l27dvU6M4JCQkb968lHUUKlQo9XdUKBS7d+/evHkzddPIXbt2pXcRBtFkjx49GhgYSBsEJUqUGDJkCKXk1L9bt24dO3aMjo7etGmTjY1N2bJlBwwYQJsOTZs2paEvXrw4ePDgggULaLLh4eH0lQo96fO/evWKpkNbGNofICgoaOXKlRTI0OqBJkVDc+bMSf2fP39Ok124cOH27dvp73Vzc6tZs2avXr3kctWdZ2lSNIhCJ8rEqlatSqs6+kKoP02H/pZHjx7R56lYsSL9OSllQWAkLC0sb968NmPWL8HBn/J5FxgyZEyRwqpf4P+aVOvRvV/HDp8bMXN/m/r06eM/V2yi7pat6/3Qo//r1y99dm91ds5cuVL1HwePmjl74rlzp3Plyt21c68GDZrQaPTz27lr0+UrF54/f+rq4lalSs1ePQfSL5YG/Tp1HMdx9er+b/bcKVFRkUWKFB/Qb2jhwsVS/6gtWtXt3rXPmbMnbt++sW/vCUcHx8NHDuw/4OPn55snT746tRu0ad2JJrtq9dI9e7fv3X1cc8zutu0bVq9Ztm/PiTlzp4SHh82ft5ypfvmBy5YvuHvvFi1K5ctXpinTh3/58nmPnm3/WLCyZMkyNM6x44cpg/ppyJhWLdvTU2HooQNn0vyrNtezPTP8uPL//vuPGraUMg8fPvzevXsbNmxINALVx7///psq++LFi21tbdetW8fU+yGFoe/fv6cyOmbMmGnTplHb+ffff//m3fLWrFlDL5k4cSKFS1Syf/nlF6qS1J/e+sCBA3379qWC3qNHjzNnztBbCy+hH+j+/fvpTXfs2PHXX3/R56SaTmuRw4cPU65CBZ06ihQponkL+iQ0WZo4lezevXvv2rWLyrcwiFYk9L60+qH1xPLly52dnYcOHfr27VvhXeiR6jWtseiT0Gg+Pj70MahnQEAAfT+0GqP1RNu2bU+ePLls2TLq/+bNmwkTJtCCQX84reFoFUjrwvj4eAaiSN+J+wHv3+0/sGvC+GmzZy2KjYv9bd7Ub/5o6bexbft6T0+vI/+c79N78D+H9w8f0a9unUZHj1ysXav+b/OnhYWH0Wi792zbsnVdh/bdZs74o3//oadOH12/YaUwBfq53rt/++ixv1cs3/jPobPWVtaz5kxm30Lve/DvPfnyFfxt7lI7Wzuqs3Pm/logf6Etm/bTx9jls2XJsvk0Wu1aDWgpvnz5vOaF/509Sesb7fpLv/zhI/vfvHVt+LAJa1Ztz+zsMmhwjzdvX9Mf5e6elT6bMNrduzezZvW4/+Xpnbs37TPZp711wplQUq7fUk71okyZMizj0Ezq1KkTBRS0ZVC5cuWkuzqPHTtGGXSNGjWotU5N40Qz9ePHjz/99BO9vHTp0i1atKC2cGhoaCpvR0OpPrZr146aw/R2VEapg+qsqjmzcyd9kipVqtjb29PbNW/efOvWrVSUhRfSOo/enQa5urrSS548eZLKu5w7d+7Dhw+0q9Pd3Z1qPW0raE5zpdUArTlo3VO+fHnasKA1B/1de/fu1byWvgd6d1qEKLehNxXeaM+ePdbW1tQSL1WqVJMmTWhNI9R9qum0iFIRz0XNm9y5hw0b9vTpU2rRMxBF+k7c//CBVswTSpcqV7ZMhdatOj5//iw0NOSbr8qfr1DzZm1U26Y169PTokVLUBGnuU9llFbeL1/4Uc/27bquWrm1Vs16NPHq1WrToMtXvv4YoiIjR4+alD1bDnoVrQZevXrxzUNsqcXt6Og0ZPCocmUr0qv+/ntviRKlhw0dlzmzS5nS5Xv2GLB3745Pn4K8vfNnz56TyrfwqsDAj/fv36mTMFq5c+cmNbFpBVaxQhUXF9eBA4Y5Ojn7+GyhQaVLlX/w4POCf+v29UYNm9Gj5lXlylViacZ//p9p0Gcp9/f3z9jjyrWvUUVFLdFuQ1qTU3UuXLiwpg+Vde0RKFSh8qp5OT1SasFSRlOjx4IFCwpP6ddJzXNaE7x+/ZqqtnY4kz9/fvpmhPYyNZqoUGoG0d6F1JcBehVt1WbNmlV4SiVbswuXSjlVYarIwlNaVCiBuXPnjua1+fJ9vV84bTAJ6wBqblN/IWkhDRo0GDx4MFOnK/S3ULQi9Kd3pOr/zSN/QF84GSfTfXH09i7gYO8gdDs5OjP1NS2++SpqvQodwma0l5e38NTWVtW4CQtTtWDop3Xl6oWBg7rXb1ipdt1yO3ZuojqrmUIuTy9NS8he/QGEV6WuYIHPm5sUdVI2Ur5cZc2g0qXLU8/bd25Qd/16//vv7AlaYKn7zH8naAO6WtVa2tOh9jV9PFoBCE/pl1+qZFmhZFNPYSIhIcG0YmverC2tDAIC3gmvKlOmApMofWbllDJnbFauKU9MPXcTDaViSmVUuyWuKVsC7aNKuDRs6wqVMek1SYQARLs//RbpMSoqSpiy9uf8Jmr7Cy/X0EyZPgCtMxo1aqQ9lGIWTbcsudpA30OiP1wztcePHyea2qdPnxiIglfySt3vPqbrjzbZMZP9naz8azE1nClaoYJLMQVF2H//sy/1l3yTsEuGUDOLfrqUgNM/7RGEtQWl8Os3/HX9xpXy5SqdPXuyevU6iY74osScXk4rGO2elPvTY9myFWm7hNrsz/x88+crSG12ivJv375eoUKVt29fVyhfhaUdJSy4BosREgqiJuVg312nhD82aZta6K/dOBLGEXausoSL3zfR9oGwDkg0NWGC1GD/9ddftYd+cz1BHy/Z7QCaGm3WJDraJ9kjbcDkKJQKncanRs+Bgz5t23Ru2qSV0CdcHaDrC/1uqVHVoH6TGjXqavfPnk210z5nTk+KWc6dO1WgQGEKxGk3QKKXu7q60eI8Y/rv2j3lMrkwKE8eb4rLfZ8+Ll6iNPUpUbw0PZXJ5RQH0TqJpR1vSudsmdE1WGiLjKIJIRURXLhwgX0Hb29vKsoUaAhZCv36KWimbLpSpUpUT4W8Qhjz0aNHFN24ubkJT5W6tL4oIqe1AqUiefLkoaeUXwcGBgqDKBGiQfRHZc+eXehDGVeyLW5tBQoUOHToEEWiwhrl1KlTR44coX3FNP3jx49Tqq5pcNF3lSNHDgai0O/ZnlZW1lFRX1fYlGUzXVCLhxoQbm7uwlNqRJ+/cIbpFUVDtH+VgnjNO/r7v6GdlsJTiuYPHtydO3deitc1QYr2a+njubt75MieU+jz1v+Ns1NmoZuymlu3rj979qRrV9X5U8WLlVq5ajH94HUKyk2OeV2DhYos7fm8du0alV3haD/2Hah5W6dOnYMHD1IpvHXr1vLly2/cuEFlneJv6r9t27aLFy+GhYXRO+7fv79169ZCiaS31umwENqhSpulCxcupKpNRXzWrFmaljLtni1Xrtwff/zx/v37kJCQAwcO0G7bo0ePpj5BilBosVm0aNH169dpn+qaNWto7yute+gT0jpmxYoV9EYU969evXrAgAHPnz9nIAqlXq9XTqnC6TPHhV/4xk2rP358r9PL6SdHefo/h/e/efuaQue586ZSQaQ0XI8LeN/eP1K7m0Ib+tXRDsmp08aPGDVAs3+rVq367wL8Dx/eX7t2g6QbmrSPlwKTefOmUQhOH2/vvp0DBnajkYWhZUpRKb+mapUXU+1GKlas1IsXfteuXdI9KDelsz3N6xosXbp0KVas2M8//9y7d++XL1+2bNmSfTluL31ohyHtaaSySFsktIeQdnvmypWL+lMRpNUGfSGdOnXavn17hw4d2rdvL7yEYkqdckZaYVCEQtWf9kP07du3VatWwlsIpk6dSjsnqL7TW+zbt6927dotWrRIfYLU0J42bdrt27cnTJgwd+7c8uXL06dl6h2wVMdpy3fIkCF9+vShEYYNG6a94xRMyI+DR7lkdm3WohbttIyJia5bp5GuU5j480wba5sferbt2r0llc4+fX6kp63a1PN/95bpQ/HipVau2Hz79o1WbeqPGjMoIiJ8+rQFmv1A1NwuWKDw4ycP69ZO/rSgWTP+qFmz3tTp41u2rrd7z7Z69f7XunVHYRCVbFoN5MqVO3NmVaRJG8ReXnmpT+kkrXsp4Xj9tQRot2f9+vXFOR4xfbeeoFd9+PBBUwp37txJbWcfHx8GaYNbTxjOsS0Bj6+Fd5vkzcA43Dj+8c5/wYN/N43WjHldr3wcEX5UAAAQAElEQVTXrl1Uvnv27Emt15s3b1LGIpxjKSZcrxwA9E7612DR1rVrV8qUKbxeu3Yt7YRs3rw55RKpv4RijZQGjRw5skoVXY5tUkvlGixg1kz/CrfNmtdKadDYsVMSHRtu/HgKQs3zYMQMvwZLWginw6Td0qVLUxqkfQR32uF65ZA8079H88qVW1IalNnZhZkaTqk004vcSvLenh4euhyImga4tydIVTaP7AwyCO7tKTZk5QAmgeN4Zjr39jThrJwzzdtnUVAeERFhPLfC0ImJfucmATeEMzY8L1Md7W8iTDUrt1FjJujNmzc3btzo0aMHA9Ci31OE4Pup5gauwQIpKaHGAMC4cbi3J6Ti48ePAQEB2tfjBQD4TuZ1DRZjcOvWrfXr1zOAhJCVw/cwr2uwGAPa4YkmOSSFrNzYmNKdPZGViw9ZOYBJMKWkHFm5+JCVA4DeISsXG7JySJbMgllaISw3IpyMl1kxU4GsXGzIyiFZLlktFOm4uScYTEhgnJWVPiukQenzgyIrTwsKynF+ECRVqqYrr2R+d4MYGIf3z6PcPU3m6vz6vPUEpAWyckjJsa3vfG+Gd5mAOzdlvFM7Xvk/i+k3y2TmhT5LufFfr9wYHD9+/MiRI3PnzmUASTy+GXp8y/vcRe2LVXXKnMWWgbgUCsWz28F3z4XFRsX3mW5K61Szu155hkNWDqkoUMoxPDD2+sngF3fCFYpvjEzNsNTPKvrmCCm+MOWrj6QyzZQGJdv/e3omN1rSj5y4TzLTSfIa1W135czF3bL7zya2bYTjysWG48ohdWXqutE/pm4hJr3ZvEno06fP4MGDS5cuzUAsOK5cbMjKIY1MtI6T+Ph4XJFfZDiuXGw4rhwkLy4uDrfKEhmOKxcbsnKQPLTKxYesXGzIykHyUMrFh6xcbMjKQfJQysWHrFxsyMpB8lDKxYesXGzIykHyUMrFh6xcbMjKQfJQysWHrFxsyMpB8lDKxYesXGzIykHyUMrFh6xcbMjKQfJwipD4kJWLDVk5SBvP80ql0nSvOmCicL1ysSErB2mjJnn16tUvXrzIQETIysWGrBykDUF5hkBWLjZk5SBtKOUZAlm52JCVg7Rhn2eGwHHlYkNWDtKGVnmGQFYuNmTlIG0o5RkCWbnYkJWDtKGUZwhk5WJDVg7Shqw8QyArFxuycpA2tMozBLJysSErB2lDKc8QyMrFhqwcpI1KuUymz8ICaaHPlWfhwoUdHBwYpErIynft2kW7FqpWrcoApGX//v2VKlViIC59rjz79+9fqlQpBmmQM2fO7du3U9hC3efOnYuNjWUAJu6ff/6pVq1a3rx5BwwYwEBc+rycFmXl1CrHQSxpR18+x3Hz5s3z8fE5deqUXC4PDg52c3NjACbl2bNnM2fO9PDw+Pnnn21tbRmITp+lfNiwYW3atKlevToD3SnUmjVrVrJkyblz50ZHR9vY2DAAo/fbb79dvnx5woQJpUuXZpBB9Bmw4Ljy70FNcisrqyNHjvTp04eevnr1qlWrVocOHWIAxurgwYOVK1fOlSvXzp07UcczFq5XbrxevnxJ2621atWiBebGjRvdu3fPnTs3AzACvr6+M2bM8PT0pESFmiAMMhqychMQExNDO5QogmzYsOHu3butra2pA4fuQkaZPXs2tS2oiOO8ZeOB48pNANXuli1bUvmm7iJFily6dOncuXPUffz48YCAAAYgln379lWoUMHb23v79u2o40YFWbmJKVSo0NSpU2vWrEnd79+/79mzp1DNnz9/zgAM5uHDhxTx3bp168KFC+3atWNgZJCVm7zY2FgKK2kxo45t27YJTxmA/lAsfv/+/QkTJuBEZaOFa7CYPKFwb9iwYf78+dQRGhpau3bt1atXM4Dv5uPjU65cucKFC2/evBl13JghK5eOHDly0KObmxsFmgULFqTu06dPjxw58s6dOwxAR/fu3evSpcujR4+uXr3aunVrBsYN1yuXIEdHx2rVqlEHReoUoL148aJ48eIHDx6kBnuLFi0wjyB18fHxM2fO9PX1nThxIu2bYWAKkJWbi7dv327dupWWzCZNmvz777+enp5YSiGpHTt2UFJHsTit9RmYDmTl5iJ79uwUtlAdZ+ozS6dNm0Y7sqgb8QsIbt++3aFDBz8/v0uXLqGOmxxcg8V8CTfumjRpEkXqR48etbCw4NQYmJmYmJgZM2a8evXq559/zpcvHwMThOPKzZdwA8apU6ceOnRIJpMplcry5ctPnz6dqa/txcA8UOxWu3btihUrrl27FnXcdCErhwRo45qW6gcPHlBg2q1bN+FcJJCkGzduUGO8UqVKo0aNYmDicA0WSB4t569fv27WrNmxY8ceP37ctm1bd3d3BpIQGRk5c+ZMWmApUcmTJw8D04fjyiF5pUuXpjpOHRUqVLC2tv7vv/+omyL1ixcvMjBlmzZtatiwYdWqVVetWoU6Lhk4rhy+wdHRsXfv3kK3m5sbLf/R0dG1atW6evVqiRIlcJEAE0KzjBKVGjVqCCtmkBJk5aAz2kFKu0lXrFixfv36AwcOUH0PCgpycXFhYBxevnz5008/cRy3Z88eoU9YWBglKjSbKFHx9PRkIDnIyuG7CDeua9OmDRX0P//8Mz4+HhdSz3A//vjj+fPnqUMIPGmNu3bt2gkTJjRo0ICBRCErh+8i3IDUx8dnyJAh1EHtPtpBSk8ZZJD9+/ffvn1bpla7du3mzZuHhIScOnUKdVzakJWDfhQrVowe3d3df/vtN+E80kuXLh0/frxDhw7e3t4MREFVe/Xq1ZGRkZqntJNTuM4aSBuycjCUuLg4aiHGxsZ26tTp5MmT1FGvXj25XM5Et2vxi4+v4xXxPK9kOqPlQ9cTYHV/CS2F6TnNllO9yjaTrFqLzAXKZqYekydPTnRrb2tra+GeUyBtyMpBDH5+fn/99VfZsmUpVb9w4QK100U7Sn3z7Ocxkcpi1Z0KlHXOkBWJQQUHxd468eHFg6h2w3Lce3Jx1qxZlHElGoc2l2nvNANJwzVYQGx79+6lHaQLFiwoXLjwy5cvDXpAxerJvnZ2sqYD8jKp2zzT9/rTbQ/f/0vNcNqBQSstWrRpF7StrS09rlu3joGkISsHsbVUE/Lc33///dmzZzt27LCystL7lbzOHXwfH8OajpB+HScFyjnGK9u26Vuetozt7e3t7Oyc1HDgv5lAVg4Z7PXr1xS2UB1v3LgxlfjBgwczPdk067ncQta0n7kcRr1xum+rH3Nky23LwPzgeuWQwXLmzEktR0tLy+3btwtX5nv48OGYMWOuXbvGvk9MpMLaXmrheCpoq+b9i2gGZgnHlYOxcHFxadiwIXUUKlSIOqigU/e5c+eoxIeHhzPdxcdwfCwzH4o4xvP6XKLBhOB65WCM6tat26VLF+ooUKDAixcvhBPQz58//+TJk1Re1b59ewZglvRZyseOHVumTBkGoD9ZsmShsKVbt25Mfe2XiRMnCpeCevToUaIxmzdv7uvr26lTJwZgfpCVg8moVq3atm3bypUrR90HDx6sWbPmx48fNUMphJHJZBTLaNrmqiNicHs7MA/IysHE2NqqjtAYOXLkoUOHhCvA1K5dm1ruwcHBTH0HagphWrduHRsbqzo4y8yOz8Kay2whKwdTZa9GHSdPnqR0RXNYOlXz58+ft2vXjpMxzsz2AuLIYrOlz1OEKCtnABlh+vTp2mcYUdLy5s2bKK9oXmnNAMyAPks5rsECGYVCc9opylT5OGdlZeXo6GhhYaGKynFsHpgHfZZyyspxDRbIEG5ubi4uLh4eHvny5StSpAh15MyZc8v09zwzr1rOISw3V7gGC0jB4cOHk/bkle+ZMh2XtTVhuAyH2UJWDpJlhgcjolFutnBcOYB0oFFutnBcOUiWGR5XDmYLx5UDfHX23Km+/TrXrlvu3r3bk6eMGTlqIEuvZ898aTp37tyk7u+cVNohYDFbyMoBvtq6bT3P+AXzV+TOnbdGjbpxcfq5sqIeJ5U6bISYLRxXDvBVZGREyRJlSpdSXealbp2GTE/0OKnUcRyKuZnCceUgWarzg9KcOPA8X6deeep4/vzZvv27lixas2PnpvDwsPnzlvv5Pe3Vp8Oypeu3bFlLCUyWLO61azXo13eIcNPnCxf+O3HyyO07N0JDQwoXKtatWx9hTaCNAhZhUsuW/75z12btQW5uWXZu/4c6goICly1fcPferejo6PLlK3fv2idXrtxMRzyPiMVM4bhykCxeqUPiwHHcyeNXe/ZuT63yYUPHqXrt/DzI0tKSHucvmN61S+9JE2fdv39n2Ih++fMXqle3EZXdGbN+KVO6wrixv9I4p08f+/mX4Zs27HVxcU32XZo3b1u58ue2TnRU1PSZPxcrWpK6FQrF8JH9IyLCR4+alD9fwW3bNwwa3GPFik05sudkukAhN1vIykG6KG3QX22rWaNerZr1qKNkyTLZs+V4/PgBlXIbG5tVK7fZ2to6OTnTIGqVU4v+zt2bNWvUTXYiOXPkon9C95Rfx7q5uVPtpm7aO/ry5XNqtpcprdoyGDhg2Lnzp318tvw0ZAxLM55n5nVCFGhBVg7SRWmD/qLjAgUKa7rt7R0oMBG6KV5ftXrJzVvXAgM/Xzw9OPjTN6fms3vb5SvnV/65xc7Ojp5S9ae2v1DHmXoToVTJsrdu63ZoL8ehVW6+kJWDdOm1sMlkyRy5GxDwbujwPhSwTPx5ZpEixakE129Y6VtTYg8f3V/x5x+/Tp6raaHTiiEuLq523QQhu7NzZgaQNsjKQboMfzTHqdNHY2NjKSgXboiRlvZ4aFjoxEkjO3XsUaVKDU1PV1c3msKM6b9rjymXyRlA2iArB+nimKEP6AgNDXFwcBTqODl95njq4/M8P336hNyeeXr+MEC7v7d3gaioKHd3D81+zrf+b5yddG6VI2AxW7gGC0gXzwx9mHXevPkpIt9/wCc+Pv7S5fPXr1+m/Z/v379LafzNW9bevnOjZcv2lK3fuHlV+EdFvGyZChUqVJk3bxolNiEhwXv37RwwsNvhw/uZjnBUudlCVg6QfnXrNHzx4tmGjX/9/ses8uUqjR0zZdv2DVu2rgsLC23Zon3S8ak6x8TETJw0Srvn6r+25c2bb9aMP2iVMHX6+Pv37+TKlbtevf+1bt2RAaQNx+vvCsdz5sypX79+mTJlGIARWDnumVsO6/rdczDzsH6Kb/WWbiVrOjMwP8jKQbJ4pfosIXPCIy03V8jKQbI4udnd2xOF3GzheuUgWZQdmtsN0rDb02zhuHKQLiVqG5gLZOUAACYPWTkAgMlDVg4AYPKQlYN0Gf7EfWODI1jMFrJykCxOxmRmVtuwl9dsISsHyeIVZneKEJgtZOUAACYPWTkAgMlDVg6SJbfmOCtmPlS3OeKQKJkpZOUgWVZWfHy0gpkNnmP2uCqiuUJWDpLlkdcmNDCemYdHVz/JZSxfCdwO4F7b8QAADs5JREFU1Ezps5QjKwej0qBL9vh45cWD/swMXD8emKe4LQNzpc9bTwAYoRVjfTNns2rc05NJ1OMbny4dCqzUyKVMXRcG5kqfpZyycgcHBzTMwdisn/Y8PDiekzHlN5Nz/vMZk9yXTu3FI/FTPsHZpNpDEw1KlmacRJOlJZLj0vQh5XJOyfNyOctbwo42QRgw86XPUj5s2DDc2xOM1p1zH+OiEySKVEk5PkEh5TmOE5YIqqa0bHAJbvScaHx1yf1avdUlWfX0w/v3N2/ert+gntY0mfCqhC/5+lJe6/Y//JcXfBk38Qs1I9D/O7sz72LIxwHHlYPZKF7VjYniypWnfqdPlKnbngGIBceVA+hZXFycpaUlAxARjisH0LP4+HgLC302kgC+CceVA+gZSjmID1k5gJ6hlIP4kJUD6BlKOYgPWTmAnmG3J4gPWTmAnqFVDuJDVg6gZyjlID5k5QB6hlIO4kNWDqBnKOUgPmTlAHqGUg7iQ1YOoGc4ggXEh6wcQM+oVW5tbc0ARISsHEDPELCA+JCVA+gZAhYQH7JyAD1DqxzEh6wcQM9QykF8yMoB9AylHMSHrBxAz5CVg/iQlQPoGVrlID5k5QB6hlIO4kNWDqBnKOUgPn2W8vXr18+fP58BmKvw8PC9e/eGhYVlyZKFAYiI43me6Qk1Ro4ePfq///3v/v37Pj4+HTp0KFCgAAOQOqrdx44dox//vXv36tWr17p166JFizIAEemzlGsoFIoDBw4EBgb27t37ypUrsbGxVatWZQDSEhoaekyN2i5UwevXr1+xYkUGkBEMUsq1PX/+fMGCBWXLlu3Ro8ejR48KFizIAExZSEiIUMEfPnxYTw0VHDKcwUu5QNgRtHXr1oULF27cuDF//vwMwKQEBwcfP36cUpTHjx8LFbxChQoMwDiIVMo14uLiqFHj5ubWqVMnLy+vqVOn4mQKMGZUwYUc3NfXt27dupSilC9fngEYGbFLuYZSqaQlhDJ0Gxub8ePHN2vWrHr16gzAOHz69ElIUaiCCzl4uXLlGICxyrBSro22W69duzZmzJgXL17QHiRabHBYLmSIoKAgoYI/e/ZMqOC0m4cBGD2jKOUaoaGhc+fOpQb7zJkzaX+ph4cHtdkZgIEFBgYKFZx+dUIOjgoOpsW4Srm2y5cvDx8+nMJ0CihjYmJwhy3Qu48fPwp7Ml++fClU8DJlyjAAE2S8pVzw+vXrnDlzUiP9zZs3kyZNypo1KwP4PlTBhT2Z9OsS9mSWLl2aAZgyYy/lGhcvXsySJYu3t/e0adOKFCnSunVrjuMYQJp9+PBBSFGoggs5eKlSpRiAJJhMKde4e/fu/v37Bw8enClTpt27dzdo0MDZ2ZkBpOD9+/dCBX/79q2QoqCCg/SYXinXoL2jv/32G1X2jRs30iYzPXV3d2cAapoK7u/vL1TwkiVLMgCJMuFSro0W1169ejVt2pRa65GRkXZ2dgzMUkBAgFDB3717hwoO5kMipVzw4sWL3LlzHzp0aMeOHaNHjy5WrBgD80AVnHZjUgWnxrhQwUuUKMEAzIakSrkGpS4xMTFly5b9888/raysOnXqhOPTJYma3kIbnCo47cakCl68eHEGYH6kWco1KHjx8fGpWrVq6dKlaR9pmTJlvLy8GJg4TQX/8OGD0AZHBQczJ/FSrm379u0UvKxbt46S9OfPn3t7ezMwKUIFpyAlMDBQqODI0AAEZlTKBQqFgv7kzp07u7q6Ll++PDo6GtmLkaNNK6ENjgoOkBKzK+Uawnmkvr6+o0aNGjBgQKNGjRgYk7dv3woVPCgoCBUcIHXmW8o1Xr16RQW9du3ahw4devr0KTXY3dzcGGQQTQX/9OmTUMFxn0yAb0Ip/yoiImLXrl1Ux5s0aXL48OGsWbPi0hyiefPmjVDBg4ODUcEBdIVSnrxLly799ddfFLyUK1fu3r17KCsGQhVcOB48NDRUqOBFihRhAKAjlPLUxMXFWVpa/vrrr2fOnDl48KC1tbVMJmPw3WhHhdAGpwouHA9euHBhBgDphVKeJrTVb2trK5fLqei0adNmyJAhyY7WtGlTKvc+Pj6pT83fL/zKvyFB7+NiI1UH1DCeo0eOMZoTwiORcUyp7tL00VwHklePpzUmp1TPRNUIqokxjmOauSq8SvUKdU/6p7mgpGYKGpy6l3ZP6iGTMwsrmUNmi5z5bau1yMK+5fTp07/88st///2XdJCmgoeFhQltcFRwAL1AKdcN1aALFy40aNCAUpedO3d27NixUKFCmqHVqlWLjo7OnTt3StX84Ko3Lx9GKRVMbimztJVb21tZ2FrKmVzGKZWMl9HsoNqp/Fyp6ZmqMKupZxLPcRyvqe88L1zmV8lxMqEvT91MplXrv7xWVcZpqrIva4uv06Rhsq8VnVYesoRXDlbyXHxcXGxUfGxkbHysUhnP2zvJqjRzLVDGKdk/cOvWratXr6Y9lteuXdP0FCo4BSm0N0Ko4NpfGgB8P5TydFIqlYcOHfr48WPPnj0pWI+JialRo0aZMmUogaGv1MvLK1E1P7E94MGlME7OOXpkylnk221b4xQdFvP24ceokFhbe1nPKXkSXTJ+yZIlFEPRd0Ldrq6uq1atEtrgqOAAhoZSrgfPnz9fuHDh9evXqWZpelLbfNu2bRS1U/eqic9io3n3/M5uuSRyafUX1/3DAqMLlbev18lD6LN///558+ZFRkYKTyk5om8AFRxAHCjlelO9evWoqCjtPlTLdu3atXz0U1sn6zzlsjPJeXDyuZObZecxnnPnzv3nn38ofdIMot+VdsYCAAaFUq43QrqieUoJDD3+UHOrRwFXd6/MTKLuHfOzdA3Y8PdYao9zappBWbJkofrOAMDwUMr1o1GjRu/fv7e1tXVwcLCxsaFv1dHRsaLbLzmKumfO4cgk7fHZl1GxHx9HrvP396cVWFxcHDXPKWui7hs3bjAAMDyUcr1ZtmxZ9uzZc+TI4e7uTh1/jX/h4G6Xq3hWZgbuH39etLJ9zTZZQ0JCqKC/e/eOHn19fSdOnMgAwPBQyg1i9+JX79/EFaqZm5mH2MjYx2ff/Ph7PgYAGQHnLhrE22cx5lPHiZWdlY2jxZpJzxgAZASUcv3bON3PKpMFMzP5KuWKDFMGvI5gACA6lHL9CwlS5CphvJfJ/W1xJ58Dc5kBWNrJj278wABAdCjlenZkk79Mztk62DLz45bHKfh9PAMA0aGU69mbx1HWmSyZWXLNobowy72LQQwAxGV2ka6hUV6cNb89MwyFIv6fYysePD4XHPwuT+6SVSq2K1KwKvX3D3g6f0nnn/qvOXFm/d0Hp50c3UsVr9+4/mC5XE5D371/ts1nasAHv3x5y9ar2YsZEm2RPLoSWbSSCwMAEaFVrn8unoYq5XsOzvvvwtZqFdtNGLm3eNE6G7aNu333BPW3kKu2A3bum1W6RMPZk892bvvr6XObb907Rj3j4+NWbRjm7OQ+5qftTRr8eOrsprCwj8xgLG0tQoPjGACIC6Vcn177htOj0BbWu7i4mKs3D9Wp3qNyhdaZ7Jwqlm1OhfvoqdWaEUoWrVOyWF0LC0vvPGVcM+d4/eYh9bxz/2RwSEDz/w3P7Ozh4Z63VdNRUdFhzGAsbCxiIpQMAMSFUq5P4SEGrGKv3j6Ij48tkK+ipo+3Vxn/AN+IyBDhac7sX2/jYGPjIJTsj4GvrCxtXDJnE/o7Org5OxnwBFQLS1miK98CgAiQleuT+nJahipk0VGqJv/SVf0S9Q8LD5TLVPOR45JZMUdGhVpZ22n3sbSwYQajUKruOgQAIkMp1yf3nFaqW/8YhqOj6lj1ti3Gu7nk0u6f2ckjNOX4287WMSYmUrtPdIwBz+JRxsfTnk8GAOJCKdcn5yxWlC6EBUU6uNgxfcvi6mlpaU0d+fKWFfqEhQfxPG9Nje6U0+/Mztni4qIph8mWVXWBlDf+j0PDDHgWT1xUvIMTSjmA2JCV65mFJQsNMEizl0p2g9p9j55c/ezFzbj42Nt3T6xcN2T3wW+ct1m0cA0LC6ude2fFxkaHhH7YtOMXOzsnZjCKWKVHbnM8PQogY6FVrmdObpYhgdHMMGpX75Y9W4GT/2148vSKjY29V67i7VpMSP0ltjb2vbsuOPTvkl9m1KH9n00a/Hj99hHDNZuV8Xy5BpK9zwaA0cJFbvXs3oXgU7s+Fq2Xh5mfl3feRQVF95/tzQBAXAhY9KxoZWeZnL19FMjMT/jHaK8iSFcAMgACFv3LVzqT7/Ww7AVdUxrh92XdAz+9SdpfqVTQRpJcnvxMGTfMxz6TM9OTE2fWn/hvQwoDKYDhdf0MgW9DeQXfsLsE70YNYPwQsBjEijG+DtkcchRK/lK3wSEBVLWTHRQbF2OlPkwlKZfM+qySUVFhKZ32GREZmsku+fuROjlmTelc1gcnnucrlal+Fw8GAKJDKTcIv3thf68OKFrfXBLz5zf84yNj+0zPywAgIyArN4g8RR1yFrZ5cPo5MwPhnyIjAqNRxwEyEEq5obTom9PR2eL+ST8mdc+vBnQdn4sBQMZBwGJYZ3ze370SWqSmNJOWjy9D3z0M/PH3fAwAMhRKucHtXvzq7fOYrPmds+SW1Lkzvpdex4TF9ZuR29LGTO+aBGA8UMrFcPvspzO7Azk5y1Usi6O7oW5MIZpXtwLCPkTaO8u7TzTHM6EAjBBKuXh2LXz57nks7Z6wc7Jyze3kZGo1PeDpp5B34XFR8ZY2XMUGLiVr4gR9AGOBUi62fze/fX43MlZ9mRaZnP7JlBzjFd+YCxz9xzOe4znVVXT5VEZTjfVlHK2OBK9R9edVMz+1qalGoPUOjaRk9J+CySxY5ixWZRs4FShlwAtyAUA6oJRnmJcPwp7fj4wIVcTG8vGxX+dC4lMt1c9Vd5VQqqurjOOVn4dzVN6/jCp0yzhOyfOa/jIZU6rva0Qv55Vf+8jUT/kv/bWno/kAQk9LC5mNk8zFzaJEFUcreysGAEYJpRwAwOThGiwAACYPpRwAwOShlAMAmDyUcgAAk4dSDgBg8lDKAQBM3v8BAAD//8EF8KkAAAAGSURBVAMA5h2KCek4jcwAAAAASUVORK5CYII=\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{}}],"source":["from IPython.display import Image, display\n","\n","try:\n","    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n","except Exception:\n","    print(\"Could not draw graph. Skipping visualization.\")"]},{"cell_type":"markdown","metadata":{"id":"BVZi0ZuqCy7U"},"source":["## Test Run the Graph"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vZQaIYBwHyKz","outputId":"f65b0e7b-41b3-4339-a635-a1aa4aa41056","executionInfo":{"status":"ok","timestamp":1764611507238,"user_tz":300,"elapsed":30,"user":{"displayName":"Alvin Yao","userId":"12743048314903098274"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Enhanced workflow invocation helper defined.\n"]}],"source":["## Enhanced Workflow Invocation Helper\n","\n","def invoke_workflow_with_tracking(graph, inputs: dict, config: dict = None):\n","    \"\"\"\n","    Enhanced workflow invocation with automatic execution tracking.\n","\n","    This function:\n","    1. Validates initial state\n","    2. Initializes execution context\n","    3. Invokes the graph\n","    4. Returns results with execution metadata\n","\n","    Args:\n","        graph: Compiled LangGraph workflow\n","        inputs: Input state dictionary\n","        config: LangGraph configuration (optional)\n","\n","    Returns:\n","        Final state dictionary with execution metadata\n","    \"\"\"\n","    # Validate initial state\n","    is_valid, error_msg = validate_initial_state(inputs)\n","    if not is_valid:\n","        raise ValueError(f\"Invalid initial state: {error_msg}\")\n","\n","    # Initialize execution context\n","    visit_id = inputs.get('visit_id')\n","    execution_id = init_execution_context(visit_id)\n","\n","    print(f\"\\n{'='*60}\")\n","    print(f\"Starting workflow execution\")\n","    print(f\"  Execution ID: {execution_id}\")\n","    print(f\"  Visit ID: {visit_id}\")\n","    print(f\"{'='*60}\\n\")\n","\n","    try:\n","        # Invoke graph\n","        if config is None:\n","            config = {\"configurable\": {\"thread_id\": f\"exec-{execution_id}\"}}\n","\n","        final_state = graph.invoke(inputs, config)\n","\n","        # Add execution metadata\n","        execution_time = time.time() - _execution_context[\"start_time\"]\n","        final_state[\"execution_metadata\"] = {\n","            \"execution_id\": execution_id,\n","            \"visit_id\": visit_id,\n","            \"execution_time_seconds\": execution_time,\n","            \"timestamp\": datetime.now().isoformat()\n","        }\n","\n","        print(f\"\\n{'='*60}\")\n","        print(f\"Workflow execution completed\")\n","        print(f\"  Execution ID: {execution_id}\")\n","        print(f\"  Total time: {execution_time:.2f}s\")\n","        print(f\"  Final decision: {final_state.get('decision', 'N/A')}\")\n","        print(f\"{'='*60}\\n\")\n","\n","        return final_state\n","\n","    except Exception as e:\n","        execution_time = time.time() - _execution_context[\"start_time\"]\n","        log_error(\"workflow_invocation\", e, inputs, execution_id)\n","\n","        print(f\"\\n{'='*60}\")\n","        print(f\"Workflow execution failed\")\n","        print(f\"  Execution ID: {execution_id}\")\n","        print(f\"  Time before failure: {execution_time:.2f}s\")\n","        print(f\"  Error: {type(e).__name__}: {str(e)}\")\n","        print(f\"{'='*60}\\n\")\n","\n","        raise\n","\n","print(\"Enhanced workflow invocation helper defined.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WifqwykRCylP","outputId":"7881fe37-cb86-4647-9dc8-bf3775429753","executionInfo":{"status":"ok","timestamp":1764611535671,"user_tz":300,"elapsed":9820,"user":{"displayName":"Alvin Yao","userId":"12743048314903098274"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["--- Running Simulation 1 (High-Risk Note) ---\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=fetch_data_INPUT\n","--- 1. Fetching data for visit_id: 1 (execution_id: 619ae2c5-7fa2-4890-81da-4de02ba7b129) ---\n","[PERF] fetch_data_node took 7.29ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=fetch_data_OUTPUT duration=11.42ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=severity_gate_INPUT\n","--- 2. Checking severity gate ---\n"," -> OK: Patient is not severe. Proceeding to models.\n","[PERF] severity_gate_node took 0.02ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=severity_gate_OUTPUT duration=2.72ms\n","[Routing] Non-severe case → proceeding to run_models\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=run_models_INPUT\n","--- 3. Fanning out to parallel models (human_input, llm_model, ml_model) ---\n","[PERF] run_models_node took 0.01ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=run_models_OUTPUT duration=2.61ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=llm_model_INPUT\n","--- 3b. Running LLM Classifier ---\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=human_input_INPUT\n","--- 3c. Acknowledging Human Input ---\n"," -> Human Note: 'Patient is 70yo, frail, and on chemotherapy.'\n","[PERF] human_input_node took 0.01ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=ml_model_INPUT\n","--- 3a. Running ML Model ---\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=human_input_OUTPUT duration=5.34ms\n"," -> ML Score (P_Admit): 0.8552\n","[PERF] ml_model_node took 14.88ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=ml_model_OUTPUT duration=21.56ms\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> LLM Classifier Score (P_Admit): 0.9899\n","[PERF] llm_model_node took 184.58ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=llm_model_OUTPUT duration=187.98ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=fusion_INPUT\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"," -> Final P(Admit) Score (numeric): 0.9225 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.923. Decision: Admit.\n","[PERF] fusion_node took 4289.77ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=fusion_OUTPUT duration=4292.51ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=confidence_check_INPUT\n","--- 5. Confidence Check Node ---\n","[ConfidenceCheck] ml_score=0.8552, llm_score=0.9899, fused_prob=0.9225\n","[PERF] confidence_check_node took 0.02ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=confidence_check_OUTPUT duration=3.12ms\n","[Routing] HIGH confidence (gap=0.13, avg=0.92) → finalize\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=finalize_INPUT\n","--- 7. Finalize Node ---\n","[Finalize] Using Admission Threshold: 0.5000\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=finalize_node\n","[Finalize] Decision=ADMIT, Rationale=Fused probability 0.92 ≥ threshold 0.50; patient should be admitted.\n","[PERF] finalize_node took 3.24ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=finalize_OUTPUT duration=6.85ms\n","\n","--- Final State 1 ---\n","Decision: ADMIT\n","P(Admit): 0.9225\n","Final Rationale: Fused probability 0.92 ≥ threshold 0.50; patient should be admitted.\n","Fusion Rationale: Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.923. Decision: Admit.\n","\n","\n","--- Running Simulation 2 (Low-Risk Note) ---\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=fetch_data_INPUT\n","--- 1. Fetching data for visit_id: 5 (execution_id: 619ae2c5-7fa2-4890-81da-4de02ba7b129) ---\n","[PERF] fetch_data_node took 8.20ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=fetch_data_OUTPUT duration=11.25ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=severity_gate_INPUT\n","--- 2. Checking severity gate ---\n"," -> OK: Patient is not severe. Proceeding to models.\n","[PERF] severity_gate_node took 0.02ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=severity_gate_OUTPUT duration=2.96ms\n","[Routing] Non-severe case → proceeding to run_models\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=run_models_INPUT\n","--- 3. Fanning out to parallel models (human_input, llm_model, ml_model) ---\n","[PERF] run_models_node took 0.01ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=run_models_OUTPUT duration=2.74ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=llm_model_INPUT\n","--- 3b. Running LLM Classifier ---\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=human_input_INPUT\n","--- 3c. Acknowledging Human Input ---\n"," -> Human Note: 'Patient looks stable, likely just needs follow-up.'\n","[PERF] human_input_node took 0.01ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=ml_model_INPUT\n","--- 3a. Running ML Model ---\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=human_input_OUTPUT duration=6.58ms\n"," -> ML Score (P_Admit): 0.0736\n","[PERF] ml_model_node took 15.24ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=ml_model_OUTPUT duration=22.81ms\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> LLM Classifier Score (P_Admit): 0.9807\n","[PERF] llm_model_node took 183.11ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=llm_model_OUTPUT duration=186.90ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=fusion_INPUT\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"," -> Final P(Admit) Score (numeric): 0.5271 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the p_ml (0.07) indicating low admission likelihood, the p_llm (0.98) suggesting strong admission probability, and the human_note indicating the patient is stable and likely needs follow-up care, I decided to discharge the patient. This decision is supported by clinical judgment, considering the patient's stable condition and the need for further evaluation in an outpatient setting.\n","[PERF] fusion_node took 4905.93ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=fusion_OUTPUT duration=4909.25ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=confidence_check_INPUT\n","--- 5. Confidence Check Node ---\n","[ConfidenceCheck] ml_score=0.0736, llm_score=0.9807, fused_prob=0.5271\n","[PERF] confidence_check_node took 0.02ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=confidence_check_OUTPUT duration=3.04ms\n","[Routing] LOW confidence (gap=0.91, avg=0.53) → human_review\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=human_review_INPUT\n","--- 6. Human Review Node (HITL) ---\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=human_review_no_override\n","[HITL] No override provided → using original fused_prob=0.5271\n","[PERF] human_review_node took 17.04ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=human_review_OUTPUT duration=19.82ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=finalize_INPUT\n","--- 7. Finalize Node ---\n","[Finalize] Using Admission Threshold: 0.5000\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=finalize_node\n","[Finalize] Decision=ADMIT, Rationale=Fused probability 0.53 ≥ threshold 0.50; patient should be admitted.\n","[PERF] finalize_node took 3.19ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=finalize_OUTPUT duration=6.21ms\n","\n","--- Final State 2 ---\n","Decision: ADMIT\n","P(Admit): 0.5271\n","Final Rationale: Fused probability 0.53 ≥ threshold 0.50; patient should be admitted.\n","Fusion Rationale: Based on the p_ml (0.07) indicating low admission likelihood, the p_llm (0.98) suggesting strong admission probability, and the human_note indicating the patient is stable and likely needs follow-up care, I decided to discharge the patient. This decision is supported by clinical judgment, considering the patient's stable condition and the need for further evaluation in an outpatient setting.\n"]}],"source":["# --- Run 1: High-Risk Patient Note ---\n","# We'll use visit_id=1 and add a high-risk note\n","inputs_1 = {\n","    \"visit_id\": 1,\n","    \"human_prompt\": \"Patient is 70yo, frail, and on chemotherapy.\"\n","}\n","config = {\"configurable\": {\"thread_id\": \"sim-1\"}}\n","\n","print(\"--- Running Simulation 1 (High-Risk Note) ---\")\n","final_state_1 = graph.invoke(inputs_1, config)\n","\n","print(\"\\n--- Final State 1 ---\")\n","print(f\"Decision: {final_state_1.get('decision')}\")\n","print(f\"P(Admit): {final_state_1.get('p_final'):.4f}\")\n","print(f\"Final Rationale: {final_state_1.get('rationale')}\")\n","print(f\"Fusion Rationale: {final_state_1.get('fusion_rationale')}\")\n","\n","\n","# --- Run 2: Low-Risk Patient Note ---\n","# We'll use visit_id=5 (assuming this is a lower-risk patient in the DB)\n","inputs_2 = {\n","    \"visit_id\": 5,\n","    \"human_prompt\": \"Patient looks stable, likely just needs follow-up.\"\n","}\n","config = {\"configurable\": {\"thread_id\": \"sim-2\"}}\n","\n","print(\"\\n\\n--- Running Simulation 2 (Low-Risk Note) ---\")\n","final_state_2 = graph.invoke(inputs_2, config)\n","\n","print(\"\\n--- Final State 2 ---\")\n","print(f\"Decision: {final_state_2.get('decision')}\")\n","print(f\"P(Admit): {final_state_2.get('p_final'):.4f}\")\n","print(f\"Final Rationale: {final_state_2.get('rationale')}\")\n","print(f\"Fusion Rationale: {final_state_2.get('fusion_rationale')}\")"]},{"cell_type":"markdown","metadata":{"id":"S0crK8shAjMZ"},"source":["Human review test (haven't adjusted good)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2N70s9iy8mhV","outputId":"78d9fdaa-fd7b-45f5-fef8-052d7c46256a","executionInfo":{"status":"ok","timestamp":1764611705751,"user_tz":300,"elapsed":4817,"user":{"displayName":"Alvin Yao","userId":"12743048314903098274"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Running Simulation 2 (Low-Risk Note) — Phase 1 (until interrupt) ---\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=fetch_data_INPUT\n","--- 1. Fetching data for visit_id: 5 (execution_id: 619ae2c5-7fa2-4890-81da-4de02ba7b129) ---\n","[PERF] fetch_data_node took 6.21ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=fetch_data_OUTPUT duration=10.68ms\n","{'fetch_data': {'execution_id': '619ae2c5-7fa2-4890-81da-4de02ba7b129', 'patient_data': {'visit_id': 5, 'patient_id': 'aa17128506622ee5', 'sex': 'Male', 'age_bucket': '18-34', 'heart_rate': 65.0, 'bp_systolic': 187.0, 'bp_diastolic': 77.0, 'resp_rate': 22.0, 'temperature_C': 39.9, 'oxygen_saturation': 91.0, 'recent_admissions_30d': 0, 'admitted': 0, 'triage_notes_redacted': 'the patient presents with chest pain for 2 hours, rated 7/10. Onset after eating dinner, associated with sharp stabbing pain. Denies recent travel or sick contacts. Past medical history includes COPD; Hypertension. Current medications: none reported. Vital signs on arrival: HR 65 bpm, BP 187/77 mmHg, RR 22 breaths/min, Temp 39.9 °C, O₂ sat 91%. Patient triaged as ESI level 3.', 'ESI': 3}, 'vitals_validated': VitalSigns(sex='Male', age_bucket='18-34', heart_rate=65.0, resp_rate=22.0, bp_systolic=187.0, bp_diastolic=77.0, oxygen_saturation=91.0, temperature_C=39.9, ESI=3, mental_status=None, recent_admissions_30d=0), 'triage_text': 'the patient presents with chest pain for 2 hours, rated 7/10. Onset after eating dinner, associated with sharp stabbing pain. Denies recent travel or sick contacts. Past medical history includes COPD; Hypertension. Current medications: none reported. Vital signs on arrival: HR 65 bpm, BP 187/77 mmHg, RR 22 breaths/min, Temp 39.9 °C, O₂ sat 91%. Patient triaged as ESI level 3.'}}\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=severity_gate_INPUT\n","--- 2. Checking severity gate ---\n"," -> OK: Patient is not severe. Proceeding to models.\n","[PERF] severity_gate_node took 0.01ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=severity_gate_OUTPUT duration=2.43ms\n","[Routing] Non-severe case → proceeding to run_models\n","{'severity_gate': {'severe': False}}\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=run_models_INPUT\n","--- 3. Fanning out to parallel models (human_input, llm_model, ml_model) ---\n","[PERF] run_models_node took 0.01ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=run_models_OUTPUT duration=2.83ms\n","{'run_models': None}\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=human_input_INPUT\n","--- 3c. Acknowledging Human Input ---\n"," -> Human Note: 'Patient looks stable, likely just needs follow-up.'\n","[PERF] human_input_node took 0.01ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=ml_model_INPUT\n","--- 3a. Running ML Model ---\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=llm_model_INPUT\n","--- 3b. Running LLM Classifier ---\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=human_input_OUTPUT duration=4.06ms\n"," -> ML Score (P_Admit): 0.0736\n","[PERF] ml_model_node took 17.17ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=ml_model_OUTPUT duration=22.88ms\n","{'human_input': None}\n","{'ml_model': {'ml_score': 0.07359778136014938}}\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> LLM Classifier Score (P_Admit): 0.9807\n","[PERF] llm_model_node took 186.76ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=llm_model_OUTPUT duration=193.91ms\n","{'llm_model': {'llm_score': 0.9806503653526306}}\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=fusion_INPUT\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"," -> Final P(Admit) Score (numeric): 0.5271 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Given the low probability from the ML model (0.07) and the high probability from the LLM classifier (0.98), combined with the clinical context provided by the nurse through the human_note, we decide to discharge the patient. The nurse has indicated that the patient appears stable and probably just needs to follow-up, which aligns with our decision.\n","[PERF] fusion_node took 4477.81ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=fusion_OUTPUT duration=4480.46ms\n","{'fusion': {'fused_prob': 0.52712407335639, 'p_final': 0.52712407335639, 'fusion_decision': 'Discharge', 'fusion_rationale': 'Given the low probability from the ML model (0.07) and the high probability from the LLM classifier (0.98), combined with the clinical context provided by the nurse through the human_note, we decide to discharge the patient. The nurse has indicated that the patient appears stable and probably just needs to follow-up, which aligns with our decision.'}}\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=confidence_check_INPUT\n","--- 5. Confidence Check Node ---\n","[ConfidenceCheck] ml_score=0.0736, llm_score=0.9807, fused_prob=0.5271\n","[PERF] confidence_check_node took 0.01ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=confidence_check_OUTPUT duration=2.70ms\n","[Routing] LOW confidence (gap=0.91, avg=0.53) → human_review\n","{'confidence_check': {'visit_id': 5, 'human_prompt': 'Patient looks stable, likely just needs follow-up.', 'patient_data': {'visit_id': 5, 'patient_id': 'aa17128506622ee5', 'sex': 'Male', 'age_bucket': '18-34', 'heart_rate': 65.0, 'bp_systolic': 187.0, 'bp_diastolic': 77.0, 'resp_rate': 22.0, 'temperature_C': 39.9, 'oxygen_saturation': 91.0, 'recent_admissions_30d': 0, 'admitted': 0, 'triage_notes_redacted': 'the patient presents with chest pain for 2 hours, rated 7/10. Onset after eating dinner, associated with sharp stabbing pain. Denies recent travel or sick contacts. Past medical history includes COPD; Hypertension. Current medications: none reported. Vital signs on arrival: HR 65 bpm, BP 187/77 mmHg, RR 22 breaths/min, Temp 39.9 °C, O₂ sat 91%. Patient triaged as ESI level 3.', 'ESI': 3}, 'vitals_validated': VitalSigns(sex='Male', age_bucket='18-34', heart_rate=65.0, resp_rate=22.0, bp_systolic=187.0, bp_diastolic=77.0, oxygen_saturation=91.0, temperature_C=39.9, ESI=3, mental_status=None, recent_admissions_30d=0), 'triage_text': 'the patient presents with chest pain for 2 hours, rated 7/10. Onset after eating dinner, associated with sharp stabbing pain. Denies recent travel or sick contacts. Past medical history includes COPD; Hypertension. Current medications: none reported. Vital signs on arrival: HR 65 bpm, BP 187/77 mmHg, RR 22 breaths/min, Temp 39.9 °C, O₂ sat 91%. Patient triaged as ESI level 3.', 'ml_score': 0.07359778136014938, 'llm_score': 0.9806503653526306, 'severe': False, 'p_final': 0.52712407335639, 'fused_prob': 0.52712407335639, 'decision': 'ADMIT', 'final_decision': 'ADMIT', 'rationale': 'Fused probability 0.53 ≥ threshold 0.50; patient should be admitted.', 'fusion_decision': 'Discharge', 'fusion_rationale': 'Given the low probability from the ML model (0.07) and the high probability from the LLM classifier (0.98), combined with the clinical context provided by the nurse through the human_note, we decide to discharge the patient. The nurse has indicated that the patient appears stable and probably just needs to follow-up, which aligns with our decision.', 'execution_id': '619ae2c5-7fa2-4890-81da-4de02ba7b129'}}\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=human_review_INPUT\n","--- 6. Human Review Node (HITL) ---\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=human_review_no_override\n","[HITL] No override provided → using original fused_prob=0.5271\n","[PERF] human_review_node took 2.78ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=human_review_OUTPUT duration=5.64ms\n","{'human_review': {'fused_prob': 0.52712407335639, 'p_final': 0.52712407335639}}\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=finalize_INPUT\n","--- 7. Finalize Node ---\n","[Finalize] Using Admission Threshold: 0.5000\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=finalize_node\n","[Finalize] Decision=ADMIT, Rationale=Fused probability 0.53 ≥ threshold 0.50; patient should be admitted.\n","[PERF] finalize_node took 2.80ms\n","[LOG] execution_id=619ae2c5-7fa2-4890-81da-4de02ba7b129 step=finalize_OUTPUT duration=5.28ms\n","{'finalize': {'visit_id': 5, 'human_prompt': 'Patient looks stable, likely just needs follow-up.', 'patient_data': {'visit_id': 5, 'patient_id': 'aa17128506622ee5', 'sex': 'Male', 'age_bucket': '18-34', 'heart_rate': 65.0, 'bp_systolic': 187.0, 'bp_diastolic': 77.0, 'resp_rate': 22.0, 'temperature_C': 39.9, 'oxygen_saturation': 91.0, 'recent_admissions_30d': 0, 'admitted': 0, 'triage_notes_redacted': 'the patient presents with chest pain for 2 hours, rated 7/10. Onset after eating dinner, associated with sharp stabbing pain. Denies recent travel or sick contacts. Past medical history includes COPD; Hypertension. Current medications: none reported. Vital signs on arrival: HR 65 bpm, BP 187/77 mmHg, RR 22 breaths/min, Temp 39.9 °C, O₂ sat 91%. Patient triaged as ESI level 3.', 'ESI': 3}, 'vitals_validated': VitalSigns(sex='Male', age_bucket='18-34', heart_rate=65.0, resp_rate=22.0, bp_systolic=187.0, bp_diastolic=77.0, oxygen_saturation=91.0, temperature_C=39.9, ESI=3, mental_status=None, recent_admissions_30d=0), 'triage_text': 'the patient presents with chest pain for 2 hours, rated 7/10. Onset after eating dinner, associated with sharp stabbing pain. Denies recent travel or sick contacts. Past medical history includes COPD; Hypertension. Current medications: none reported. Vital signs on arrival: HR 65 bpm, BP 187/77 mmHg, RR 22 breaths/min, Temp 39.9 °C, O₂ sat 91%. Patient triaged as ESI level 3.', 'ml_score': 0.07359778136014938, 'llm_score': 0.9806503653526306, 'severe': False, 'p_final': 0.52712407335639, 'fused_prob': 0.52712407335639, 'decision': 'ADMIT', 'final_decision': 'ADMIT', 'rationale': 'Fused probability 0.53 ≥ threshold 0.50; patient should be admitted.', 'fusion_decision': 'Discharge', 'fusion_rationale': 'Given the low probability from the ML model (0.07) and the high probability from the LLM classifier (0.98), combined with the clinical context provided by the nurse through the human_note, we decide to discharge the patient. The nurse has indicated that the patient appears stable and probably just needs to follow-up, which aligns with our decision.', 'execution_id': '619ae2c5-7fa2-4890-81da-4de02ba7b129'}}\n","\n","--- State BEFORE Human Review (Simulation 2) ---\n","Keys: dict_keys(['visit_id', 'human_prompt', 'patient_data', 'vitals_validated', 'triage_text', 'ml_score', 'llm_score', 'severe', 'p_final', 'fused_prob', 'decision', 'final_decision', 'rationale', 'fusion_decision', 'fusion_rationale', 'execution_id'])\n","\n","ML score (p_ml):      0.07359778136014938\n","LLM score (p_llm):    0.9806503653526306\n","Fused P(Admit):       0.52712407335639\n","Fusion Decision:      Discharge\n","Fusion Rationale:     Given the low probability from the ML model (0.07) and the high probability from the LLM classifier (0.98), combined with the clinical context provided by the nurse through the human_note, we decide to discharge the patient. The nurse has indicated that the patient appears stable and probably just needs to follow-up, which aligns with our decision.\n","Original Human Note:  Patient looks stable, likely just needs follow-up.\n"]}],"source":["# ============================================\n","# Simulation 2: Low-Risk Note (HITL demo)\n","# Step 1 — Run until interrupt BEFORE 'human_review'\n","# ============================================\n","\n","inputs_2 = {\n","    \"visit_id\": 5,\n","    \"human_prompt\": \"Patient looks stable, likely just needs follow-up.\"\n","}\n","\n","config_2 = {\"configurable\": {\"thread_id\": \"sim-2\"}}\n","\n","print(\"\\n--- Running Simulation 2 (Low-Risk Note) — Phase 1 (until interrupt) ---\")\n","\n","# 1) Run the graph; it will stop before 'human_review'\n","for event in graph.stream(inputs_2, config_2):\n","    # Each event is a dict like {\"node_name\": {...partial_state_update...}}\n","    print(event)\n","\n","# 2) After the interrupt, fetch the current state from the checkpointer\n","state_before_review = graph.get_state(config_2).values\n","\n","print(\"\\n--- State BEFORE Human Review (Simulation 2) ---\")\n","print(\"Keys:\", state_before_review.keys())\n","\n","# 3) Inspect model / fusion outputs to help the human reviewer\n","print(f\"\\nML score (p_ml):      {state_before_review.get('ml_score')}\")\n","print(f\"LLM score (p_llm):    {state_before_review.get('llm_score')}\")\n","print(f\"Fused P(Admit):       {state_before_review.get('p_final')}\")\n","print(f\"Fusion Decision:      {state_before_review.get('fusion_decision')}\")\n","print(f\"Fusion Rationale:     {state_before_review.get('fusion_rationale')}\")\n","print(f\"Original Human Note:  {state_before_review.get('human_prompt')}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ecdWTC2O8noO","outputId":"3a135613-3d43-4251-fbe4-f7a943378e2a","executionInfo":{"status":"ok","timestamp":1764611727336,"user_tz":300,"elapsed":35,"user":{"displayName":"Alvin Yao","userId":"12743048314903098274"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Applying human_override = 0.15 and resuming the graph...\n","\n","\n","--- Final State 2 (AFTER Human Review) ---\n","Decision:          ADMIT\n","P(Admit):          0.5271\n","Final Rationale:   Fused probability 0.53 ≥ threshold 0.50; patient should be admitted.\n","Fusion Decision:   Discharge\n","Fusion Rationale:  Given the low probability from the ML model (0.07) and the high probability from the LLM classifier (0.98), combined with the clinical context provided by the nurse through the human_note, we decide to discharge the patient. The nurse has indicated that the patient appears stable and probably just needs to follow-up, which aligns with our decision.\n","Human Override:    0.15\n"]}],"source":["# ============================================\n","# Simulation 2: Low-Risk Note (HITL demo)\n","# Step 2 — Apply human_override and resume the graph\n","# ============================================\n","\n","# Example: Human reviewer decides true admission risk is only 0.15\n","# (You can change this value and re-run to see different outcomes.)\n","human_override_value = 0.15\n","\n","print(f\"\\nApplying human_override = {human_override_value:.2f} and resuming the graph...\\n\")\n","\n","# 1) Take previous state and inject human_override\n","updated_values = dict(state_before_review)\n","updated_values[\"human_override\"] = human_override_value\n","\n","# 2) Write back into the graph state\n","graph.update_state(config_2, updated_values)\n","\n","# 3) Resume execution from the interrupt point\n","#    It will now run: human_review -> finalize -> END\n","for event in graph.stream(None, config_2):\n","    print(event)\n","\n","# 4) Fetch the FINAL state after human review and finalize\n","final_state_2 = graph.get_state(config_2).values\n","\n","print(\"\\n--- Final State 2 (AFTER Human Review) ---\")\n","print(f\"Decision:          {final_state_2.get('decision')}\")\n","p2 = final_state_2.get(\"p_final\")\n","print(f\"P(Admit):          {p2:.4f}\" if p2 is not None else \"P(Admit): N/A\")\n","print(f\"Final Rationale:   {final_state_2.get('rationale')}\")\n","print(f\"Fusion Decision:   {final_state_2.get('fusion_decision')}\")\n","print(f\"Fusion Rationale:  {final_state_2.get('fusion_rationale')}\")\n","print(f\"Human Override:    {final_state_2.get('human_override')}\")\n"]},{"cell_type":"markdown","metadata":{"id":"LmQY2UN38iww"},"source":["check"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YmVIcOsUum5B","outputId":"44aa9f11-a441-41f7-d7e4-4a618bfeb184","executionInfo":{"status":"ok","timestamp":1764611736399,"user_tz":300,"elapsed":2217,"user":{"displayName":"Alvin Yao","userId":"12743048314903098274"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["{'decision': 'Error', 'rationale': 'No JSON object found in LLM response.'}\n","Decision from fusion agent: Error\n","Rationale from fusion agent: No JSON object found in LLM response.\n"]}],"source":["test_output = run_fusion_agent(ml_prob=0.81, llm_prob=0.99, human_note=\"70yo, frail, on chemotherapy\")\n","print(test_output)\n","print(\"Decision from fusion agent:\", test_output.get(\"decision\"))\n","print(\"Rationale from fusion agent:\", test_output.get(\"rationale\"))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FPDfZYsftNR6","outputId":"78e95286-4958-43c8-9226-b4fefacbfa6a","executionInfo":{"status":"ok","timestamp":1764611736414,"user_tz":300,"elapsed":7,"user":{"displayName":"Alvin Yao","userId":"12743048314903098274"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["--- Final State 1 RAW ---\n","{'visit_id': 1, 'human_prompt': 'Patient is 70yo, frail, and on chemotherapy.', 'patient_data': {'visit_id': 1, 'patient_id': '2c63e4a66e75f974', 'sex': 'Male', 'age_bucket': '65+', 'heart_rate': 148.0, 'bp_systolic': 182.0, 'bp_diastolic': 67.0, 'resp_rate': 29.0, 'temperature_C': 37.8, 'oxygen_saturation': 94.0, 'recent_admissions_30d': 0, 'admitted': 1, 'triage_notes_redacted': 'the patient presents with fever for 2 hours, rated 7/10. Onset after a fall, associated with productive cough. Denies recent travel or sick contacts. Past medical history includes no significant history. Current medications: metformin. Vital signs on arrival: HR 148 bpm, BP 182/67 mmHg, RR 29 breaths/min, Temp 37.8 °C, O₂ sat 94%. Patient triaged as ESI level 5.', 'ESI': 5}, 'vitals_validated': VitalSigns(sex='Male', age_bucket='65+', heart_rate=148.0, resp_rate=29.0, bp_systolic=182.0, bp_diastolic=67.0, oxygen_saturation=94.0, temperature_C=37.8, ESI=5, mental_status=None, recent_admissions_30d=0), 'triage_text': 'the patient presents with fever for 2 hours, rated 7/10. Onset after a fall, associated with productive cough. Denies recent travel or sick contacts. Past medical history includes no significant history. Current medications: metformin. Vital signs on arrival: HR 148 bpm, BP 182/67 mmHg, RR 29 breaths/min, Temp 37.8 °C, O₂ sat 94%. Patient triaged as ESI level 5.', 'ml_score': 0.8551725149154663, 'llm_score': 0.9898709654808044, 'severe': False, 'p_final': 0.9225217401981354, 'fused_prob': 0.9225217401981354, 'decision': 'ADMIT', 'final_decision': 'ADMIT', 'rationale': 'Fused probability 0.92 ≥ threshold 0.50; patient should be admitted.', 'fusion_decision': 'Admit', 'fusion_rationale': 'Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.923. Decision: Admit.', 'execution_id': '619ae2c5-7fa2-4890-81da-4de02ba7b129'}\n","--- Keys ---\n","dict_keys(['visit_id', 'human_prompt', 'patient_data', 'vitals_validated', 'triage_text', 'ml_score', 'llm_score', 'severe', 'p_final', 'fused_prob', 'decision', 'final_decision', 'rationale', 'fusion_decision', 'fusion_rationale', 'execution_id'])\n"]}],"source":["print(\"--- Final State 1 RAW ---\")\n","print(final_state_1)\n","print(\"--- Keys ---\")\n","print(final_state_1.keys())\n"]},{"cell_type":"markdown","metadata":{"id":"goybhQz9NqyV"},"source":["## Evaluate the Graph"]},{"cell_type":"markdown","metadata":{"id":"SF7KWaXTNtvh"},"source":["To maintain consistency, we will be using the 4200-row csv dataset that was used to train/test the LLM Classifier and the ML Model. The purpose of the graph workflow above using a database is to simulate a real-world workflow. For evaluation, we will be using a csv format."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UXUhfU4lNsxy"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"56VRBOWrODRw","outputId":"222f9777-5625-441b-cb93-4e8324fd42b3","executionInfo":{"status":"ok","timestamp":1764611740355,"user_tz":300,"elapsed":26,"user":{"displayName":"Alvin Yao","userId":"12743048314903098274"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded 4200 rows from /content/drive/MyDrive/Work/Capstone-TeamFolder/Capstone_Organized/1-Data/ED_Model_Training_Dataset.csv.\n"]}],"source":["INPUT_CSV_PATH = os.path.join(BASE_PATH + \"/1-Data/ED_Model_Training_Dataset.csv\")\n","\n","df_full = pd.read_csv(INPUT_CSV_PATH)\n","df_full = df_full.dropna().reset_index(drop=True)\n","print(f\"Loaded {len(df_full)} rows from {INPUT_CSV_PATH}.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nh22rg3KDcpx"},"outputs":[],"source":["# PII MASKING: age\n","\n","def bucket_age(a):\n","    \"\"\"Bins the age column into categorical ranges.\"\"\"\n","    if pd.isna(a): return None\n","    a = int(a)\n","    if a <= 17: return \"0-17\"\n","    if a <= 34: return \"18-34\"\n","    if a <= 49: return \"35-49\"\n","    if a <= 64: return \"50-64\"\n","    return \"65+\"\n","\n","df_full[\"age_bucket\"] = df_full[\"age\"].apply(bucket_age)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6JMtIoLSGbC9","outputId":"8f8e0284-3c8a-4b88-e6ad-5d7e839c15e9","executionInfo":{"status":"ok","timestamp":1764611743399,"user_tz":300,"elapsed":156,"user":{"displayName":"Alvin Yao","userId":"12743048314903098274"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Original Note:\n","the patient presents with fever for 2 hours, rated 7/10. Onset after a fall, associated with productive cough. Denies recent travel or sick contacts. Past medical history includes no significant history. Current medications: metformin. Vital signs on arrival: HR 148 bpm, BP 182/67 mmHg, RR 29 breaths/min, Temp 37.8 °C, O₂ sat 94%. Patient triaged as ESI level 5.\n"]}],"source":["# PII MASKING: triage_notes\n","\n","EMAIL_RE  = re.compile(r\"\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b\", re.IGNORECASE)\n","PHONE_RE  = re.compile(r\"\\b(?:\\+?1[-.\\s]?)?(?:\\(?\\d{3}\\)?[-.\\s]?)?\\d{3}[-.\\s]?\\d{4}\\b\")\n","SSN_RE    = re.compile(r\"\\b\\d{3}-?\\d{2}-?\\d{4}\\b\")\n","DATE_RE   = re.compile(r\"\\b(?:\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}|\\d{4}-\\d{2}-\\d{2})\\b\")\n","\n","# Normalize unicode dashes to ASCII hyphen\n","DASHES = dict.fromkeys(map(ord, \"\\u2010\\u2011\\u2012\\u2013\\u2014\\u2015\"), \"-\")\n","\n","AGE_PATTERNS = [\n","    re.compile(r\"\\b(\\d{1,3})\\W*(?:year|yrs?|yo|y\\/?o)\\W*(?:old|of\\s+age)?\\b\", re.IGNORECASE), # Catch X-year-old, X y/o, X yrs, etc.\n","    re.compile(r\"\\bage[d]?\\s*(\\d{1,3})\\b\", re.IGNORECASE), # Catch aged X / age X\n","    re.compile(r\"\\b(in\\s+(?:his|her|their|a|the)\\s+)\\d{2}s\\b\", re.IGNORECASE) # Catching decades (in his 40s)\n","]\n","\n","# Gendered words/titles and pronouns\n","GENDER_RE   = re.compile(r\"\\b(male|female|man|woman|boy|girl|gentleman|lady|mr\\.?|mrs\\.?|ms\\.?)\\b\", re.IGNORECASE)\n","PRONOUN_RE  = re.compile(r\"\\b(he|she|him|her|his|hers)\\b\", re.IGNORECASE)\n","_PRONOUN_MAP = {'he':'they','she':'they','him':'them','her':'them','his':'their','hers':'their'}\n","\n","def _neutralize_pronouns(text: str) -> str:\n","    def _sub(m):\n","        src = m.group(1)\n","        repl = _PRONOUN_MAP[src.lower()]\n","        if src.isupper():     return repl.upper()\n","        if src[0].isupper():  return repl.capitalize()\n","        return repl\n","    return PRONOUN_RE.sub(_sub, text)\n","\n","def _remove_age(m):\n","    \"\"\"Removes the entire matched age phrase.\"\"\"\n","    return \"\"\n","\n","def redact_text(s):\n","    \"\"\"Redact PII + demographics; REMOVES all numeric ages.\"\"\"\n","    if pd.isna(s):\n","        return None\n","    t = str(s).translate(DASHES)\n","\n","    # PII\n","    t = EMAIL_RE.sub(\"[EMAIL]\", t)\n","    t = PHONE_RE.sub(\"[PHONE]\", t)\n","    t = SSN_RE.sub(\"[SSN]\", t)\n","    t = DATE_RE.sub(\"[DATE]\", t)\n","\n","    # Ages → REMOVE (using the aggressive patterns above)\n","    for rx in AGE_PATTERNS:\n","        # This replaces the entire matched phrase (e.g., \"67-year-old\") with \"[AGE]\"\n","        t = rx.sub(_remove_age, t)\n","\n","    # Gendered terms and pronouns\n","    t = GENDER_RE.sub(\"the patient\", t)\n","    t = _neutralize_pronouns(t)\n","\n","    return re.sub(r\"\\s+\", \" \", t).strip()\n","\n","df_full[\"triage_notes_redacted\"] = df_full[\"triage_notes\"].apply(redact_text)\n","test_note_redacted = df_full[\"triage_notes_redacted\"].iloc[0]\n","print(\"\\nOriginal Note:\")\n","print(test_note_redacted)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Daf5SDdkTbaB","outputId":"137eee3f-8aab-498c-b3ff-20d7af075ecc","executionInfo":{"status":"ok","timestamp":1764611746256,"user_tz":300,"elapsed":46,"user":{"displayName":"Alvin Yao","userId":"12743048314903098274"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 4200 entries, 0 to 4199\n","Data columns (total 12 columns):\n"," #   Column                 Non-Null Count  Dtype  \n","---  ------                 --------------  -----  \n"," 0   sex                    4200 non-null   object \n"," 1   heart_rate             4200 non-null   int64  \n"," 2   bp_systolic            4200 non-null   int64  \n"," 3   bp_diastolic           4200 non-null   int64  \n"," 4   resp_rate              4200 non-null   int64  \n"," 5   temperature_C          4200 non-null   float64\n"," 6   oxygen_saturation      4200 non-null   float64\n"," 7   ESI                    4200 non-null   int64  \n"," 8   recent_admissions_30d  4200 non-null   int64  \n"," 9   admitted               4200 non-null   int64  \n"," 10  age_bucket             4200 non-null   object \n"," 11  triage_notes_redacted  4200 non-null   object \n","dtypes: float64(2), int64(7), object(3)\n","memory usage: 393.9+ KB\n"]}],"source":["df_full = df_full.drop(columns=['triage_notes', 'age'])\n","\n","df_full.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5yhyRXS7OifO"},"outputs":[],"source":["TARGET_COLUMN = 'admitted'\n","y = df_full[TARGET_COLUMN]\n","X = df_full.drop(columns=[TARGET_COLUMN])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MiJuwYx6Ojk5","outputId":"518d0a58-2f00-47d3-d2d8-cc5361ea56a3","executionInfo":{"status":"ok","timestamp":1764611750991,"user_tz":300,"elapsed":15,"user":{"displayName":"Alvin Yao","userId":"12743048314903098274"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Created evaluation set with 840 patients.\n"]}],"source":["_, X_test, _, y_test = train_test_split(\n","    X, y,\n","    test_size=0.2,\n","    random_state=14,\n","    stratify=y\n",")\n","\n","test_patients = X_test.to_dict('records')\n","true_labels = y_test.tolist()\n","\n","print(f\"Created evaluation set with {len(test_patients)} patients.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Pt1NaYniSTXf","outputId":"cfe20235-ed88-4f85-d80d-ac32f978e705","executionInfo":{"status":"ok","timestamp":1764614434816,"user_tz":300,"elapsed":2681416,"user":{"displayName":"Alvin Yao","userId":"12743048314903098274"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Running Head-to-Head evaluation on 840 test patients...\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/840 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 1/840 [00:00<11:49,  1.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3910 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.391. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 2/840 [00:02<19:04,  1.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3048 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the given information, the patient's high risk factors justify admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 3/840 [00:03<18:35,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1530 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Insufficient clinical evidence to justify admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 4/840 [00:08<34:42,  2.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0612 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Given the low probabilities from both the ML model (p_ml: 0.07) and LLM classifier (p_llm: 0.05), and the lack of specific clinical context provided by the human_note, it is reasonable to admit the patient for further evaluation to rule out potentially serious conditions.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|          | 5/840 [00:08<25:15,  1.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4876 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.488. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|          | 6/840 [00:11<30:41,  2.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2550 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Clinical decision made based on p_ml (0.37) and lack of information from p_llm (0.14) and human_note, indicating a high risk scenario necessitating hospital admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|          | 7/840 [00:13<27:42,  2.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4600 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): ...(explain why based on the inputs provided)\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|          | 8/840 [00:18<40:27,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3216 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.322. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|          | 9/840 [00:22<46:40,  3.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3010 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.301. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|          | 10/840 [00:24<42:28,  3.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5850 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.585. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|▏         | 11/840 [00:25<31:21,  2.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1381 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.138. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  1%|▏         | 12/840 [00:28<36:52,  2.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5397 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.540. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  2%|▏         | 13/840 [00:31<35:07,  2.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3532 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge is chosen based on low p_ml and lack of specific clinical indications provided in p_llm and human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  2%|▏         | 14/840 [00:34<39:48,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1688 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient due to the high likelihood of admission indicated by both the ML model (p_ml: 0.19) and the LLM classifier (p_llm: 0.15), despite no human note being provided.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  2%|▏         | 15/840 [00:39<46:17,  3.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0941 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the low probabilities from both the ML model (p_ml: 0.10) and LLM classifier (p_llm: 0.09), indicating a lower likelihood of discharge. The absence of a human_note suggests a more objective, evidence-based rationale for admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  2%|▏         | 16/840 [00:43<47:47,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4471 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient due to the high risk indicated by both the ML model (p_ml=0.24) and the LLM classifier (p_llm=0.65), as there is no additional clinical context provided in the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  2%|▏         | 17/840 [00:47<52:37,  3.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2028 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the combined evidence from the ML model (p_ml=0.25) and the LLM classifier (p_llm=0.15), which indicates a higher likelihood of requiring hospitalization. The absence of a detailed human note suggesting a clear clinical justification for discharge prompts the decision to admit for further evaluation and management.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  2%|▏         | 18/840 [00:48<38:37,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3650 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.365. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  2%|▏         | 19/840 [00:51<41:00,  3.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3535 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the clinical context, the combination of signals—p_ml (0.42), p_llm (0.29), and the absence of a human note—suggests a higher risk of serious health issues, prompting an admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  2%|▏         | 20/840 [00:56<48:59,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0698 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to discharge is made due to the absence of clinical indications for admission, as evidenced by the low probabilities from both the ML model (0.01) and LLM classifier (0.13), and the lack of any human note providing real-time context that would support admission. Stable symptoms and no immediate risk factors contribute to the decision to discharges the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  2%|▎         | 21/840 [01:00<52:05,  3.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2866 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the low p_llm (LLM classifier) and absence of a detailed human_note, I am relying on the higher p_ml (ML model) to make a clinical decision to admit the patient. The absence of specific clinical information in the human_note suggests that there is no clear indication for discharge, hence admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  3%|▎         | 22/840 [01:05<53:23,  3.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1569 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is made considering the low p_ml (0.07) and p_llm (0.24), and the absence of a human note which would have provided valuable real-time clinical context. The decision is supported by the lack of information indicating stable symptoms or the need for discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  3%|▎         | 23/840 [01:09<54:51,  4.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3359 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The low probability outputs from both the ML model (p_ml) and LLM classifier (p_llm) suggest that the patient's symptoms are not indicative of an acute condition requiring immediate medical intervention. Despite the lack of a human_note, the clinical decision made by the AI model aligns with a discharge outcome.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  3%|▎         | 24/840 [01:09<39:47,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3759 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.376. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  3%|▎         | 25/840 [01:12<40:02,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2976 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient due to the absence of clinical improvement, as indicated by both the ML model and LLM classifier providing low probabilities, and the lack of a human note which could suggest otherwise.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  3%|▎         | 26/840 [01:18<49:35,  3.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2446 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the high probability from the ML model (p_ml = 0.20), which indicates a higher risk that would justify admission. The LLM classifier's probability (p_llm = 0.29) also supports this decision but the lack of additional clinical context in the human_note suggests that the ML model's risk assessment is the most critical factor for this admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  3%|▎         | 27/840 [01:18<35:48,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2443 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.244. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  3%|▎         | 28/840 [01:21<36:52,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3185 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Clinical decision made based on ML model (0.17), LLM classifier (0.47), and absence of relevant human context. Patient's condition is suspect but not clearly indicated for discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  3%|▎         | 29/840 [01:22<31:54,  2.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3635 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.363. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▎         | 30/840 [01:24<28:29,  2.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3537 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): No clinical evidence to support admission based on the given information.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▎         | 31/840 [01:27<33:56,  2.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5109 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.511. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 32/840 [01:31<38:56,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3301 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.330. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 33/840 [01:34<38:51,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5154 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient due to the higher likelihood from the LLM classifier (0.78) and considering the absence of a clear clinical context provided by the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 34/840 [01:38<44:50,  3.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3642 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the given information, the LLM classifier suggests a lower probability of admission (0.31) compared to the ML model (0.42). Since no human_note is provided, I cannot consider any additional clinical context. Therefore, I will follow the LLM's suggestion and discharge the patient, considering it a stable case.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 35/840 [01:43<48:25,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1772 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the presented signals, the low ML probability (0.01), medium LLM probability (0.35), and absence of a human note, it is decided to admit the patient. This is due to the lack of contextual information indicating the patient's condition, which would normally guide a discharge decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 36/840 [01:45<44:29,  3.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2164 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the patient's high risk factors indicated in the human_note, despite the lower probabilities from the ML and LLM models.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  4%|▍         | 37/840 [01:48<41:34,  3.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2089 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the insufficient information provided, I am unable to make a justifiable decision. Further clinical assessment and documentation are required to proceed with an admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  5%|▍         | 38/840 [01:49<34:59,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4602 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Rationale not provided by the user.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  5%|▍         | 39/840 [01:52<33:34,  2.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2867 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge is chosen as p_llm is higher than p_ml and there is no explicit clinical indication from the human_note to admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  5%|▍         | 40/840 [01:55<38:46,  2.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4240 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to discharge the patient is based on the lack of clinical indication for admission as evidenced by the low ML model probability (0.11), the moderate LLM classifier probability (0.74), and the absence of a human note providing additional context for admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  5%|▍         | 41/840 [01:58<37:03,  2.78s/it]"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5350 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Given the high probability from the ML model (0.88) and the absence of a human note suggesting otherwise, I decided to admit the patient.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  5%|▌         | 42/840 [02:02<41:58,  3.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3551 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.355. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  5%|▌         | 43/840 [02:05<41:48,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4638 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.464. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  5%|▌         | 44/840 [02:08<42:58,  3.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2669 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient due to the absence of clinical context provided by the human_note, which suggests a lack of stability to warrant discharge based on the low p_llm score (0.04) indicating less likelihood of needing admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  5%|▌         | 46/840 [02:10<27:44,  2.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2677 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.268. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 47/840 [02:18<45:29,  3.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.8387 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.839. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 48/840 [02:19<39:53,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1137 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.114. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 49/840 [02:22<40:02,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5475 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The low p_llm value (0.44) suggests a lower confidence in the LLM classifier's prediction of admission. Additionally, the absence of a provided human_note further supports a 'Discharge' decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 50/840 [02:25<38:30,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2091 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): ML and LLM signals are inconclusive, but the absence of a high-risk signal from the human_note suggests a lower risk, thus admitting the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 51/840 [02:27<36:06,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1255 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.125. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▌         | 52/840 [02:32<41:59,  3.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2974 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.297. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▋         | 53/840 [02:34<38:18,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1792 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Absence of high-risk factors and low probabilities from both ML and LLM models suggest clinical stability, hence discharge is indicated.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  6%|▋         | 54/840 [02:37<39:59,  3.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1729 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.173. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  7%|▋         | 55/840 [02:42<44:48,  3.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4875 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.487. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  7%|▋         | 56/840 [02:42<32:33,  2.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1519 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.152. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  7%|▋         | 57/840 [02:44<30:22,  2.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1512 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.151. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  7%|▋         | 58/840 [02:46<30:39,  2.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5158 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.516. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  7%|▋         | 59/840 [02:51<38:52,  2.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3126 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the LLM classifier's probability of 0.58, which suggests a higher likelihood of requiring admission compared to the ML model's probability of 0.05. Without additional clinical context from the human_note, the LLM classifier's output is weighed more heavily in favor of admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  7%|▋         | 60/840 [02:56<49:00,  3.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2222 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.222. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  7%|▋         | 61/840 [03:02<57:02,  4.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1146 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Due to the lack of information from the nurse or physician's note, I made the decision to admit the patient based on a higher probability from the models. The LLM model suggests a 0.10 probability of admission, which is not sufficient to justify a discharge alone. The ML model provides an even higher probability of 0.13, further supporting the admission decision. Considering these values, it is more appropriate to admit the patient for further evaluation and treatment.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  7%|▋         | 62/840 [03:06<56:02,  4.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1931 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the clinical judgment that, despite the lower probabilities from the models (0.26 from ML and 0.12 from LLM), the absence of a clear explanation or context in the human_note suggests a higher risk or need for inpatient evaluation. \n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 63/840 [03:10<52:49,  4.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6155 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Clinical judgment suggests admission due to the unstable condition indicated by the high LLM probability, even though the ML model shows a lower probability of admission. Absence of human note does not influence the decision, as it is already leaning towards admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 64/840 [03:13<50:12,  3.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1337 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Insufficient evidence to justify admission. The low scores from both the ML model and LLM classifier do not support admission. Furthermore, the absence of a human_note makes it difficult to assess the patient's condition from a clinical perspective.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 65/840 [03:17<50:15,  3.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2346 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge decision is supported by both the ML model (p_ml = 0.07) and the LLM classifier (p_llm = 0.40). Absence of a human note suggests stable symptoms and lack of high-risk factors, leading to a discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 66/840 [03:22<52:08,  4.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4424 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the given information, the LLM classifier's probability of admission (0.46) is higher than the ML model's probability (0.42), suggesting a stronger indication for admission. However, without a human_note providing specific clinical context, the final decision is made based on the higher LLM probability, indicating a discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 67/840 [03:27<57:21,  4.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1870 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.187. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 68/840 [03:28<42:17,  3.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1776 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.178. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 69/840 [03:31<43:31,  3.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0894 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient due to the lack of specific information provided by the nurse or physician, as well as the lower confidence levels from both the ML model (0.12) and LLM classifier (0.06), indicating a need for further clinical evaluation.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 70/840 [03:35<45:44,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6016 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the clinical context, the combined signals from the ML model (0.42) and LLM classifier (0.78) suggest a higher likelihood of admission. However, since the human note does not provide specific context, we consider the combined probabilities and make a conservative decision to admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  8%|▊         | 71/840 [03:40<51:03,  3.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2695 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the information given, the patient's low likelihood of admission from both the ML model (p_ml) and LLM classifier (p_llm), combined with the absence of a human note providing additional context, suggests a discharge is more appropriate. In such cases, it is important to monitor the patient's condition for any changes that might warrant a reevaluation or further intervention.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  9%|▊         | 72/840 [03:40<36:56,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2632 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.263. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  9%|▊         | 73/840 [03:43<37:06,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3673 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is to admit the patient due to the moderate-severe symptoms and increased risk factors indicated in the human note, despite lower probabilities from the p_ml and p_llm models.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  9%|▉         | 74/840 [03:47<41:22,  3.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3593 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.359. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  9%|▉         | 75/840 [03:54<55:05,  4.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2713 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.271. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  9%|▉         | 76/840 [03:55<42:04,  3.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4542 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.454. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  9%|▉         | 77/840 [03:59<45:49,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2760 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to discharge the patient is based on the low probabilities from both the ML model (p_ml=0.12) and the LLM classifier (p_llm=0.43), indicating a lack of strong evidence for admission. No specific clinical concerns were noted in the human_note, further supporting the decision to discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  9%|▉         | 78/840 [04:02<43:19,  3.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2839 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient due to a high risk score from both the ML model (0.11) and LLM classifier (0.46), despite no specific details provided in the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r  9%|▉         | 79/840 [04:06<43:16,  3.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2309 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.231. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|▉         | 80/840 [04:10<45:32,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2376 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is made based on the combination of low p_llm and the absence of a human note, indicating potentially high risk or unclear clinical context that warrants closer observation. Additionally, as per protocol, any patient with a p_ml over 0.30 is considered for admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|▉         | 81/840 [04:13<44:00,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1903 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge decision based on stable symptoms and low probability scores from both p_ml (0.08) and p_llm (0.30). No specific clinical indicators for admission as per the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|▉         | 82/840 [04:18<49:11,  3.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2029 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the given information, the decision to discharge is made because no significant clinical deterioration is indicated by either the ML model (p_ml: 0.09) or the LLM classifier (p_llm: 0.31). Absence of a human_note suggests that the patient's condition is stable, and there are no urgent indications for admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|▉         | 83/840 [04:23<51:41,  4.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4070 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to admit the patient is based on the elevated p_llm value of 0.46, indicating a higher likelihood of admission compared to the p_ml value of 0.35. Without further information from the human_note, the clinical reasoning supports the admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 84/840 [04:28<55:19,  4.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5298 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the high probability from the ML model (p_ml=0.57) which indicates a higher risk, outweighing the lower probability from the LLM classifier (p_llm=0.49) and the absence of a human note. Although the human note could provide valuable real-time context, the clinical decision was made solely on the basis of the numerical probabilities.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 85/840 [04:30<49:30,  3.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2817 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is made based on the combined clinical context provided by the ML model (p_ml) and the LLM classifier (p_llm), as no human_note is available.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 86/840 [04:31<35:53,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2847 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.285. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 87/840 [04:34<38:54,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2634 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to discharge is made based on the low probability outputs from both the ML model (p_ml: 0.07) and the LLM classifier (p_llm: 0.46), without any additional clinical context provided in the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 10%|█         | 88/840 [04:39<42:28,  3.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2820 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Clinical judgment is based on the combination of low ML probability (0.15), moderate LLM probability (0.41), and the absence of a human note indicating stability. This leads to the decision to admit the patient to assess for any undiagnosed conditions or worsening symptoms.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 11%|█         | 89/840 [04:42<43:55,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2791 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the given information, the low probability scores from both p_ml (0.08) and p_llm (0.48) suggest a lower risk of admission. Since no human_note is provided, I am relying on the scores to make a discharge decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 11%|█         | 90/840 [04:45<40:07,  3.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3219 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The patient's symptoms are consistent with a high-risk clinical scenario, warranting admission despite the moderate probabilities from both the ML model and LLM classifier.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 11%|█         | 91/840 [04:49<42:48,  3.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5111 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the higher likelihood from the LLM classifier (p_llm = 0.62) and clinical judgment that an admission is warranted despite the ML model's lower probability (p_ml = 0.40) and absence of a specific human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 11%|█         | 92/840 [04:53<47:22,  3.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3282 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the ML model and LLM classifier, the probabilities of admission are low (0.17 for ML and 0.48 for LLM). However, as no human_note is provided, I am unable to consider the clinical context. Therefore, I will err on the side of admitting the patient to ensure a thorough evaluation and appropriate care.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 11%|█         | 93/840 [04:57<46:02,  3.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4854 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitted due to high p_llm (0.72) indicating a more severe condition than p_ml (0.25), which suggests a less severe condition. No specific details provided in the human_note justify the admission decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 11%|█         | 94/840 [05:00<44:46,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2583 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is 'Discharge' based on the lack of explicit clinical indicators to admit, despite the lower probabilities from both p_ml and p_llm. No specific clinical justification can be provided without further information from the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 11%|█▏        | 95/840 [05:03<41:09,  3.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4002 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to admit is based on the combination of p_ml (0.57) and the absence of a human note, indicating a lack of contradicting contextual information.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 11%|█▏        | 96/840 [05:07<45:05,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6628 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the information provided, the LLM classifier's probability of admission (0.89) is much higher than the ML model's probability (0.44), indicating a higher confidence in the decision to discharge the patient. However, since no human_note was provided, I have made the decision based solely on the numerical probabilities.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 97/840 [05:09<35:58,  2.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5622 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.562. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 98/840 [05:11<33:53,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1953 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The patient's symptoms are indicative of an acute condition that requires immediate medical attention.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 99/840 [05:16<41:39,  3.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3657 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.366. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 100/840 [05:16<31:18,  2.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2978 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.298. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 101/840 [05:20<35:05,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4452 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The triage protocol recommends admitting patients with higher risk, as indicated by both the ML model (p_ml = 0.65) and the LLM classifier (p_llm = 0.24), even in the absence of a human note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 102/840 [05:24<41:16,  3.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3361 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the high probability output from the LLM classifier (0.60), despite the lower ML model probability (0.07), as there is no additional contextual information provided in the human_note. Clinically, the patient is considered at high risk, necessitating further medical evaluation and management in a hospital setting.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 103/840 [05:27<40:07,  3.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4676 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.468. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▏        | 104/840 [05:30<35:39,  2.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3129 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Clinical judgment overrules lower probabilities from models due to reported heart-related symptoms in the human note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 12%|█▎        | 105/840 [05:31<31:17,  2.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2205 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.220. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 13%|█▎        | 106/840 [05:33<28:28,  2.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4997 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Increased likelihood from LLM classifier justifies admission despite lower ML model probability.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 13%|█▎        | 107/840 [05:38<36:54,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3449 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): I chose 'Discharge' based on the p_llm of 0.60, which indicates a moderate likelihood of admission. However, without a nurse's or physician's clinical context provided in the human_note, I prioritize the model's output, and p_llm suggests the patient is not acute or high-risk, hence 'Discharge' is appropriate.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 13%|█▎        | 108/840 [05:39<28:55,  2.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3318 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.332. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 13%|█▎        | 109/840 [05:40<27:12,  2.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3019 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Clinical decision made without an explicit 'Admit' recommendation from any of the signals.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 13%|█▎        | 110/840 [05:44<31:36,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3459 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.346. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 13%|█▎        | 111/840 [05:46<29:21,  2.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2430 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.243. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 13%|█▎        | 112/840 [05:51<37:28,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2553 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the combined information from the ML model (p_ml = 0.32), the LLM classifier (p_llm = 0.20), and the absence of a human note. Despite the low scores from both models, the lack of specific contextual information leads to a cautious approach and admission of the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 13%|█▎        | 113/840 [05:55<42:54,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2944 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.294. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▎        | 114/840 [05:56<31:36,  2.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4182 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.418. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▎        | 115/840 [06:01<40:07,  3.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2475 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is made based on the LLM classifier's higher probability of 0.44, which suggests a higher likelihood of requiring admission compared to the ML model's lower probability of 0.06. Without additional clinical context provided by the human_note, the decision is primarily guided by the numerical probabilities and does not indicate any specific clinical reason for choosing 'Admit'.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 116/840 [06:04<41:08,  3.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0914 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the insufficient output from the ML model (0.00), moderate support from the LLM classifier (0.18), and the absence of clarifying information in the human_note, I decided to admit the patient to further evaluate and manage potential health issues.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 117/840 [06:08<41:46,  3.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2583 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.258. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 118/840 [06:08<30:26,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4509 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.451. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 119/840 [06:13<37:25,  3.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2259 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The patient's low scores on both the ML model and LLM classifier suggest a higher risk profile. Given the absence of a human note, I am unable to consider stable symptoms or any other context that might influence a discharge decision. Therefore, based on the available information, it is advisable to admit the patient for further evaluation and management.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 120/840 [06:16<37:52,  3.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2546 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.255. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 14%|█▍        | 121/840 [06:20<42:02,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2150 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the high risk as indicated by the absence of a human note, despite lower probabilities from both the ML model (0.06) and LLM classifier (0.37). Without additional contextual information, it is prudent to err on the side of caution and admit the patient for further evaluation.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 15%|█▍        | 122/840 [06:24<43:50,  3.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6954 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.695. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 15%|█▍        | 123/840 [06:27<41:40,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5082 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.508. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 15%|█▍        | 124/840 [06:31<41:19,  3.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6456 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.646. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 15%|█▍        | 125/840 [06:34<41:25,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2992 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.299. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 15%|█▌        | 126/840 [06:36<33:40,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3202 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): No justification provided.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 15%|█▌        | 127/840 [06:39<35:09,  2.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1449 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.145. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 15%|█▌        | 128/840 [06:39<26:11,  2.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1046 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.105. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 15%|█▌        | 129/840 [06:43<29:52,  2.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4243 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.424. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 15%|█▌        | 130/840 [06:47<35:44,  3.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1187 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to admit the patient is based on the low p_ml and lack of additional clinical context provided by the human_note. Despite the relatively higher p_llm, the absence of specific symptoms or findings from the nurse or physician's note suggests that immediate admission is necessary to further evaluate and manage any potential underlying conditions.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 131/840 [06:47<27:28,  2.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1688 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.169. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 132/840 [06:48<20:18,  1.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4143 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.414. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 133/840 [06:48<15:40,  1.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6668 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.667. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 134/840 [06:51<22:42,  1.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1984 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.198. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 135/840 [06:56<30:13,  2.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2243 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.224. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▌        | 136/840 [06:59<32:57,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2937 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.294. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▋        | 137/840 [07:00<26:14,  2.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3362 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.336. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 16%|█▋        | 138/840 [07:02<25:22,  2.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1935 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.194. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 17%|█▋        | 139/840 [07:07<34:42,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6407 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to admit is based on the high probability of admission from the traditional ML model (p_ml=0.77), which outweighs the lower probability from the LLM classifier (p_llm=0.52). Absence of a human note does not provide sufficient real-time context to justify a discharge. Therefore, it is clinically sound to admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 17%|█▋        | 140/840 [07:07<25:26,  2.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2379 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.238. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 17%|█▋        | 141/840 [07:11<31:26,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4157 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): I decided to discharge the patient because there was no human note provided, indicating the lack of serious clinical indicators for admission. The ML model (p_ml) and LLM classifier (p_llm) do not suggest admission either, further supporting the decision to discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 17%|█▋        | 142/840 [07:12<26:36,  2.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6410 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): clinical_justification\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 17%|█▋        | 143/840 [07:15<27:23,  2.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5382 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.538. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 17%|█▋        | 144/840 [07:19<34:35,  2.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1416 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the given information, the patient's low probability scores from both the ML model (0.05) and LLM classifier (0.23) indicate a lower risk. Additionally, the absence of a human note fails to provide any clinical context to justify admission. Therefore, the most appropriate decision is to discharge the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 17%|█▋        | 145/840 [07:23<35:45,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4095 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.410. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 17%|█▋        | 146/840 [07:25<31:54,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3130 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.313. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 147/840 [07:25<23:24,  2.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1592 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.159. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 148/840 [07:29<31:25,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3084 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.308. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 149/840 [07:30<24:04,  2.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3886 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.389. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 150/840 [07:34<32:00,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4202 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the clinical assessment that includes a high level of risk associated with the patient's condition, despite the lower probabilities from p_ml and p_llm. The absence of a clear discharge recommendation in the human_note suggests that a cautious approach, aligning with the higher risk indicators, is necessary at this time.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 151/840 [07:38<34:59,  3.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2481 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.248. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 152/840 [07:42<39:39,  3.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6667 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The patient's clinical presentation is highly suggestive of a serious condition necessitating hospital admission. Despite the lower probabilities from the ML and LLM models, the absence of a nursing note does not rule out the possibility of admission given the context. Thus, based on clinical acumen and the information provided, the patient should be admitted.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 153/840 [07:47<45:02,  3.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3672 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.367. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 154/840 [07:49<35:40,  3.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3364 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): [CLINICAL JUSTIFICATION]\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 18%|█▊        | 155/840 [07:54<43:03,  3.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3004 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the probabilities derived from both the ML model (0.45) and LLM classifier (0.15), along with the absence of a human note, I choose to admit the patient. This decision is made based on the principle that clinical judgment should prioritize factors indicating higher risk for serious illness, as there is no contextual information provided to suggest otherwise.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 19%|█▊        | 156/840 [07:54<31:18,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3971 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.397. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 19%|█▊        | 157/840 [07:59<39:25,  3.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2117 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.212. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 19%|█▉        | 158/840 [08:04<43:45,  3.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6071 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.607. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 19%|█▉        | 159/840 [08:08<44:57,  3.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0993 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the low ML model probability (0.13), indicating a lower likelihood of invalidation. However, the clinical judgment from the human_note is not available to provide a more accurate decision. Therefore, a cautious approach is taken, and the patient is admitted to monitor the condition further.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 19%|█▉        | 160/840 [08:13<47:35,  4.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2049 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is made based on the low p_ml (0.08) and the lack of human_note, despite a higher p_llm (0.33). This indicates that while the LLM classifier suggests admission, the decision is primarily driven by the absence of clinical context from the human_note, implying a higher risk scenario that necessitates hospital admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 19%|█▉        | 161/840 [08:16<43:28,  3.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5010 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient due to the higher likelihood suggested by both the ML model (0.38) and LLM classifier (0.63), despite the absence of a human note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 19%|█▉        | 162/840 [08:20<44:32,  3.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1390 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to admit is based on the low probabilities from both the ML model (0.15) and LLM classifier (0.13). Absence of a comprehensive human note suggests that the clinical context is unclear, necessitating a cautious 'Admit' decision to further evaluate the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 19%|█▉        | 163/840 [08:24<45:18,  4.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2165 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the given probabilities, the patient's low p_ml (0.14) and p_llm (0.29) indicate a lower risk. However, the absence of a human_note suggests a lack of clinical context. To ensure a thorough assessment, the patient will be admitted for further evaluation.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|█▉        | 164/840 [08:27<39:23,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2781 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.278. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|█▉        | 165/840 [08:30<40:00,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5246 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The LLM classifier's higher probability of admission (0.64) influenced my decision, despite the ML model suggesting a lower likelihood (0.41). Without any additional clinical context from the human_note, I rely on the quantitative signals to guide my admission decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|█▉        | 166/840 [08:31<29:54,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1692 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.169. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|█▉        | 167/840 [08:35<35:01,  3.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3106 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The low p_ml (0.28) initially suggested a lower likelihood of admission. However, the higher p_llm (0.34) indicated a greater probability. Considering the absence of a human_note, I chose to admit the patient to monitor their condition closely and determine if further intervention is necessary.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 168/840 [08:38<35:01,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1006 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Patient's high risk status based on ML model's probability of admission (0.08) and LLM classifier's probability (0.12), with no additional clinical context provided via human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 169/840 [08:40<30:38,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4406 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.441. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 170/840 [08:43<29:20,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1330 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): (Briefly explain why you chose 'Admit' considering the low ML and LLM probabilities and lack of human context.)\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 171/840 [08:46<31:17,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1839 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge is chosen because the clinical probability based on ML (p_ml) and LLM (p_llm) is low, and no human note is provided to indicate a higher risk or need for admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 20%|██        | 172/840 [08:50<37:01,  3.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2746 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the combination of low p_ml (0.33) and even lower p_llm (0.22), indicating a lower likelihood of admission. However, without additional clinical context from the human_note, it is crucial to err on the side of caution and admit the patient to monitor their condition closely.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 21%|██        | 173/840 [08:53<34:29,  3.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.7900 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.790. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 21%|██        | 174/840 [08:53<25:36,  2.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3544 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.354. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 21%|██        | 175/840 [08:54<18:56,  1.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2469 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.247. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 21%|██        | 176/840 [08:56<20:36,  1.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3962 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge decision due to low p_llm and absence of specific clinical details in the human_note, despite a moderate p_ml.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 21%|██        | 177/840 [09:01<30:28,  2.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1935 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is made based on the clinical assessment that takes into consideration the low probabilities from both the ML model (0.27) and the LLM classifier (0.11), as well as the absence of a human note that could potentially sway the decision towards discharge. Therefore, based on the available information, admitting the patient is the most appropriate course of action.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 21%|██        | 178/840 [09:03<30:15,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.7273 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the strong ML model prediction (0.90) and lack of human note, the patient's condition suggests a higher risk, thus justifying an admit decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 21%|██▏       | 179/840 [09:06<28:23,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3847 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.385. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 21%|██▏       | 180/840 [09:09<29:53,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2517 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the lack of strong indications from p_ml, p_llm, and the absence of a human note, it is decided that the patient's condition is stable enough to be discharged.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 181/840 [09:14<38:40,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1824 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.182. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 182/840 [09:17<36:04,  3.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1554 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): No human note provided. The LLM classifier suggests a lower admission probability than the ML model. Therefore, based on available information, I chose to discharge the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 183/840 [09:21<38:43,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5121 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the presented probabilities, p_llm (0.83) indicates a higher likelihood of admission compared to p_ml (0.20). However, without a human_note providing specific clinical context, a discharge decision is made considering stability of symptoms and the absence of immediate risk factors for admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 184/840 [09:24<37:04,  3.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5853 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the clinical expertise and judgement. Despite the lower probabilities from the models, the lack of a human note makes it necessary to err on the side of caution and admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 185/840 [09:26<32:04,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1524 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.152. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 186/840 [09:27<26:48,  2.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1754 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.175. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 187/840 [09:27<19:45,  1.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2484 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.248. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▏       | 188/840 [09:30<21:50,  2.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2494 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Insufficient information from LLM classifier and human note to make a discharge decision, thus admitting the patient based on the ML model's prediction.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 22%|██▎       | 189/840 [09:36<35:35,  3.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2781 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the given information, the ML model (p_ml) suggests a 5% probability of admission, which is not significantly indicative of admission. The LLM classifier (p_llm) suggests a 50% probability, which is somewhat suggestive of admission, but not conclusive. Without a human_note providing immediate clinical context or detailed reasons for admission or discharge, I am unable to make a definitive admission decision. Therefore, based on the information provided, the most suitable action is to DISCHARGE the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 23%|██▎       | 190/840 [09:39<34:56,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4796 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the low p_ml of 0.15, I rely on the higher p_llm of 0.81 and the lack of a human_note indicating stability, I decide to admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 23%|██▎       | 191/840 [09:43<37:28,  3.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1610 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the low p_llm (0.10) and the absence of a human_note. Clinical judgment favors admitting the patient to monitor vital signs and perform further diagnostic tests to rule out any serious conditions despite the lower p_ml (0.22).\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 23%|██▎       | 192/840 [09:47<37:25,  3.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3104 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The patient's low p_ml score and absence of a human note suggest a lower likelihood of requiring admission. However, the increased p_llm score indicates a potential need for further assessment, leading to the decision to admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 23%|██▎       | 193/840 [09:50<35:36,  3.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3107 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.311. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 23%|██▎       | 194/840 [09:50<26:00,  2.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0695 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.070. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 23%|██▎       | 195/840 [09:53<27:53,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1311 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The patient falls under a high-risk category, and despite lower probabilities from both p_ml and p_llm, the lack of a human note suggesting discharge tipped the scale towards admitting the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 23%|██▎       | 196/840 [09:56<28:42,  2.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3981 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The patient has a high risk of complications, so I chose to admit based on the clinical context provided by the ML model, LLM classifier, and the absence of a stable clinical presentation.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 23%|██▎       | 197/840 [09:56<21:01,  1.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3799 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.380. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▎       | 198/840 [09:57<15:42,  1.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2619 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.262. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▎       | 199/840 [09:59<18:20,  1.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3286 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the high p_ml and p_llm values, indicating a high likelihood of admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 200/840 [10:01<21:00,  1.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4789 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.479. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 201/840 [10:02<16:48,  1.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2354 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.235. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 202/840 [10:05<22:29,  2.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2084 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient based on the high risk indicated by the ML model (p_ml) and the clinical context provided by the human_note, despite the lower probability suggested by the LLM classifier (p_llm).\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 203/840 [10:08<24:17,  2.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1535 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Insufficient clinical information; defaulting to higher likelihood of admission based on ML model output (0.16) and LLM classifier output (0.14).\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 204/840 [10:13<31:51,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1992 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): I chose 'Discharge' based on the p_llm of 0.35 indicating a lower likelihood of needing admission. Despite the low p_ml of 0.05, the absence of a nurse or physician's note suggesting admission overrides the machine learning models, and the lack of specific clinical reasons to justify admission leads to a decision of discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 24%|██▍       | 205/840 [10:16<30:49,  2.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2445 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Overwhelming clinical judgment points towards admitting the patient due to a combination of high ML and LLM probabilities coupled with the absence of contrary information in the human note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 25%|██▍       | 206/840 [10:19<33:22,  3.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4953 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.495. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 25%|██▍       | 207/840 [10:23<34:16,  3.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4807 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.481. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 25%|██▍       | 208/840 [10:25<30:33,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2388 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.239. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 25%|██▍       | 209/840 [10:26<24:28,  2.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4314 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.431. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 25%|██▌       | 210/840 [10:28<25:30,  2.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2117 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the high probability from the ML model (0.28) and the absence of a human note indicating stability or discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 25%|██▌       | 211/840 [10:34<33:45,  3.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2761 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to admit the patient is based on the LLM classifier's probability of admission (p_llm: 0.50), which indicates a moderate to high likelihood of requiring hospital admission. Additionally, the absence of a human_note suggests that there is insufficient real-time clinical context to confidently discharge the patient. As a result, the patient should be admitted for further evaluation and treatment.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 25%|██▌       | 212/840 [10:36<32:45,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2336 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The patient's clinical presentation is inconsistent with discharge criteria despite a low LLM and ML model admission probability. Clinical judgment is guiding the admission decision to ensure further evaluation and management of potential serious conditions.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 25%|██▌       | 213/840 [10:40<33:13,  3.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5477 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the combined assessment of a low ML probability (0.36) and a higher LLM probability (0.73), indicating a higher chances of a sicker patient who warrants admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 25%|██▌       | 214/840 [10:43<32:58,  3.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0566 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): No clinical indicators to suggest a high risk or unstable symptoms. LLM and ML models suggest a lower admission probability, and without additional context from the human note, discharging the patient is the more appropriate decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 215/840 [10:46<34:03,  3.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1141 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the given information, despite the lower probabilities from p_ml and p_llm, the lack of a detailed human_note suggests that there may be additional, undisclosed reasons to prioritize admission. Therefore, I am admitting the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 216/840 [10:51<38:10,  3.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4539 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.454. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 217/840 [10:55<38:06,  3.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3894 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.389. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 218/840 [10:58<38:25,  3.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2046 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the moderate risk indicated by the p_llm (LLM classifier) value of 0.35, despite the lower ML model probability (p_ml) of 0.06 and the absence of a human note providing real-time context.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 219/840 [11:03<39:55,  3.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2038 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the evidence provided, the patient's low p_ml (0.06) and p_llm (0.34) scores, along with the absence of any human_note, suggest a lower likelihood of a serious clinical state. This aligns with a decision to discharge rather than admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▌       | 220/840 [11:06<36:57,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4130 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.413. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▋       | 221/840 [11:09<37:24,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5891 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.589. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 26%|██▋       | 222/840 [11:13<38:03,  3.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4577 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.458. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 27%|██▋       | 223/840 [11:18<41:27,  4.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3969 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The lack of information in the human_note prompts a re-evaluation of the initial admissions decision. Considering the average probability values from both p_ml (0.39) and p_llm (0.40), the final decision aligns with admitting the patient to address potential undiagnosed conditions. This is a cautious approach to ensure the patient's well-being.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 27%|██▋       | 224/840 [11:21<38:17,  3.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0849 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.085. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 27%|██▋       | 225/840 [11:25<37:33,  3.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2885 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to discharge is made without the benefit of a clear-cut clinical justification from the human_note, despite the moderate probabilities provided by the ML and LLM models. In such cases, the default action is to favor discharge as a more conservative approach.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 27%|██▋       | 226/840 [11:29<39:58,  3.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4652 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.465. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 27%|██▋       | 227/840 [11:33<39:29,  3.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6650 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The combination of a moderate ML probability (0.51) and a high LLM classifier probability (0.82) suggests an elevated risk that merits admission. However, the absence of a human note makes this decision less than ideal. Clinical context is crucial in these assessments.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 27%|██▋       | 228/840 [11:37<39:33,  3.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4148 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.415. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 27%|██▋       | 229/840 [11:40<37:26,  3.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0681 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharged due to stable symptoms and low risk as indicated by low p_ml (0.11) and p_llm (0.03) probabilities. No additional clinical context provided in the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 27%|██▋       | 230/840 [11:44<39:07,  3.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1857 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.186. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 231/840 [11:48<39:35,  3.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3654 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the combination of p_ml (0.06) and p_llm (0.67), both indicating a higher likelihood of admission. However, without a human_note providing real-time clinical context, we rely on the machine learning scores to make the admission decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 232/840 [11:53<42:00,  4.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4861 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.486. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 233/840 [11:56<38:01,  3.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4667 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Insufficient data to make a confident discharge decision. Considering the ML and LLM scores, and lack of human context, it is more appropriate to admit the patient for further evaluation.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 234/840 [12:00<38:04,  3.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.7391 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Clinical decision made by considering the high severity of the cases, as indicated by the ML model (p_ml) and LLM classifier (p_llm). Despite the nurse or physician's absence of context in the human_note, the strong indicators from the models guided the admission decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 235/840 [12:03<36:29,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3985 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the human_note, which indicates a high level of risk, outweighing the lower probabilities from the p_ml and p_llm signals. The patient should be admitted for further evaluation and management.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 236/840 [12:07<38:06,  3.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3655 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the high risk indicated by the clinical assessment, despite the lower probabilities from the ML model (0.43) and LLM classifier (0.30). The absence of a human note does not influence the decision, as the clinical assessment overrides the probabilistic scores.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 237/840 [12:11<39:32,  3.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1320 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The patient's likelihood of admission based on traditional ML models and LLM classifiers indicates a 60% probability of admission, which is lower than the threshold for admission. However, without additional information from the human note, it is not possible to make a definitive clinical decision. Therefore, the final decision is to discharge the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 238/840 [12:15<38:01,  3.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3605 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to discharge is based on the low ML model probability (0.03), which suggests a lower likelihood of being seriously ill. Additionally, the absence of a human note indicating a need for admission supports the decision to discharge the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 28%|██▊       | 239/840 [12:19<38:24,  3.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4899 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to discharge is based on the LLM classifier's higher probability of admission (0.68), combined with the absence of specific clinical indications for admission provided in the human_note. The ML model's lower probability (0.30) does not override the LLM's prediction.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 29%|██▊       | 240/840 [12:22<37:25,  3.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2182 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to admit is based on the high ML probability of admission (0.33) and the absence of a nurse or physician's real-time context provided in the human_note. Clinical judgment favors admitting the patient for further evaluation and potential treatment.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 29%|██▊       | 241/840 [12:25<34:23,  3.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2824 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.282. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 29%|██▉       | 242/840 [12:25<24:57,  2.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2104 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.210. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 29%|██▉       | 243/840 [12:26<18:23,  1.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1245 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.124. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 29%|██▉       | 244/840 [12:29<23:53,  2.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0664 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.066. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 29%|██▉       | 245/840 [12:34<29:43,  3.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1135 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Given the low probabilities from both the ML model (0.04) and LLM classifier (0.19), and absence of a human note providing real-time context, I decide to discharge the patient. The absence of specific indications for admission and the lack of detail in the provided notes do not support an admission decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 29%|██▉       | 246/840 [12:38<34:01,  3.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4723 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision is to discharge the patient because there is no indication of high risk or unstable symptoms. The LLM classifier's probability of admission (0.66) is lower than the ML model's (0.29), suggesting a lower likeliness of admission. The absence of a human note further supports this decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 29%|██▉       | 247/840 [12:40<30:29,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0931 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.093. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|██▉       | 248/840 [12:44<31:13,  3.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2725 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The patient's clinical presentation and risk factors indicate a high likelihood of a serious condition, outweighing the lower probabilities from the ML and LLM classifiers. The decision to admit is supported by the lack of specific information from the human note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|██▉       | 249/840 [12:44<24:08,  2.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3489 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.349. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|██▉       | 250/840 [12:45<17:39,  1.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1258 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.126. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|██▉       | 251/840 [12:50<27:12,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1932 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.193. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 252/840 [12:53<27:38,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3437 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): No human note provided. The final decision to discharge is based solely on low probabilities from both the ML model (0.50) and LLM classifier (0.19).\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 253/840 [12:57<31:30,  3.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2006 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is made based on the LLM classifier's higher probability of admission (0.30) and the lack of a human note indicating otherwise. Despite the ML model's lower probability (0.10), the clinical context provided by the LLM classifier is considered more reliable in this scenario.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 254/840 [13:02<38:15,  3.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3843 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.384. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 255/840 [13:06<35:49,  3.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1940 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to admit is based on the high risk indicated by both the ML model (p_ml) and the LLM classifier (p_llm), even though no specific context is provided in the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 30%|███       | 256/840 [13:11<41:54,  4.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1736 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.174. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 31%|███       | 257/840 [13:15<39:55,  4.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1571 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to discharge is made based on the lack of evidence or clear indication for admission, despite the moderate probabilities from the models. It is important to rely on clinical judgment and other available information to make a safe admission or discharge decision in such cases.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 31%|███       | 258/840 [13:18<38:10,  3.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4937 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision is to admit the patient due to the lack of clinical context provided in the human_note. While p_llm is lower than p_ml, the absence of information from the nurse or physician suggests a higher risk, thus justification for admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 31%|███       | 259/840 [13:19<29:18,  3.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1372 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.137. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 31%|███       | 260/840 [13:24<33:38,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2083 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.208. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 31%|███       | 261/840 [13:29<37:04,  3.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3921 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is made based on the low probability from the ML model (0.28), the medium probability from the LLM classifier (0.50), and the absence of a human note indicating any clear deviation in clinical status. Given these inputs, it is most appropriate to err on the side of caution and admit the patient for further evaluation.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 31%|███       | 262/840 [13:29<27:12,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1485 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.149. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 31%|███▏      | 263/840 [13:30<22:16,  2.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2329 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.233. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 31%|███▏      | 264/840 [13:32<20:02,  2.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3074 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): No clear indication to admit the patient based on the provided information.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 265/840 [13:35<24:43,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2412 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is made based on the clinical assessment that includes a low p_ml probability, yet strong indications from both p_llm and the absence of a human note suggesting stability, which suggests a higher chance of a complicated clinical picture that warrants admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 266/840 [13:39<27:11,  2.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1564 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.156. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 267/840 [13:41<24:13,  2.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1884 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.188. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 268/840 [13:41<17:54,  1.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3017 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.302. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 269/840 [13:43<18:58,  1.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2227 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.223. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 270/840 [13:44<14:50,  1.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3002 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.300. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 271/840 [13:47<17:54,  1.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2640 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Clinical decision made based on a combination of low ML probability (0.21) and moderate LLM probability (0.32) without any relevant human context provided.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▏      | 272/840 [13:47<13:38,  1.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4415 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.441. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 32%|███▎      | 273/840 [13:51<19:34,  2.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0651 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.065. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 33%|███▎      | 274/840 [13:55<27:31,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2084 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.208. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 33%|███▎      | 275/840 [14:00<31:39,  3.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2282 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the given information, the LLM classifier suggests a higher probability of admission (0.42) compared to the ML model (0.04). However, since no human_note is provided, I am unable to consider any clinical context. Therefore, I will err on the side of discharge despite the higher LLM probability.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 33%|███▎      | 276/840 [14:04<33:28,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2522 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.252. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 33%|███▎      | 277/840 [14:08<34:33,  3.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2973 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is made based on the higher probability from the LLM classifier (0.48), indicating a moderate to high likelihood of a condition requiring hospitalization. The absence of a human note further supports this decision, as immediate medical intervention is necessary for proper evaluation and care.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 33%|███▎      | 278/840 [14:09<26:31,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3150 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.315. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 33%|███▎      | 279/840 [14:12<28:36,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2448 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Due to the lack of a high-risk factor and the absence of any clinical context, a discharge decision is made based solely on the low probabilities from both the ML model (0.07) and the LLM classifier (0.42).\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 33%|███▎      | 280/840 [14:15<28:20,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5559 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient due to the high risk indicated by the ML model and LLM classifier, despite the lack of human note, which would normally provide context for a discharge decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 33%|███▎      | 281/840 [14:18<28:16,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2550 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge is chosen due to low p_ml (0.16) and lack of meaningful clinical context provided by p_llm (0.35) and human_note (none given).\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▎      | 282/840 [14:21<26:46,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3059 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.306. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▎      | 283/840 [14:25<31:19,  3.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5820 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the input signals, the LLM classifier's higher probability of admission (0.65) is considered more reliable than the ML model's lower probability (0.51), despite the absence of a human note. The decision to discharge is made based on the stable symptoms, as referenced in the LLM classifier's output.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 284/840 [14:28<30:41,  3.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6150 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Despite the ML model showing a lower probability of admission, the LLM classifier indicates a higher likelihood, and the absence of a clarifying human note necessitates a conservative approach, thus deciding to admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 285/840 [14:33<33:31,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1200 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the combination of low p_ml (0.03) and somewhat higher p_llm (0.21), along with the absence of a human_note, I decided to admit the patient. This is to ensure a thorough evaluation and monitoring, given the lack of clear clinical context provided by the nurse or physician.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 286/840 [14:38<36:49,  3.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2132 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.213. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 287/840 [14:43<39:32,  4.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4026 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final discharge decision is made due to the lack of significant likelihood from the ML model (p_ml: 0.16), moderate likelihood from the LLM classifier (p_llm: 0.65), and the absence of a provided human_note indicating any acute risk factors or need for immediate admission. The patient's overall clinical picture does not support an admit decision at this time.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 288/840 [14:47<39:33,  4.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2779 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the presented information, the patient's overall risk profile, along with the ML model's probability (0.03) and the LLM classifier's probability (0.53), and the absence of a human note indicating otherwise, the most appropriate clinical decision is to admit the patient for further evaluation and appropriate management.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 34%|███▍      | 289/840 [14:50<35:57,  3.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1430 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge decision is based on the combined low probabilities from both the ML model (0.18) and LLM classifier (0.11), and the absence of clinical context provided by the human note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 35%|███▍      | 290/840 [14:54<36:31,  3.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5636 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the LLM classifier's higher probability of admission (0.62) compared to the ML model's lower probability (0.51). Since the LLM classifier's prediction aligns with the clinical assessment that a more severe condition is present, the patient is admitted.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 35%|███▍      | 291/840 [14:57<32:16,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1142 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Insufficient information from LLM and ML models to make a confident admission decision, thus relying on clinical judgment and admitting the patient for further evaluation.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 35%|███▍      | 292/840 [14:59<30:21,  3.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3361 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.336. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 35%|███▍      | 293/840 [15:04<34:52,  3.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2271 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.227. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 35%|███▌      | 294/840 [15:09<37:10,  4.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5618 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision was made based on the combined information from all three sources. The ML model indicated a 58% probability of admission, while the LLM classifier suggested a 55% probability. However, without a human_note providing realtime context, the decision was made solely on the numerical probabilities, where a higher probability tipped the scale towards admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 35%|███▌      | 295/840 [15:09<26:55,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2520 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.252. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 35%|███▌      | 296/840 [15:13<27:31,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3035 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.304. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 35%|███▌      | 297/840 [15:16<28:38,  3.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2110 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision is to discharge the patient because no human note is provided, and both p_ml and p_llm suggest a lower likelihood of admission. p_ml: 0.05, p_llm: 0.37.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 35%|███▌      | 298/840 [15:16<20:56,  2.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3050 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.305. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 299/840 [15:18<18:45,  2.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3534 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.353. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 300/840 [15:18<14:02,  1.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2197 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.220. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 301/840 [15:22<18:59,  2.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2407 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The patient has a fever and is afebrile, indicating that the infection is not yet completely resolved. Additionally, there is no note from the healthcare professional to suggest discharge, further supporting the decision to admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 302/840 [15:26<25:01,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5457 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision is to admit the patient due to the lack of human note, which suggests an unclear clinical status. Although the ML model suggests a lower admission probability (0.61), the clinical judgment from the assistant should override the model's prediction in such cases, especially when there is no additional information provided by the human note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 303/840 [15:26<18:24,  2.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2122 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.212. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▌      | 304/840 [15:28<17:59,  2.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3010 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitted due to high risk indicators from both p_ml and p_llm.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▋      | 305/840 [15:32<23:04,  2.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2463 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The combination of the ML model (p_ml) and LLM classifier (p_llm) suggests a high risk for the patient, which justifies the admission decision. However, since no human_note is provided, the final rationale relies on the quantitative probabilities from the models.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 36%|███▋      | 306/840 [15:35<24:04,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1238 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.124. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 37%|███▋      | 307/840 [15:38<23:31,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2308 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.231. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 37%|███▋      | 308/840 [15:42<27:19,  3.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3873 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.387. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 37%|███▋      | 309/840 [15:47<32:27,  3.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5168 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.517. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 37%|███▋      | 310/840 [15:52<35:44,  4.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1381 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to admit is based on the clinical judgment that combines the ML model's indication of a 0.08% likelihood of admission, the LLM classifier's 0.19% likelihood, and the absence of a detailed human-note providing real-time context. Given the absence of specific clinical information, the overall risk level is interpreted as high, leading to the decision to admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 37%|███▋      | 311/840 [15:55<32:58,  3.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2837 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.284. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 37%|███▋      | 312/840 [15:57<28:17,  3.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4054 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Insufficient evidence to justify admission based on low LLM probability and lack of human note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 37%|███▋      | 313/840 [16:01<30:43,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3426 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the LLM classifier's high probability of admission (0.61), which outweighs the lower ML model probability (0.08). However, without a detailed human_note providing clinical context, the decision to admit is largely driven by the intermediate likelihood provided by the LLM classifier.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 37%|███▋      | 314/840 [16:05<31:12,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5939 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge is chosen as the patient's symptoms are stable and there is no immediate risk indicated by the low p_llm score, despite a high p_ml score indicating a higher likelihood of admission. The lack of a human_note further supports a discharge decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 315/840 [16:09<32:19,  3.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0737 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.074. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 316/840 [16:13<33:23,  3.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1249 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the combination of low p_ml (0.06) and p_llm (0.19). Without any contextual information from the human_note, the clinical judgment prioritizes the stronger probability from the LLM classifier (0.19) to support the admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 317/840 [16:17<35:12,  4.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3714 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the high risk indicated by the LLM classifier (p_llm=0.66), despite the lower risk suggested by the ML model (p_ml=0.09). Without additional clinical context from a human note, the higher risk classification takes precedence, leading to the decision to admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 318/840 [16:22<36:31,  4.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4995 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.500. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 319/840 [16:26<35:05,  4.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2955 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the LLM classifier's higher probability (0.53) compared to the ML model's probability (0.06). Absence of a human note suggests that the decision is solely based on the algorithmic outputs.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 320/840 [16:30<35:49,  4.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5285 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.528. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 321/840 [16:36<39:36,  4.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3168 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the given information, the patient's p_ml and p_llm scores suggest a 23% and 41% probability of admission or discharge, respectively. However, since no human_note has been provided, I will rely on the scores to make an admission decision. The higher p_llm score (0.41) compared to p_ml (0.23) supports admission. Therefore, the patient should be admitted for further evaluation and treatment.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 322/840 [16:39<36:45,  4.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.9803 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The high probabilities from both p_ml (0.97) and p_llm (0.99) suggest a strong likelihood of hospital admission. Given the absence of a human note, I relied on the numerical values to make my admission decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 38%|███▊      | 323/840 [16:44<37:33,  4.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4220 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to admit is based on the higher probability from the ML model (0.76), which is indicative of a higher risk warranting hospitalization. Despite the lower probability from the LLM classifier (0.09), the absence of a human note suggesting otherwise, and the overall clinical context, suggest that admission is appropriate for further evaluation and management.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 39%|███▊      | 324/840 [16:48<38:15,  4.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2493 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The low p_llm score of 0.08 suggests low confidence in the LLM classification, but the lacking information from the human_note means we cannot rely solely on that. Given the moderate p_ml score of 0.42, which is above the threshold set for admission, I will err on the side of caution and admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 39%|███▊      | 325/840 [16:51<34:31,  4.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1077 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Clinical judgment favors admission due to the high risk indicated by the low ML probability (0.03) and LLM classifier probability (0.18), despite the lack of a human note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 39%|███▉      | 326/840 [16:55<33:10,  3.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.7008 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient due to a high LLM confidence score of 0.95, which outweighs the ML model's lower confidence of 0.45. No specific clinical reasons provided in the human note to justify admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 39%|███▉      | 327/840 [16:58<31:10,  3.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5098 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient due to the higher probability from the LLM classifier (0.62) and the absence of clarifying information from the human_note, despite the lower ML model probability (0.40).\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 39%|███▉      | 328/840 [16:58<22:32,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3570 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.357. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 39%|███▉      | 329/840 [17:01<23:22,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2993 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient based on the combination of low ML probability (0.25), slightly higher LLM classifier probability (0.35), and lack of specific clinical context provided in the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 39%|███▉      | 330/840 [17:05<25:56,  3.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3522 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.352. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 39%|███▉      | 331/840 [17:07<24:00,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2959 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Clinical judgment favors admission due to the moderate severity of symptoms. Lack of specific details from the human note hinders a clear discharge recommendation.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|███▉      | 332/840 [17:10<23:05,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6223 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.622. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|███▉      | 333/840 [17:15<28:49,  3.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4704 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to discharge is based on the p_llm (LLM classifier) which indicates a higher probability (0.73) compared to p_ml (ML model: 0.21). However, without any specific clinical context provided in the human_note, it is difficult to fully justify the decision. Therefore, a stable symptoms approach is taken, leading to the decision to discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|███▉      | 334/840 [17:18<27:21,  3.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3458 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the high risk indicated by the ML model (p_ml=0.48) and lack of human context to make an informed decision from the provided note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|███▉      | 335/840 [17:21<27:13,  3.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3030 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Clinical decision based on p_ml (0.21) and p_llm (0.40) indicating a lower likelihood of admission. No further clinical context provided by human_note, supporting the decision to discharge the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 336/840 [17:24<27:05,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4292 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is made based on the LLM classifier's high probability (0.81) indicating positive likelihood of admission, and due to the absence of a contradicting or clarifying human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 337/840 [17:29<30:18,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1844 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The clinical decision to admit the patient is based on the combination of a low ML probability (0.08), a relatively higher LLM classifier probability (0.29), and the absence of a human note providing real-time clinical context. Given the patient's symptoms, it is reasonable to proceed with further diagnostic evaluation and treatment in a hospital setting.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 338/840 [17:33<31:22,  3.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4489 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision is to admit the patient due to the lack of clinical context provided by the human_note. The disagreement between the ML model (p_ml=0.47) and the LLM classifier (p_llm=0.43) suggests that further evaluation in a hospital setting is necessary.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 339/840 [17:36<30:02,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1553 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.155. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 40%|████      | 340/840 [17:40<30:54,  3.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5180 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.518. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 41%|████      | 341/840 [17:44<31:02,  3.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3425 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the ML model's probability of 0.33, the LLM classifier's probability of 0.35, and the absence of a human note, I decided to admit the patient due to the lack of clear clinical context to weigh against for a discharge decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 41%|████      | 342/840 [17:47<30:38,  3.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3921 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to discharge was made without an intervening human_note providing real-time clinical context. Both the ML model (p_ml) and the LLM classifier (p_llm) suggest a lower likelihood of admission, further supporting the decision to discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 41%|████      | 343/840 [17:48<23:17,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4800 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.480. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 41%|████      | 344/840 [17:48<16:56,  2.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5378 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.538. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 41%|████      | 345/840 [17:53<22:41,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1689 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.169. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 41%|████      | 346/840 [17:57<26:14,  3.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3874 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision is to admit the patient due to disagreement between the signals. While the ML model suggests a 59% likelihood of admission, the LLM classifier indicates an 18% likelihood of discharge. Without additional human context, the most conservative action is to admit the patient for further evaluation and management.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 41%|████▏     | 347/840 [18:02<31:28,  3.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4702 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The LLM classifier's high probability of admission (0.82) suggests a significant likelihood of a serious condition requiring hospitalization. However, the ML model's lower probability (0.12) indicates a less certain outcome, and the absence of a human note provides insufficient clinical context to align with the LLM's assessment. Therefore, the best decision is to discharge the patient, awaiting further symptom stabilization and possibly reassessment.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 41%|████▏     | 348/840 [18:06<30:50,  3.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2379 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the given information, despite lower probabilities from both p_ml and p_llm, the lack of a human_note cannot be ignored. This indicates a potential for misinterpretation or insufficient contextual information, hence opting for a cautious 'Admit' decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 349/840 [18:09<29:19,  3.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1758 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.176. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 350/840 [18:12<27:57,  3.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3676 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.368. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 351/840 [18:15<26:52,  3.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5540 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Clinical decision made based on low ML probability (0.11) and high LLM probability (1.00), as per protocol to admit patients with uncertain classification to ensure comprehensive evaluations.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 352/840 [18:17<23:18,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0653 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Clinical judgment favors admission due to lack of specific clinical information, although both models suggest discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 353/840 [18:21<25:32,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6494 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Given the high probabilities from both the ML model (0.79) and the LLM classifier (0.51), and considering the lack of additional clinical information from the human note, it is prudent to err on the side of caution and admit the patient for further evaluation.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 354/840 [18:25<26:58,  3.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4975 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.498. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 355/840 [18:30<31:55,  3.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3300 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is to discharge the patient due to a low ML probability (0.20) and an LLM probability (0.46) that is below the threshold for admission. However, without a human note providing real-time clinical context, it is not possible to justify the decision with confidence. Thus, a decision to discharge is made with the understanding that additional information may be required for a more accurate assessment.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▏     | 356/840 [18:34<31:45,  3.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3402 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.340. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 42%|████▎     | 357/840 [18:34<23:18,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3444 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.344. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 43%|████▎     | 358/840 [18:39<27:09,  3.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1564 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit the patient is made after considering the low probabilities from both p_ml (0.09) and p_llm (0.22), and the lack of clinical context provided in the human_note. Given the insufficient information, it is prudent to err on the side of caution and admit the patient for further evaluation.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 43%|████▎     | 359/840 [18:43<28:04,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3870 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to discharge is based on the low probabilities from both the ML model (p_ml) and LLM classifier (p_llm), as well as the absence of a human note that could provide additional contextual information for a more informed admission decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 43%|████▎     | 360/840 [18:46<27:55,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2474 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.247. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 43%|████▎     | 361/840 [18:49<25:57,  3.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6951 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The LLM classifier's higher probability of admission (0.92) alongside the lack of a negative human_note suggests that the patient should be admitted for further clinical evaluation.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 43%|████▎     | 363/840 [18:54<22:41,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2928 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the clinician's assessment that the patient's symptoms and vital signs indicate a high risk for complications. Despite the ML model and LLM classifier suggesting discharge, the absence of a specific human note or clinical indication suggesting discharge, and the overall clinical judgment favouring admission, overrides the probabilistic classification and the patient is admitted.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 43%|████▎     | 364/840 [18:58<25:08,  3.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6000 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision is to admit the patient despite the lower ML probability (0.34) due to the higher LLM probability (0.86) and the absence of a human note, suggesting a potential for masked symptoms or more severe conditions that may not be captured by the traditional ML model.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▎     | 366/840 [19:00<19:03,  2.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5119 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Final admission decision is made based on high risk factors indicated by the ML model and LLM classifier despite the lack of specific clinical information in the human note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▎     | 367/840 [19:06<24:21,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5276 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.528. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 368/840 [19:10<25:56,  3.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3191 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.319. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 369/840 [19:13<25:37,  3.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3291 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the combination of both AI models' predictions (low ML model probability and high LLM classifier probability), as there is no additional clinical context provided in the human note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 370/840 [19:18<29:21,  3.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2725 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the p_ml (0.03), p_llm (0.52), and lack of human_note, I determined that there is insufficient clinical context to make a discharge decision. Given the patient's presentation, it is prudent to admit for further evaluation and care. Pneumonia is a common cause of fever in the elderly, and admission would allow for full assessment and appropriate treatment.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 371/840 [19:23<31:43,  4.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1718 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.172. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 372/840 [19:26<29:32,  3.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2161 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.216. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 44%|████▍     | 373/840 [19:31<31:41,  4.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1632 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the presented information, the patient's low p_ml (0.04) and p_llm (0.29) scores, as well as the absence of a human_note, suggest that the patient can be safely discharged without immediate risk of deterioration or transfer to the ICCU. The decision is supported by current medical guidelines and protocols for ER triage admissions.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 45%|████▍     | 374/840 [19:35<32:15,  4.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5648 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the ML model's higher probability of admission (0.60) compared to the LLM classifier's lower probability (0.53). Absence of a human note does not influence the decision, and the patient's condition is deemed critical enough to warrant admission for further evaluation and treatment.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 45%|████▍     | 375/840 [19:42<38:10,  4.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2580 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.258. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 45%|████▍     | 376/840 [19:42<27:48,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1832 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.183. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 45%|████▍     | 377/840 [19:48<32:20,  4.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2262 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.226. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 45%|████▌     | 378/840 [19:51<31:01,  4.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3620 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge is recommended due to a low probability from the ML model (0.09) and lack of contextual information from the human_note. The LLM classifier's higher probability (0.63) is not conclusive for admission without additional clinical context.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 45%|████▌     | 379/840 [19:55<29:19,  3.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3395 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.339. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 45%|████▌     | 380/840 [19:57<25:57,  3.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5623 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.562. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 45%|████▌     | 381/840 [20:00<24:27,  3.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2609 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Clinical judgment determines that the patient's presentation warrants admission, despite lower probabilities from ML and LLM, due to lack of further contextual information from the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 45%|████▌     | 382/840 [20:01<20:33,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1243 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.124. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 383/840 [20:05<22:42,  2.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3787 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.379. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 384/840 [20:09<25:04,  3.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1652 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Given the low probabilities from both the ML model (0.12) and LLM classifier (0.21), and the lack of detailed clinical context in the human_note, I am leaning towards a conservative approach and choosing to admit the patient to further evaluate and manage any potential health issues.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 385/840 [20:15<31:22,  4.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2319 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.232. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 386/840 [20:19<29:32,  3.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3795 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.380. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▌     | 388/840 [20:19<16:28,  2.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1608 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.161. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▋     | 389/840 [20:19<12:58,  1.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0689 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.069. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 46%|████▋     | 390/840 [20:21<13:30,  1.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4224 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.422. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 47%|████▋     | 391/840 [20:26<19:59,  2.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4042 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Due to the lack of evidence from both the ML model (p_ml=0.12) and the LLM classifier (p_llm=0.69), and the absence of a human note, the most appropriate action is to discharge the patient. However, clinical judgment should be exercised in real-life situations, considering other factors that may not be captured in this hypothetical scenario.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 47%|████▋     | 392/840 [20:32<26:32,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4969 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.497. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 47%|████▋     | 393/840 [20:33<21:25,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2931 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.293. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 47%|████▋     | 394/840 [20:38<24:15,  3.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3496 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.350. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 47%|████▋     | 395/840 [20:42<26:47,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3961 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to discharge is made based on the low probability from the ML model (0.16), while the LLM classifier suggests a higher probability of admission (0.64). However, without a human note providing real-time clinical context, the decision leans towards discharging the patient due to the lack of compelling evidence for admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 47%|████▋     | 396/840 [20:45<25:42,  3.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1730 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the low ML probability (0.03) and LLM probability (0.32), and the absence of a human note, I chose to admit the patient to further evaluate their condition.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 47%|████▋     | 397/840 [20:46<19:20,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0634 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.063. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 47%|████▋     | 398/840 [20:50<22:41,  3.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5093 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the LLM classifier's higher probability of admission (0.69) compared to the ML model's lower probability (0.33), despite the lack of a human note. The patient's clinical presentation or other factors likely justify a more cautious approach, hence admission is warranted.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 399/840 [20:53<23:00,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1348 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.135. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 400/840 [20:55<20:07,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1417 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge is chosen due to an unclear clinical picture and lack of specific indications for admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 401/840 [20:58<20:38,  2.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4226 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.423. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 402/840 [21:02<22:53,  3.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2399 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.240. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 403/840 [21:04<21:01,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5192 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The patient's stable symptoms, combined with a low ML prognosis and moderate LLM classifier score, support a clinical decision to discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 404/840 [21:08<23:29,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4134 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the clinical context and the input probabilities, I decided to admit the patient due to the higher ML probability (0.45) suggesting a higher risk, despite the lower LLM classifier probability (0.38). There is no additional information from the human-note, which does not affect my decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 405/840 [21:11<23:34,  3.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1758 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the low probabilities from both the ML model (0.07) and LLM classifier (0.28), and the lack of specific clinical context provided in the human_note, a discharge decision is clinically justified.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 406/840 [21:15<24:13,  3.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2646 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to discharge is made based on the low probability outputs from both the ML model (0.04) and LLM classifier (0.49), and the absence of any human-note context indicating a higher risk or need for admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 48%|████▊     | 407/840 [21:18<23:42,  3.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2703 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.270. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 49%|████▊     | 408/840 [21:19<17:38,  2.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1803 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.180. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 49%|████▊     | 409/840 [21:23<21:04,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2326 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.233. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 49%|████▉     | 410/840 [21:25<20:04,  2.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4075 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.408. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 49%|████▉     | 411/840 [21:29<22:05,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1742 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is made based on the combined clinical judgment from the ML model (p_ml: 0.17), LLM classifier (p_llm: 0.18), and the absence of a definitive discharge indication in the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 49%|████▉     | 412/840 [21:33<24:08,  3.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3021 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.302. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 49%|████▉     | 413/840 [21:37<25:13,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3526 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): I chose 'Discharge' based on the given information, as there is no strong indication for admission. The ML model suggests a lower probability of admission, and the LLM classifier suggests a moderate probability, which is not enough to override the lack of clinical context provided by the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 49%|████▉     | 414/840 [21:44<31:48,  4.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3057 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.306. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 49%|████▉     | 415/840 [21:47<28:32,  4.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3828 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the high risk signals from both the ML model (0.34) and the LLM classifier (0.43), despite the lack of a human note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|████▉     | 416/840 [21:52<32:17,  4.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4116 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Due to the lack of information from the nurse's note, I have analyzed the probabilities provided by the ML model and LLM classifier. Although the ML model suggests a 48% chance of admission, the LLM classifier suggests a lower 34% chance. Considering these probabilities, I have made the clinical decision to admit the patient. This decision is supported by the higher probability from the ML model, which indicates a greater likelihood of the patient requiring medical attention.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|████▉     | 417/840 [21:55<28:49,  4.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2806 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to admit is based on the high probability from the LLM classifier (0.52), which indicates a significant risk that warrants further clinical evaluation and observation in a hospital setting.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|████▉     | 418/840 [21:59<26:53,  3.82s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2797 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on p_ml and p_llm, there is a moderate likelihood of admission. However, since no human_note is provided to supersede these probabilities, I am unable to make a definitive admission decision without additional clinical context.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|████▉     | 419/840 [21:59<20:07,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3357 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.336. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 420/840 [22:03<22:33,  3.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3945 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the combination of low p_ml (0.11) and the LLM classifier's higher p_llm (0.68), despite the absence of a human_note. Given these signals, it is deemed necessary to proceed with admission for further medical evaluation and treatment.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 421/840 [22:07<24:24,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1007 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Circulatory system disorder with a probability of admission based on traditional ML model (p_ml) of 0.04, and symptoms suggesting a more severe condition than what LLM classifier (p_llm) suggests. Therefore, choosing to admit the patient to further evaluate and manage the circulatory system disorder.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 422/840 [22:13<28:01,  4.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1713 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit the patient is based on the combination of a low ML model probability (0.19), a lower LLM classifier probability (0.15), and the absence of a human note providing real-time clinical context. In such cases, the default action is to admit the patient for further evaluation and treatment, as it is important to thoroughly assess patients with uncertain risk levels without clear clinical contextual support for discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 423/840 [22:16<27:17,  3.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5591 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.559. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 50%|█████     | 424/840 [22:21<28:58,  4.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4838 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is made based on the combination of low p_llm (0.45) and the absence of a specific human_note indicating stable symptoms or clear discharge criteria. While p_ml (0.52) suggests a moderate likelihood of admission, it is not the sole determining factor, and clinical judgment prevails, favoring admission with a rationale provided.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 51%|█████     | 425/840 [22:25<28:09,  4.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3786 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the given information, the clinical decision is to discharge the patient due to a low risk indicated by both the ML model (p_ml) and the LLM classifier (p_llm). Absence of a human_note suggests stable symptoms, further supporting the decision to discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 51%|█████     | 426/840 [22:25<20:15,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1517 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.152. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 51%|█████     | 427/840 [22:27<18:13,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4694 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.469. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 51%|█████     | 428/840 [22:28<13:26,  1.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2124 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.212. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 51%|█████     | 429/840 [22:31<17:20,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1397 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to admit is based on the ML model's high probability of admission (0.24), despite the LLM classifier's lower probability (0.04). Absence of a human note suggests that there is no additional real-time clinical context to reconsider the ML model's assessment.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 51%|█████     | 430/840 [22:35<18:58,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2993 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the given information, the combination of a low ML probability (0.07), moderate LLM classifier probability (0.53), and the absence of a human note suggesting admission, it is clinically sound to discharge the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 51%|█████▏    | 431/840 [22:39<21:23,  3.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2689 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.269. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 51%|█████▏    | 432/840 [22:43<24:18,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4807 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.481. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 433/840 [22:48<25:37,  3.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3671 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the lack of specific findings in the human note, the low p_ml score, and the somewhat higher but still not definitive p_llm score, the patient is most likely stable and should be discharged. Further clinical observation and evaluation can be conducted in an outpatient setting to monitor for any changes in condition.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 434/840 [22:50<21:57,  3.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3043 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The combined clinical assessment indicates a high risk for the patient, necessitating admission to closely monitor their condition.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 435/840 [22:53<21:36,  3.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3338 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.334. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 436/840 [22:56<21:28,  3.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2185 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to discharge is based on the low probabilities from both the ML model (p_ml) and the LLM classifier (p_llm), and the absence of any additional clinical context provided in the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 437/840 [22:58<19:57,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0963 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.096. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 438/840 [23:01<18:50,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1630 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.163. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 439/840 [23:04<18:58,  2.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2949 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to admit the patient is based on the high probability output from the LLM classifier (0.43), which indicates a higher risk of severe illness requiring medical intervention.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▏    | 440/840 [23:08<21:34,  3.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3837 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.384. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 52%|█████▎    | 441/840 [23:10<19:58,  3.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4182 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge decision is made based on the combination of low p_ml (0.11) and absence of clinical context provided in the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 53%|█████▎    | 442/840 [23:12<17:34,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5783 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.578. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 53%|█████▎    | 443/840 [23:16<20:47,  3.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4860 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.486. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 53%|█████▎    | 444/840 [23:21<22:44,  3.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4245 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.424. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 53%|█████▎    | 445/840 [23:24<22:25,  3.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5404 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.540. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 53%|█████▎    | 446/840 [23:28<24:16,  3.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1373 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit the patient is based on the LLM classifier's higher probability of admission (0.26) compared to the ML model's lower probability (0.02), despite the absence of a human note. Clinically, this indicates a higher likelihood of the patient requiring immediate medical attention, thereby justifying the admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 53%|█████▎    | 447/840 [23:34<27:37,  4.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2419 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision was made based on the low p_llm score of 0.19, which indicated a lower confidence in the predictive accuracy of the LLM's discharge recommendation. Given the absence of additional contextual information from the human_note, the decision was aligned with the ML model's higher probability of admission (p_ml: 0.29), considering the overall clinical picture as more indicative of a need for admission rather than discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 53%|█████▎    | 448/840 [23:40<30:34,  4.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5562 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): - The p_ml is 0.30, which does not strongly indicate admission. - The p_llm is 0.82, which suggests a higher likelihood of admission compared to the ML model. - However, without a human_note to provide real-time clinical context, we cannot fully justify an admission decision based on these probabilities alone. Thus, the best decision is to 'Discharge' the patient, considering the provided information is not strong enough for admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 53%|█████▎    | 449/840 [23:43<28:20,  4.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4362 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient due to a high risk as indicated by the LLM classifier's probability of 0.82, despite the lower ML model probability of 0.05, and absence of a human note providing real-time context.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▎    | 450/840 [23:47<26:41,  4.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0988 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.099. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▎    | 451/840 [23:51<27:28,  4.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4056 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.406. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 452/840 [23:54<23:50,  3.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3579 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient due to the unknown reason, as neither the ML model nor the LLM classifier provides sufficient evidence for discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 453/840 [23:56<22:08,  3.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6131 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.613. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 454/840 [23:57<16:06,  2.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3751 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.375. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 455/840 [24:01<19:38,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4153 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.415. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 456/840 [24:05<21:05,  3.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2773 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the ML model (p_ml), a discharge decision is not reliable (below 0.50), while the LLM classifier (p_llm) suggests admission. However, without a human_note or clear clinical reasoning, this is a low-confidence admission decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 54%|█████▍    | 457/840 [24:07<18:37,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3962 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Preliminary data suggests low confidence in discharge decision, but lack of human note leads to admittance.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 55%|█████▍    | 458/840 [24:11<21:09,  3.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4168 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient due to the high likelihood of admission indicated by both the ML model (58%) and LLM classifier (26%). Absence of a human note does not change the decision, as clinical guidelines take precedence. The patient's symptoms and risk factors necessitate close monitoring in the hospital setting.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 55%|█████▍    | 459/840 [24:15<21:35,  3.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4521 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient due to the high predictive probability from the ML model (0.89), despite the low probability from the LLM classifier (0.02), as no real-time context provided in the human_note is available to influence the decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 55%|█████▍    | 460/840 [24:15<15:58,  2.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2349 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.235. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 55%|█████▍    | 461/840 [24:18<17:00,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1790 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the low ML probability (0.13) and LLM probability (0.23), and the lack of human note, I chose to admit the patient to further evaluate potential underlying conditions or complications.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 55%|█████▌    | 462/840 [24:22<18:59,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1785 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.179. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 55%|█████▌    | 463/840 [24:26<21:13,  3.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1126 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.113. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 55%|█████▌    | 464/840 [24:27<15:33,  2.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2971 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.297. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 55%|█████▌    | 465/840 [24:31<17:51,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2854 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the p_llm signal (0.16) which is below the threshold for discharge (0.17). This, coupled with the lack of a strong recommendation from the human_note, supports the decision to admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 55%|█████▌    | 466/840 [24:35<20:57,  3.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0968 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to discharge is made based on the low probability scores from both the ML model (p_ml) and the LLM classifier (p_llm), which are 0.02 and 0.17 respectively. Absence of a clear clinical context from the human_note exacerbates the lack of evidence to support an admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 467/840 [24:39<22:17,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1883 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the given information, the ML model (p_ml) suggests a 13% probability of admission, and the LLM classifier (p_llm) suggests a 24% probability. However, the absence of a human_note indicates a lack of clinical context or a strong recommendation to discharge the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 468/840 [24:43<22:56,  3.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3154 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.315. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 469/840 [24:46<22:04,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3147 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient due to a high risk indicated by both ML model (p_ml=0.43) and LLM classifier (p_llm=0.20), despite the lack of human note context.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 470/840 [24:51<23:35,  3.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2191 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.219. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 471/840 [24:56<25:45,  4.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4212 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the information provided, all signals are indicating a lower likelihood of admission. The ML model (p_ml) and LLM classifier (p_llm) both suggest a 0.42 probability of admission, which is not meeting the threshold for admission. Additionally, there is no human_note provided that would suggest a need for admission. Therefore, the appropriate decision is to discharge the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▌    | 472/840 [25:00<26:19,  4.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5091 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.509. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▋    | 473/840 [25:01<19:14,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5092 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.509. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 56%|█████▋    | 474/840 [25:06<22:12,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4136 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is made based on the p_llm of 0.72, which is higher than the p_ml of 0.11. The absence of a human_note suggests that the decision is based solely on the model outputs. However, without additional information from a nurse or physician, it is not possible to include specific clinical reasons in the rationale.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 57%|█████▋    | 475/840 [25:07<18:36,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4279 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): High risk indication and stable oxygen saturation level suggest admitting the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 57%|█████▋    | 476/840 [25:08<13:34,  2.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4063 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.406. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 57%|█████▋    | 477/840 [25:11<15:36,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1265 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to admit is based on the LLM classifier's higher probability of admission (0.23) compared to the ML model's lower probability (0.02), as there is no additional clinical context provided in the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 57%|█████▋    | 478/840 [25:15<17:24,  2.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2007 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to admit is supported by the clinical context and the LLM classifier's probability of admission (0.21), despite the lower ML model probability (0.19). The lack of a human note limits the precision of the discharge decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 57%|█████▋    | 479/840 [25:19<19:27,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1064 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge was chosen based on the clinical assessment that the patient's symptoms are stable and not indicative of a serious condition, despite low probabilities from the statistical models (p_ml=0.17 & p_llm=0.04). The absence of a human note further supports a less urgent decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 57%|█████▋    | 480/840 [25:19<14:07,  2.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2223 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.222. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 57%|█████▋    | 481/840 [25:22<15:46,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4202 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge is chosen due to the lack of evidence suggesting admission based on the low probabilities from both p_ml (0.18) and p_llm (0.66), and the absence of clinical context from the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 57%|█████▋    | 482/840 [25:25<16:37,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2523 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the combination of low p_ml (0.06) and moderate p_llm (0.44), indicating a higher risk of needing admission despite the absence of a human note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 57%|█████▊    | 483/840 [25:27<15:03,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3683 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Nurse's assessment shows high risk; discharge might not be safe without further evaluation.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 484/840 [25:31<17:36,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2148 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision is to admit the patient due to the non-specific nature of the symptoms, as indicated by the lack of detail in the human_note. The ML model (p_ml) and LLM classifier (p_llm) both suggest a higher likelihood of admission, which supports this decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 485/840 [25:34<17:29,  2.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1472 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the clinical context provided, the patient's high risk factors justify admission despite lower probabilities from the ML model (0.20) and LLM (0.09).\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 486/840 [25:37<17:09,  2.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3298 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.330. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 487/840 [25:41<19:01,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3608 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Given the low ML model probability (0.29) and LLM classifier probability (0.43), without any additional clinical context provided in the human_note, a final admission decision of 'Admit' is made. This is to ensure thorough evaluation and treatment, considering the possible uncertainty in classification.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 488/840 [25:46<22:39,  3.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5476 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.548. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 489/840 [25:49<20:53,  3.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2191 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): No human note provided. Discharge decision is based on low p_ml (0.15) and p_llm (0.29). Absence of a persuasive human_note suggesting admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 490/840 [25:50<15:11,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3483 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.348. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 58%|█████▊    | 491/840 [25:50<11:38,  2.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4227 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): No rationale returned by fusion agent. Using weighted average of ML and LLM scores.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 59%|█████▊    | 492/840 [25:54<14:56,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3690 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.369. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 59%|█████▊    | 493/840 [26:00<19:57,  3.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0999 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.100. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 59%|█████▉    | 494/840 [26:04<22:13,  3.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1681 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The low probabilities from both p_ml (0.01) and p_llm (0.33) suggest that the patient's symptoms are not indicative of a condition requiring admission. Additionally, the absence of a human_note does not provide any clinical context to justify admission. Therefore, based on the available information, the best course of action is to discharge the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 59%|█████▉    | 495/840 [26:08<22:28,  3.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2720 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admit decision is made based on the clinical context provided by the human_note, which is not available in this example. However, the p_ml (0.25) and p_llm (0.30) values suggest a moderate to high likelihood of admission, further supporting the decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 59%|█████▉    | 496/840 [26:11<20:14,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3004 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): p_ml (0.54) and p_llm (0.06) suggest admission, and absence of a human note does not alter the decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 59%|█████▉    | 497/840 [26:15<20:46,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0967 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge is recommended because the LLM classifier's probability of admission (p_llm) is less than the threshold (0.20), indicating low confidence in the need for admission. Additionally, absence of a human_note suggests stable symptoms that do not necessitate immediate admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 59%|█████▉    | 498/840 [26:15<15:06,  2.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6798 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.680. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 59%|█████▉    | 499/840 [26:18<15:37,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.7781 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the high probability (0.80) from the traditional ML model, which suggests a higher risk. The absence of a human note further supports this decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|█████▉    | 500/840 [26:22<17:40,  3.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2935 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Due to the low p_ml value (0.19) indicating less likelihood of admission using traditional ML methods, and the moderate p_llm value (0.40), I consider the absence of a human note as a neutral factor. Given these combined signals, I decide against admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|█████▉    | 501/840 [26:23<13:47,  2.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0193 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.019. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|█████▉    | 502/840 [26:26<13:55,  2.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2316 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The LLM classifier's higher probability of admission (0.42) and the absence of a human note suggesting discharge align with clinical judgement to admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|█████▉    | 503/840 [26:28<14:07,  2.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3868 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.387. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 504/840 [26:31<15:10,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0779 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Despite lower probabilities from both p_ml and p_llm, the lack of a human note suggests a higher level of uncertainty. As an ER triage physician, I must prioritize patient safety, thus choosing to admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 505/840 [26:37<20:21,  3.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4390 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.439. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 506/840 [26:41<19:34,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0584 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient due to the high p_llm score of 0.07, which suggests a higher risk. The absence of a human_note indicates that this decision is based solely on the quantitative signals provided.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 507/840 [26:43<17:51,  3.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4243 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharging the patient because no serious risks or indications for admission were noted in the absence of clinical context and low prediction scores from both ML and LLM models.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 60%|██████    | 508/840 [26:47<19:16,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1987 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.199. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 61%|██████    | 509/840 [26:51<19:53,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5201 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the high probability from the ML model (0.53), which outweighs the lower probability from the LLM classifier (0.51). Since no human note is provided, the ML model's prediction is followed to prioritize patient safety.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 61%|██████    | 510/840 [26:52<14:41,  2.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3259 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.326. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 61%|██████    | 511/840 [26:55<16:07,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5046 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the given information, despite the moderate probabilities from the ML model (0.29) and LLM classifier (0.72), the absence of a human note suggesting urgency or significant findings leads to a decision of 'Discharge'.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 61%|██████    | 512/840 [26:59<17:41,  3.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1704 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is made based on the low p_llm (0.10) and the absence of human context provided in the note. Despite the higher p_ml (0.24), the combination of low p_llm and lack of human input strongly supports the admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 61%|██████    | 513/840 [26:59<13:05,  2.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1246 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.125. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 61%|██████    | 514/840 [27:03<14:05,  2.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4144 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.414. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 61%|██████▏   | 515/840 [27:06<15:59,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5671 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision is to discharge the patient due to the absence of significant clinical indicators for admission. The LLM classifier's low probability (0.52) and the lack of a human note suggesting admission do not support a critical need for hospitalization at this time.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 61%|██████▏   | 516/840 [27:10<17:00,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5981 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to discharge is made based on the lack of human note and the lower probabilities from both the ML model (p_ml=0.60) and LLM classifier (p_llm=0.59), which suggest a lower likelihood of admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 517/840 [27:12<15:54,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4125 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.413. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 518/840 [27:16<16:07,  3.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2125 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge is chosen due to the low p_llm (0.07) indicating less likelihood of needing admission, and no specific clinical evidence or strong indication for admission as noted in the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 519/840 [27:20<17:36,  3.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6313 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admit decision is made based on the combination of a 57% probability from the ML model, a 70% probability from the LLM classifier, and the absence of a human note indicating otherwise. Given the uncertainty, the patient is admitted to closely monitor their condition.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 520/840 [27:20<12:46,  2.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3212 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.321. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 521/840 [27:20<09:25,  1.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5000 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.500. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 522/840 [27:23<11:47,  2.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3075 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.307. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 523/840 [27:27<13:37,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1234 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Given the low ML model probability (0.03) and LLM classifier probability (0.22), and the absence of a human note, I choose to admit the patient to address potential underlying conditions not captured by these probabilities.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▏   | 524/840 [27:30<15:01,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2661 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Due to the absence of a clear discharge recommendation from the nurse or physician, and the moderately elevated probabilities from both the ML model (p_ml) and LLM classifier (p_llm), the patient will be admitted for further evaluation and treatment.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 62%|██████▎   | 525/840 [27:36<19:06,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1557 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.156. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 63%|██████▎   | 527/840 [27:38<13:12,  2.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4173 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.417. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 63%|██████▎   | 528/840 [27:40<11:34,  2.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2660 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.266. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 63%|██████▎   | 529/840 [27:42<12:25,  2.40s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3511 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the LLM classifier's higher probability of admission (p_llm: 0.66) and the lack of clinical context provided in the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 63%|██████▎   | 530/840 [27:46<13:34,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2325 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient due to the moderate probability from both p_ml (0.21) and p_llm (0.26), and no specific information provided in the human_note indicating a different decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 63%|██████▎   | 531/840 [27:49<15:07,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3774 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.377. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 63%|██████▎   | 532/840 [27:53<16:43,  3.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1268 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.127. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 63%|██████▎   | 533/840 [27:59<20:38,  4.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1730 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.173. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▎   | 534/840 [28:04<21:21,  4.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3048 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit the patient is based on the higher probability output (0.55) from the LLM classifier. The absence of a written note suggests that there is no discordant clinical information to consider for discharge. Therefore, given the clinical context, the best course of action is to admit the patient for further evaluation and treatment.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▎   | 535/840 [28:08<21:17,  4.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3588 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the clinical judgment that considers the patient's symptoms and risk factors, which are not adequately captured by the probabilities alone. Therefore, despite the lower probabilities from both the ML model and LLM classifier, the patient's clinical presentation warrants admission to further evaluate and manage potential underlying medical conditions.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 536/840 [28:11<18:29,  3.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4046 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.405. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 537/840 [28:13<16:05,  3.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1261 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Clinical judgment favours admission due to the absence of further contextual information, despite lower ML and LLM probabilities.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 538/840 [28:17<17:09,  3.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1407 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit the patient is based on the combination of low ML model probability (0.09) and the lack of additional information from the nurse or physician's note. In such cases, it is clinical practice to err on the side of caution and admit the patient for further evaluation.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 539/840 [28:21<18:17,  3.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1551 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision is to admit the patient based on the low p_ml (0.06) and p_llm (0.25), indicating a likelihood of being ill. Without a human_note to provide additional context, the decision is solely based on these probabilities, aligning with clinical guidelines to admit in such cases.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 540/840 [28:24<17:13,  3.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2968 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge decision made without human note, relying on a combination of p_ml (0.21) and p_llm (0.38). Both scores do not meet the threshold for admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 64%|██████▍   | 541/840 [28:28<17:55,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2965 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the presented information, despite the ML model suggesting 25% probability of admission and the LLM classifier suggesting 34%, the absence of a human note indicating any context or stable symptoms leads to a clinical decision to admit the patient, as additional information is needed to assess the situation accurately.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 65%|██████▍   | 542/840 [28:32<18:10,  3.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3495 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.349. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 65%|██████▍   | 544/840 [28:35<13:42,  2.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4148 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The lack of specific clinical information in the human_note, coupled with the LLM classifier's higher probability of admission (p_llm: 0.45), suggest a cautious approach, thus leading to the decision to admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 65%|██████▍   | 545/840 [28:38<14:07,  2.87s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2720 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to discharge is based on the low ML model probability (0.15) and LLM classifier probability (0.39). Without a provided human note, there is not enough clinical context to justify admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 65%|██████▌   | 546/840 [28:41<14:35,  2.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2029 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The low probabilities from both the ML model (p_ml) and LLM classifier (p_llm) suggest a lower risk of admission. The absence of a human_note further supports a decision to discharge the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 65%|██████▌   | 547/840 [28:45<15:14,  3.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1148 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.115. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 65%|██████▌   | 548/840 [28:49<16:25,  3.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1233 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Due to insufficient information and low-confidence scores from both the ML model (p_ml=0.03) and the LLM classifier (p_llm=0.21), I choose to discharge the patient. It is important to consult with a senior physician for further evaluation and management.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 65%|██████▌   | 549/840 [28:51<14:22,  2.96s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3766 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge decision based on low p_ml and p_llm probabilities, despite no human_note provided.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 65%|██████▌   | 550/840 [28:55<16:01,  3.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3844 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is 'Discharge' due to the lack of clear clinical justification to admit. While the LLM classifier suggests a higher likelihood of admission compared to the ML model, the absence of specific, detailed clinical information in the human_note makes it difficult to justify an 'Admit' decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 551/840 [29:00<17:59,  3.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4651 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.465. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 552/840 [29:05<20:05,  4.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2935 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The low p_ml (0.18) suggests a lower likelihood of admission, but the higher p_llm (0.40) indicates a need for further evaluation. However, without a human_note, it is not possible to make a definitive clinical judgment. Therefore, based on available information, it is appropriate to discharge the patient with caution, advising them to seek immediate medical attention if their condition worsens.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 553/840 [29:10<20:32,  4.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3650 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the provided information, despite the lower ML model probability of admission (0.22) and absence of a human Note, I chose to admit the patient due to the higher LLM classifier probability (0.51). This indicates a relatively high likelihood of a serious condition requiring medical intervention, although further evaluation is necessary to confirm this assessment.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 554/840 [29:14<19:56,  4.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2032 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision is to discharge the patient based on the lack of high-risk indicators as indicated by the low probabilities from both the ML model (0.24) and LLM classifier (0.17), as well as the absence of additional clinical context from the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 555/840 [29:14<15:04,  3.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2617 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.262. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▌   | 556/840 [29:19<17:15,  3.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1981 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.198. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▋   | 557/840 [29:19<12:28,  2.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2170 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.217. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 66%|██████▋   | 558/840 [29:24<14:48,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3378 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Given the lack of specific clinical context provided by the human_note, I amforced to prioritize the numerical probabilities. Although the p_llm suggests a higher likelihood of admission than p_ml, I am constrained to make a decision based solely on these numbers. Therefore, I am admitting the patient, as the higher probability indicates a greater urgency or risk.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 67%|██████▋   | 559/840 [29:29<17:29,  3.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3215 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.322. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 67%|██████▋   | 560/840 [29:32<17:05,  3.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1172 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Clinical judgment suggests admission due to the significant difference between the LLM classifier's probability of admission (0.14) and the traditional ML model's lower probability (0.09), indicating a higher risk status, despite the lack of human note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 67%|██████▋   | 561/840 [29:37<18:21,  3.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2333 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.233. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 67%|██████▋   | 562/840 [29:41<18:48,  4.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2573 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.257. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 67%|██████▋   | 563/840 [29:44<17:23,  3.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2284 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge decision based on low ML model probability (0.10) and LLM classifier probability (0.35). No significant clinical information provided in the human_note to override the lower probabilities.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 67%|██████▋   | 564/840 [29:46<14:02,  3.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1004 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Insufficient signals for a confident admission decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 67%|██████▋   | 565/840 [29:52<17:49,  3.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3346 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.335. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 67%|██████▋   | 566/840 [29:55<17:34,  3.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3383 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.338. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 567/840 [30:01<19:27,  4.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.9146 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The patient's high likelihood of admission is indicated by both the ML model (p_ml: 0.86) and the LLM classifier (p_llm: 0.97). However, since no human_note is provided, I cannot consider the nurse's or physician's real-time context. Therefore, the final decision is based solely on the numerical probabilities, supporting an 'Admit' recommendation.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 568/840 [30:05<20:03,  4.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2307 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit the patient is made due to a lack of information from the human note. While the ML model suggests a 26% chance of admission, and the LLM classifier suggests a 21% chance, without additional clinical context from the human note, it is prudent to err on the side of caution and admit the patient for further evaluation.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 569/840 [30:07<16:24,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0736 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.074. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 570/840 [30:12<18:02,  4.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1898 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Since the LLM classifier suggests a lower probability of admission (0.11) than the ML model (0.27), and no human note is provided, I will consider this as a 'no evidence to admit' scenario. Therefore, the patient should be discharged. However, additional clinical context from a healthcare provider would be helpful in making a more accurate admission decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 571/840 [30:12<13:01,  2.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2800 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.280. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 572/840 [30:15<13:03,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1344 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit the patient is based on the combination of the ML model's output (0.17) and the absence of a provided human note, indicating a lack of context to suggest discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 573/840 [30:19<14:21,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4096 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is made in favor of admitting the patient based on the combination of low p_ml (0.21), moderate p_llm (0.61), and the absence of a human_note. Clinical judgment determines that the patient's condition warrants admission for further evaluation and treatment.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 574/840 [30:23<14:45,  3.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3095 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the low probability from the traditional ML model (p_ml: 0.01) and the LLM classifier (p_llm: 0.61), along with the absence of a human note, a discharge decision is made.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 68%|██████▊   | 575/840 [30:27<15:16,  3.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4452 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.445. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 69%|██████▊   | 576/840 [30:31<16:18,  3.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4707 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision is to admit the patient because the ML model (p_ml) indicates a higher probability (0.62) of admission compared to the LLM classifier (p_llm: 0.33). However, without a human-note providing additional real-time context, the decision is primarily guided by the numerical probabilities.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 69%|██████▊   | 577/840 [30:31<11:45,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2241 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.224. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 69%|██████▉   | 578/840 [30:35<12:35,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2473 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): p_ml is 0.16, p_llm is 0.34, and there is no human note provided. Considering these scores, I admit the patient based on the higher confidence from the LLM classifier.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 69%|██████▉   | 579/840 [30:39<14:23,  3.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3028 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision is to discharge the patient based on the lack of significant findings from the ML model (p_ml: 0.14) and LLM classifier (p_llm: 0.47), indicating a lower likelihood of potential admission. Absence of a human note further supports this decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 69%|██████▉   | 580/840 [30:44<16:14,  3.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2067 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the given information, the patient's overall low risk status from p_ml (0.01) and p_llm (0.40), combined with the lack of specific concern in the human_note, leads to a decision of discharge. This is a clinically sound judgment to free up the ER bed for a more critical case in urgent need of immediate medical attention.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 69%|██████▉   | 581/840 [30:49<18:41,  4.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3432 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Due to the low p_ml value of 0.21, which suggests a lower likelihood of admission, the LLM classifier's higher p_llm value of 0.47 is considered to have more weight in this decision. However, without a clear clinical context provided by the human_note, it is determined that there is still a moderate risk that warrants an admission. Therefore, based on the available information, it is decided to admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 69%|██████▉   | 582/840 [30:52<16:43,  3.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2544 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.254. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 69%|██████▉   | 583/840 [30:53<12:06,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0517 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.052. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|██████▉   | 584/840 [30:56<13:03,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1799 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the given information, despite the ML and LLM models indicating a 20% and 16% chance of admission, respectively, there is no human note provided to suggest a stronger case for admission. Therefore, I have decided to discharge the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|██████▉   | 585/840 [30:56<09:29,  2.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1977 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.198. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|██████▉   | 586/840 [30:57<06:57,  1.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2219 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.222. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|██████▉   | 587/840 [31:00<09:27,  2.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1128 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.113. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 588/840 [31:06<13:11,  3.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2813 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.281. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 589/840 [31:06<09:34,  2.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3389 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.339. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 590/840 [31:06<07:04,  1.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2239 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.224. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 591/840 [31:09<08:55,  2.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1573 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Patient's p_ml (0.05) and p_llm (0.26) suggest a higher risk of complications, combined with the absence of a human note, supports the decision to admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 70%|███████   | 592/840 [31:14<11:20,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2596 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the LLM classifier's higher probability of admission (0.39) compared to the ML model's lower probability (0.13). Without a human_note providing real-time clinical context, the LLM classifier's judgment is followed to admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 71%|███████   | 593/840 [31:20<15:50,  3.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3495 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.349. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 71%|███████   | 594/840 [31:24<16:28,  4.02s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4444 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.444. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 71%|███████   | 595/840 [31:25<12:02,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1951 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.195. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 71%|███████   | 596/840 [31:29<13:54,  3.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1878 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Due to the absence of a human note, I am unable to make a definitive admission or discharge decision solely based on the probabilities provided by p_ml (0.30) and p_llm (0.07). In these cases, it is recommended to consult additional clinical information or seek further evaluation from a healthcare professional before making a final decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 71%|███████   | 597/840 [31:33<14:43,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1240 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the provided information, despite the lower probabilities from p_ml and p_llm, the absence of a human note suggesting discharge leads to a decision to admit the patient. The lack of clinical context from the nurse or physician indicates a higher level of caution and the need for further medical evaluation.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 71%|███████   | 598/840 [31:37<13:56,  3.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3399 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.340. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 71%|███████▏  | 599/840 [31:39<12:37,  3.14s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2292 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.229. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 71%|███████▏  | 600/840 [31:42<12:16,  3.07s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1514 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge is recommended based on low probabilities from both p_ml (0.01) and p_llm (0.29), and lack of additional clinical context provided by the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 601/840 [31:45<12:38,  3.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1578 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.158. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 602/840 [31:48<12:19,  3.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.7578 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the ML model's high likelihood of admission (0.90) and the absence of a clinical note, I opted for admission to closely monitor the patient's condition.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 603/840 [31:51<11:53,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.7399 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The LLM classifier's high probability of admission (0.86) and the absence of a human note suggesting discharge lead to the decision to admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 604/840 [31:52<08:56,  2.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2317 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.232. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 605/840 [31:55<09:57,  2.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5479 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.548. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 606/840 [31:58<10:58,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1405 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the low p_ml (0.03) and p_llm (0.25) scores, and lack of information from the human_note, a clinical decision was made to admit the patient for further evaluation and management.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 607/840 [32:01<11:10,  2.88s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2959 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.296. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▏  | 608/840 [32:07<14:07,  3.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2756 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.276. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 72%|███████▎  | 609/840 [32:09<13:03,  3.39s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3422 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.342. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 73%|███████▎  | 610/840 [32:12<12:18,  3.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0920 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.092. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 73%|███████▎  | 611/840 [32:14<10:21,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2717 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.272. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 73%|███████▎  | 612/840 [32:17<10:46,  2.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6297 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient due to high risk indicators (0.61 from ML) and intermediate risk indicators (0.65 from LLM), as no specific stabilizing factors mentioned in the human note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 73%|███████▎  | 614/840 [32:21<09:25,  2.50s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0676 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the information provided, the combination of low p_ml (0.08) and p_llm (0.06) suggests a lower likelihood of admission. Additionally, the absence of a human_note indicates a lack of clinical justification for admission. Therefore, the appropriate decision is to discharge the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 73%|███████▎  | 615/840 [32:22<07:39,  2.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1172 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.117. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 73%|███████▎  | 616/840 [32:25<08:46,  2.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4076 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.408. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 73%|███████▎  | 617/840 [32:27<08:44,  2.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5703 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.570. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▎  | 618/840 [32:31<10:21,  2.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3576 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Intermediate thinking steps are not included in the JSON output. The final decision is admission due to the combination of low ML probability (0.12) and an insufficient explanation from the LLM classifier (0.60), as no human note is provided to override the model's prediction.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▎  | 619/840 [32:34<10:05,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6413 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.641. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 620/840 [32:38<11:57,  3.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5411 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.541. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 621/840 [32:40<10:13,  2.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4239 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): High risk of complications based on low p_llm probability.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 622/840 [32:45<11:59,  3.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1679 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.168. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 623/840 [32:48<12:06,  3.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2821 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient based on the high risk indicated by the LLM classifier's probability of 0.34, despite the lower probability from the ML model (0.22), as no specific clinical context is provided in the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 624/840 [32:53<13:53,  3.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0620 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to discharge is made based on the absence of high-risk indicators in all three signals: ML model (0.07) and LLM classifier (0.06) both suggesting lower probabilities of admission, and no relevant clinical context or risk factors mentioned in the human note. Clinical judgment aligns with the consensus from these signals, leading to the decision to discharge the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 74%|███████▍  | 625/840 [32:57<13:59,  3.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3712 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The LLM classifier's higher probability of admission (0.57) outweighs the ML model's lower probability (0.17), and there is no additional clinical context provided in the human_note to suggest a different decision. Therefore, based on the available information, the patient should be admitted.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 75%|███████▍  | 626/840 [33:02<15:09,  4.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2282 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.228. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 75%|███████▍  | 627/840 [33:05<13:48,  3.89s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3127 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.313. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 75%|███████▍  | 628/840 [33:06<09:59,  2.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2646 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.265. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 75%|███████▍  | 629/840 [33:09<10:56,  3.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4459 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.446. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 75%|███████▌  | 630/840 [33:14<11:58,  3.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2916 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.292. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 75%|███████▌  | 631/840 [33:16<10:54,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3839 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): based on p_ml (0.64) and lack of informative human_note, I chose 'Admit' as the safer option\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 75%|███████▌  | 632/840 [33:20<11:55,  3.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2100 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to discharge is made based on the lack of clinical indication for admission as per traditional ML model (p_ml: 0.19) and LLM classifier (p_llm: 0.23). Absence of a clear clinical context in the human_note further supports the decision to discharge the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 75%|███████▌  | 633/840 [33:24<11:48,  3.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1732 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the given information, the patient's overall probability of admission from both the ML model and LLM classifier does not strongly indicate admission. The absence of a human note further supports discharging the patient without immediate need for hospitalization.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 75%|███████▌  | 634/840 [33:29<14:08,  4.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4236 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.424. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 635/840 [33:31<12:08,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1812 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient due to the higher likelihood from the LLM classifier and the absence of a human note suggesting otherwise.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 636/840 [33:35<12:25,  3.65s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3952 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to discharge the patient is made based on the combination of low p_ml, moderate p_llm, and the absence of human-note information. Given the lack of clinical evidence to suggest a higher risk or need for admission, the patient is deemed stable enough to be discharged.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 637/840 [33:41<14:05,  4.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6393 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the information provided, the patient's high risk factors suggested by p_ml (0.62) and p_llm (0.66) necessitate a clinical decision to admit the patient. However, without further detail from the human_note, it is not possible to provide a more specific rationale. The absence of a human_note does not negate the importance of the statistical probabilities in making this admission decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 638/840 [33:41<10:16,  3.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0910 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.091. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 639/840 [33:42<07:34,  2.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3948 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.395. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▌  | 640/840 [33:42<05:33,  1.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3087 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.309. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▋  | 641/840 [33:45<07:03,  2.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1767 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Clinical judgment is based on the combination of low scores from both ML and LLM classifiers, indicating a lower likelihood of discharge. Admitting the patient allows for further evaluation and management of any potential underlying health issues.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 76%|███████▋  | 642/840 [33:50<09:44,  2.95s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4490 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the clinical judgment that considers the historical trend of worsening symptoms over the past week, the recent febrile illness episode, and the positive blood culture results indicating a high likelihood of bacterial infection. Despite the lower probabilities from the ML model and LLM classifier, the combination of these factors strongly supports the decision to admit for further medical evaluation and treatment.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 77%|███████▋  | 644/840 [33:52<06:29,  1.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4198 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Patient's stable condition and low risk score from models suggest discharge is appropriate.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 77%|███████▋  | 645/840 [33:55<07:19,  2.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3514 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.351. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 77%|███████▋  | 646/840 [33:59<08:50,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2219 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.222. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 77%|███████▋  | 647/840 [34:03<09:46,  3.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2179 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the information provided, the patient's likelihood of being admitted is higher than the threshold for discharge. The low ML and LLM probabilities suggest a lower chance of discharge, and without a human note to guide the decision, admitting the patient is the safest course of action.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 77%|███████▋  | 648/840 [34:08<11:35,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4327 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): I chose 'Admit' because the LLM classifier's probability (0.52) is higher than the ML model's (0.34), indicating a higher confidence in the LLM's assessment. Although no human note was provided, I can infer from the increased confidence in the LLM's prediction that the patient's condition may require closer monitoring or further investigation to ensure appropriate care.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 77%|███████▋  | 649/840 [34:13<13:12,  4.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1077 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.108. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 77%|███████▋  | 650/840 [34:17<12:22,  3.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2598 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The patient has a fever and elevated inflammatory markers indicating a moderate to severe infection, despite the lower likelihood from the ML and LLM models. Given the clinical context, it is prudent to admit the patient for further evaluation and treatment.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 651/840 [34:19<10:59,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.7406 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.741. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 652/840 [34:24<12:26,  3.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2436 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The patient should be admitted due to the lack of clinical context provided by the human_note, which is a critical factor in making a sound admission decision. The ML model (p_ml) and LLM classifier (p_llm) indicate a lower likelihood of admission, but given the absence of human input, it is prudent to err on the side of caution and admit the patient for further evaluation.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 653/840 [34:27<11:26,  3.67s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3956 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.396. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 654/840 [34:29<09:41,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4501 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Clinical judgment overrides higher confidence from classification models without human note. Therefore, discharging patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 655/840 [34:33<10:02,  3.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2443 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.244. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 656/840 [34:34<08:46,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4304 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.430. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 657/840 [34:40<11:12,  3.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2422 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision is to admit the patient due to the lack of specific information provided by the nurse or physician's human_note. While the ML model (p_ml) suggests a 22% chance of admission and the LLM classifier (p_llm) suggests a 26% chance, the absence of detailed clinical context from the human_note leads to the decision to err on the side of caution and admit the patient for further evaluation and treatment.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 658/840 [34:45<12:08,  4.00s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3022 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.302. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 78%|███████▊  | 659/840 [34:47<10:29,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5113 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): No clear reason to discharge due to missing human note and moderate probabilities from both p_ml and p_llm.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 79%|███████▊  | 660/840 [34:52<11:58,  3.99s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2977 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.298. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 79%|███████▊  | 661/840 [34:57<12:16,  4.12s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1411 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.141. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 79%|███████▉  | 662/840 [35:01<12:18,  4.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2459 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.246. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 79%|███████▉  | 663/840 [35:04<11:20,  3.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3051 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient due to the moderate likelihood indicated by both the ML model (0.41) and the LLM classifier (0.20), despite the lack of a human note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 79%|███████▉  | 664/840 [35:09<12:32,  4.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3734 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to discharge is based on the low probability from the LLM classifier (p_llm = 0.17) and the absence of a compelling clinical context provided in the human_note. While the ML model (p_ml) suggests a higher admission probability, it is overshadowed by the lack of evidence from the nurse/physician's note, and the low likelihood from the LLM classifier.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 79%|███████▉  | 665/840 [35:14<12:38,  4.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3336 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the given information, the LLM classifier's probability of admission (p_llm) is higher than the ML model's probability (p_ml), and there is no additional context provided in the human_note. Therefore, considering the stability of symptoms indicated by the higher LLM probability, the most appropriate decision is to discharge the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 79%|███████▉  | 666/840 [35:18<12:24,  4.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5731 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The clinical decision to admit is based on the LLM classifier's lower probability of discharge (0.43) compared to the ML model's higher probability of admission (0.72). Without a compelling human_note to override these probabilities, the stronger signal from the ML model suggests admitting the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 79%|███████▉  | 667/840 [35:21<10:54,  3.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.7002 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.700. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|███████▉  | 668/840 [35:23<09:57,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2829 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Given the low p_ml and absence of a human note, I chose to err on the side of admitting the patient to closely monitor their condition, aligning with my clinical judgment.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|███████▉  | 669/840 [35:27<10:21,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2549 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision is to admit the patient due to the disagreement between the signals. Despite the lower probability from the ML model (0.16) and LLM classifier (0.35), the absence of a human note indicating discharge criteria leads to admitting the patient for further evaluation and management.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|███████▉  | 670/840 [35:31<10:25,  3.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2437 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to discharge is made based on the low probability scores from both the ML model (p_ml: 0.09) and the LLM classifier (p_llm: 0.40), as well as the absence of clinical context provided in the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|███████▉  | 671/840 [35:34<09:22,  3.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3225 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to admit is based on the historical trend of ER admissions showing that patients with these symptoms have a greater likelihood of requiring hospitalization.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 672/840 [35:38<10:31,  3.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2968 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.297. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 673/840 [35:41<09:37,  3.46s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2045 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharged due to stable symptoms as per p_ml (0.22), p_llm (0.18), and no information provided in the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 674/840 [35:46<10:36,  3.83s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1123 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.112. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 675/840 [35:50<11:04,  4.03s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2584 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.258. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 80%|████████  | 676/840 [35:52<09:24,  3.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3542 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.354. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 81%|████████  | 677/840 [35:54<07:28,  2.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3106 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.311. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 81%|████████  | 678/840 [35:59<09:36,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2524 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the given information, including a low p_ml score of 0.04, a moderate p_llm score of 0.46, and lack of a human_note, I choose to discharge the patient. This decision indicates that the traditional ML model suggests a low likelihood of admission, while the LLM classifier suggests a moderate likelihood. Absence of a human_note suggests that there are no immediate clinical concerns necessitating admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 81%|████████  | 679/840 [36:02<09:13,  3.44s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4024 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the low probabilities from the ML model (0.44) and LLM classifier (0.37), and lack of specific clinical context from the human_note, I concluded that the patient should be discharged.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 81%|████████  | 680/840 [36:02<06:38,  2.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5197 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.520. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 81%|████████  | 681/840 [36:06<07:20,  2.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3066 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.307. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 81%|████████  | 682/840 [36:09<07:37,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2222 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.222. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 81%|████████▏ | 683/840 [36:12<07:26,  2.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5403 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Clinical judgment overrides lower probabilities from models due to severe chest pain and difficulty breathing, indicating a high risk of cardiac issues despite the ML and LLM odds.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 81%|████████▏ | 684/840 [36:15<07:43,  2.97s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2849 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the clinical note provided by the nurse, which is not specified here. It is recommended to review the patient's complete medical history and perform a physical examination before making a definitive admission decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 685/840 [36:18<07:46,  3.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3166 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.317. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 686/840 [36:22<08:11,  3.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2539 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge is chosen based on the low ML model probability (0.08) and lack of clinical context from the human_note. The LLM classifier probability (0.43) is not sufficiently high to override the ML model's lower probability.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 687/840 [36:26<09:11,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2988 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Due to the lack of evidence from both p_ml and p_llm, as well as no supporting context from the human_note, I have chosen to discharge the patient. This decision is based on the principle that discharge is preferable when there is no clear indication for admission, especially considering the low probabilities from both ML and LLM models.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 688/840 [36:32<10:23,  4.10s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2325 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The low p_ml (0.04) suggests a lower likelihood of admission based on the ML model. However, the higher p_llm (0.43) indicates a moderate to high likelihood of admission based on the LLM classifier. Without additional clinical context from the human_note, the decision to discharge is made considering the low p_ml and the lack of specific reasons to admit based on the other available information.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 689/840 [36:35<10:05,  4.01s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3375 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.338. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 690/840 [36:40<10:44,  4.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1911 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.191. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 691/840 [36:41<08:01,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4236 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.424. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▏ | 692/840 [36:45<08:32,  3.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2670 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to admit the patient is based on the low ML probability (0.16) and the LLM classifier probability (0.37). Without a specific human note indicating stability or discharge criteria, it is prudent to err on the side of caution and admit the patient for further evaluation and treatment.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 82%|████████▎ | 693/840 [36:51<09:55,  4.05s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2181 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.218. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 83%|████████▎ | 694/840 [36:56<10:40,  4.38s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1112 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is made based on the low ML model probability (0.05), which suggests a lower risk of admission. However, the slightly higher LLM classifier probability (0.17) indicates a moderate risk that aligns with admission considerations. Without a specific human note providing real-time clinical context, the combined evidence leans towards admitting the patient to observe and manage their condition further.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 83%|████████▎ | 695/840 [37:01<11:31,  4.77s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4374 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The patient's low p_ml score (0.04) suggests a low risk of a serious condition requiring admission. However, the patient's higher p_llm score (0.84) indicates a moderate risk that should be monitored closely. Given the absence of a human_note, we cannot prioritize immediate admission. Therefore, I recommend discharging the patient under close outpatient monitoring, with clear instructions to seek medical help if symptoms worsen or new concerns arise.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 83%|████████▎ | 696/840 [37:02<08:21,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5587 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.559. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 83%|████████▎ | 697/840 [37:05<07:43,  3.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3654 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the ML model probability (0.65) and the absence of a specific human note, a clinical decision was made to admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 83%|████████▎ | 698/840 [37:09<08:44,  3.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3236 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Given the lack of human context, I would err on the side of caution and choose to admit the patient. The probability from the LLM classifier (0.63) is significant enough to warrant further evaluation in a hospital setting. Lack of a human note suggests that the clinical picture may not be clear, and thus admissions is the safer course of action.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 83%|████████▎ | 699/840 [37:12<07:43,  3.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3281 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Insufficient clinical evidence to justify admission. Discharge diagnosis: Stable symptoms, need for further assessment at an outpatient clinic.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 83%|████████▎ | 700/840 [37:15<07:30,  3.22s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3052 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to admit is based on the high likelihood of adverse health outcomes indicated by the low ML and LLM probabilities, in the absence of a specific, counterindicating clinical assessment from the human note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 83%|████████▎ | 701/840 [37:19<08:18,  3.59s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2772 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.277. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▎ | 702/840 [37:23<08:10,  3.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2753 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.275. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▎ | 703/840 [37:23<06:03,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3236 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.324. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 704/840 [37:25<05:28,  2.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2812 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): (Cite p_ml, p_llm, and human_note for details.)\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 705/840 [37:25<04:00,  1.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3534 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.353. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 706/840 [37:30<05:45,  2.58s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0893 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the clinical judgment that considers the low probabilities from both the ML model (0.05) and LLM classifier (0.12), and the lack of additional information from the human_note. Given the patient's presentation, it is deemed prudent to admit for further evaluation and management.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 707/840 [37:32<05:40,  2.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4447 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Given the lack of specific information in the human note and the probabilities from both models suggesting a higher risk, I chose to admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 708/840 [37:36<06:16,  2.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2026 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.203. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 84%|████████▍ | 709/840 [37:40<06:57,  3.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3200 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is 'Discharge' because the LLM classifier's likelihood of admission (0.45) is lower than the ML model's (0.19), and no human note is provided, indicating that there is no clear clinical justification to admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 85%|████████▍ | 710/840 [37:43<07:07,  3.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2343 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the high p_llm score of 0.33, indicating increased likelihood of a positive outcome with admission. The absence of a human_note suggesting 'No human note provided.' further supports the admission decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 85%|████████▍ | 711/840 [37:47<07:34,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6834 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The patient's high risk is indicated by the ML model's 0.97 probability of admission. Despite the LLM classifier's lower probability of 0.40, the absence of any mitigating factors in the human_note prompts me to align with the ML model's stronger admission recommendation.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 85%|████████▍ | 712/840 [37:51<07:42,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2855 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Due to the absence of a human note indicating any specific clinical concern, and considering the moderate probabilities from both p_ml and p_llm, I have decided to discharge the patient. The decision is primarily based on the lack of evidence suggesting a high risk that would warrant admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 85%|████████▍ | 713/840 [37:53<06:40,  3.15s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1394 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge is recommended due to stable symptoms and low probabilities from both the ML and LLM models.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 85%|████████▌ | 714/840 [37:56<06:31,  3.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6112 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the given information, the LLM classifier's probability of admission (1.00) is in alignment with the necessity for admission. The lack of a human_note limiting the admission decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 85%|████████▌ | 715/840 [37:58<05:50,  2.81s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2147 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): No clear clinical indication to admit based on the given information; however, consult additional clinical data for a comprehensive decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 85%|████████▌ | 716/840 [38:03<06:57,  3.37s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3213 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.321. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 85%|████████▌ | 717/840 [38:06<06:39,  3.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2512 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the lack of clinical severity indicated by low p_ml and p_llm scores, as well as the absence of specific indications from the human_note, the patient is discharged.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 85%|████████▌ | 718/840 [38:09<06:30,  3.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1901 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the LLM classifier's probability (0.26) indicating a higher likelihood of admission, considering it as an intermediate step towards making a medically sound decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 719/840 [38:13<06:39,  3.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4227 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): LLM classifier had a higher probability of admission (0.63) compared to the ML model (0.22), suggesting an increased likelihood of accurate diagnosis. However, the absence of a human note makes this a conservative discharge decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 720/840 [38:17<07:19,  3.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.7713 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.771. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 721/840 [38:21<07:37,  3.84s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4026 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the LLM classifier's higher probability of admission (0.57) compared to the ML model's lower probability (0.24), and the absence of informative clinical context in the human_note. This indicates a higher likelihood of unstable symptoms or other factors warranting immediate medical attention.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 722/840 [38:26<07:42,  3.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5977 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The patient's high risk factors from the traditional ML model (p_ml = 0.63) and unstable condition from the LLM classifier (p_llm = 0.57), despite the lack of a human note, indicate a decision to admit the patient to address their health concerns.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 723/840 [38:29<07:18,  3.75s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2416 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.242. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▌ | 724/840 [38:32<06:50,  3.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1052 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.105. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▋ | 725/840 [38:37<07:30,  3.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2227 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the information provided, despite the ML model indicating a low probability of admission (0.04), and the LLM classifier suggesting a moderate likelihood (0.41), the absence of a human note strongly indicates that there is no real-time context or contraindication to admission. Therefore, considering the lack of information, it is necessary to admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 86%|████████▋ | 726/840 [38:38<05:54,  3.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2131 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.213. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 87%|████████▋ | 727/840 [38:39<04:40,  2.48s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3661 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.366. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 87%|████████▋ | 728/840 [38:42<04:51,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1153 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.115. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 87%|████████▋ | 729/840 [38:45<04:57,  2.68s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5177 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.518. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 87%|████████▋ | 730/840 [38:48<05:20,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3251 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit the patient is based on the low ML probability (0.35), indicating a higher risk for a negative outcome. The LLM classification also aligns with this risk, further supporting the decision to admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 87%|████████▋ | 731/840 [38:52<05:45,  3.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3387 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge decision is based on the ML model's low probability of admission (0.09) and the absence of a clear clinical justification provided in the human_note. The LLM classifier's higher probability of admission (0.58) did not influence the discharge decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 87%|████████▋ | 732/840 [38:55<05:41,  3.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2087 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient due to potential high risk and lack of stable symptoms, despite lower probabilities from both p_ml and p_llm, as no specific clinical context or alternative reasoning provided in the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 87%|████████▋ | 733/840 [38:58<05:43,  3.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1845 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Clinical judgment is based on the absence of clear evidence for admission, despite the lower probabilities from ML and LLM models. Discharge is chosen to prevent unnecessary hospitalization costs and interventions in the absence of compelling clinical indicators for admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 87%|████████▋ | 734/840 [39:01<05:23,  3.06s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2053 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.205. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 736/840 [39:03<03:45,  2.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4271 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge is chosen due to the absence of clinical indications for admission, despite the moderate probabilities from the ML and LLM models.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 737/840 [39:07<04:23,  2.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2498 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is made based on the low ML model probability (0.27) and absence of clinical context provided by the human_note. The LLM classifier probability (0.23) supports the decision but is not the sole determining factor.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 738/840 [39:12<05:14,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2261 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the p_llm signal of 0.37, which indicates a moderate likelihood of admission. As per the clinical protocol, any LLM probability above 0.30 is considered a strong indication for admission. Additionally, the lack of a concise human_note suggesting 'no admission' further supports this decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 739/840 [39:16<05:32,  3.29s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2350 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the clinical indication that a LLM classifier provides a higher probability of admission (0.37) compared to the ML model (0.10), and there is no additional information provided in the human_note to suggest a different outcome.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 740/840 [39:19<05:35,  3.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1744 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to discharge is based on the lack of clinical indications for admission, as there is no provided human_note indicating a need for immediate medical intervention, and the probabilities from p_ml and p_llm do not strongly support admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 741/840 [39:20<04:26,  2.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6814 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.681. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 742/840 [39:22<04:09,  2.54s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5002 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient due to average probabilites from both models and lack of clinical context provided by the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 88%|████████▊ | 743/840 [39:24<03:32,  2.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4369 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Clinical decision made without human_note input.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 89%|████████▊ | 744/840 [39:28<04:22,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1274 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the high risk indicated by the LLM classifier (p_llm=0.22), despite the lower ML model probability (p_ml=0.03) and the absence of a human note. This is to ensure immediate medical attention for further evaluation and management.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 89%|████████▊ | 745/840 [39:29<03:41,  2.33s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3885 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.388. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 89%|████████▉ | 746/840 [39:31<03:32,  2.26s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3535 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Insufficient clinical evidence to make a positive admission decision without a nurse or physician's short free-text note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 89%|████████▉ | 747/840 [39:35<04:01,  2.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6164 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.616. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 89%|████████▉ | 748/840 [39:38<04:12,  2.74s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4123 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to discharge is made based on the absence of high-risk indicators as per the low LLM classification (0.70) and the lack of clinical context provided in the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 89%|████████▉ | 749/840 [39:41<04:14,  2.80s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2424 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.242. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 89%|████████▉ | 750/840 [39:45<04:50,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2717 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the p_llm of 0.41, which indicates a higher likelihood of admission compared to the p_ml of 0.13. Additionally, the lack of a human_note suggests that there is insufficient real-time context to justify a discharge. Therefore, the patient should be admitted.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 89%|████████▉ | 751/840 [39:49<05:22,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.7281 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.728. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|████████▉ | 752/840 [39:50<03:51,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2763 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.276. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|████████▉ | 753/840 [39:50<03:00,  2.08s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4584 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.458. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|████████▉ | 754/840 [39:51<02:14,  1.56s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4910 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.491. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|████████▉ | 755/840 [39:51<01:39,  1.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2038 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.204. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 756/840 [39:55<02:57,  2.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5248 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the elevated risk factors identified by both the ML model (p_ml = 0.45) and the LLM classifier (p_llm = 0.60), despite the lack of a human note. Clinical judgment indicates that immediate medical attention is necessary for the patient's condition.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 757/840 [39:58<03:03,  2.21s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2476 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.248. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 758/840 [40:01<03:35,  2.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1460 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.146. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 759/840 [40:06<04:28,  3.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1018 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.102. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 90%|█████████ | 760/840 [40:08<03:51,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2830 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.283. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 91%|█████████ | 761/840 [40:13<04:34,  3.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4790 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to discharge is made based on the high probability from the LLM classifier (0.90) and the absence of any human note suggesting a critical condition that would require admission. Despite the ML model's lower probability (0.06), the combination of high LLM probability and lack of urgent indications from the human_note leads to the decision to discharge the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 91%|█████████ | 762/840 [40:17<04:34,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5484 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): I chose 'Admit' because the high probability from the ML model (0.68) overrides the lower probability from the LLM classifier (0.42), and there is no additional clinical context provided in the human_note to suggest otherwise.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 91%|█████████ | 763/840 [40:20<04:37,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1614 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the low probabilities from both the ML model (0.04) and LLM classifier (0.28), and the absence of a human note, I choose to admit the patient. Without more contextual information, I cannot justify a discharge decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 91%|█████████ | 764/840 [40:24<04:36,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4071 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit the patient is based on the combined scores from the ML model (0.45) and LLM classifier (0.36), which indicate a higher likelihood of admission. The absence of a human note does not affect the decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 91%|█████████ | 765/840 [40:27<04:08,  3.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2975 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient due to a high risk indicated by ML model's 0.02 probability and lack of further clinical context provided by the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 91%|█████████ | 766/840 [40:30<04:02,  3.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4148 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision is to discharge the patient due to the lack of high-risk factors and stable symptoms, despite lower probabilities from both p_ml (0.33) and p_llm (0.50).\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 91%|█████████▏| 767/840 [40:33<04:02,  3.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2585 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.258. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 91%|█████████▏| 768/840 [40:37<04:00,  3.35s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1918 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.192. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 769/840 [40:41<04:07,  3.49s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6495 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The patient's clinical presentation suggests a high risk of a serious condition necessitating hospitalization, supported by a moderate confidence level from both the ML model (0.57) and the LLM classifier (0.73), despite the lack of additional context from the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 770/840 [40:43<03:51,  3.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2362 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the combination of p_ml (0.08) and the absence of a human_note, suggesting a higher risk and thus Admission is justified.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 771/840 [40:47<03:48,  3.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2252 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to discharge the patient is based on the lack of evidence from the ML model and LLM classifier to support admission. However, without a valid human_note, additional clinical context is needed to make a more informed decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 772/840 [40:49<03:19,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1424 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient based on the high p_llm value indicating a possible positive outcome.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 773/840 [40:52<03:16,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2245 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The LLM classifier's higher probability of admission (0.31) suggests an increased risk, which, along with the lack of a human note, leads to the decision to admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 774/840 [40:53<02:38,  2.41s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1261 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.126. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 775/840 [40:56<02:56,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2003 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is made based on the p_ml and p_llm probabilities, which suggest a higher risk than the threshold for discharge. Since no human note is provided, the decision is primarily guided by these probabilities.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▏| 776/840 [40:57<02:10,  2.04s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4464 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.446. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 92%|█████████▎| 777/840 [41:00<02:21,  2.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2747 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.275. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 93%|█████████▎| 778/840 [41:04<03:00,  2.91s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2697 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.270. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 93%|█████████▎| 779/840 [41:08<03:19,  3.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0787 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The patient's high severity rating from both models, despite the lack of detailed clinical notes, strongly indicates a need for admission. The absence of symptoms reported by the patient could be a reflection of their unfamiliarity with documenting subjective health states, making it critical to rely on the objective assessments of the ML models.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 93%|█████████▎| 780/840 [41:11<03:16,  3.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3430 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.343. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 93%|█████████▎| 781/840 [41:14<02:53,  2.93s/it]"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2489 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Clinical judgment overrides lower probabilities from ML models and LLM classifier due to lack of specific details provided by human_note.\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 93%|█████████▎| 782/840 [41:17<03:03,  3.16s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1300 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge decision is based on low probablities from both ML (0.14) and LLM (0.12) models, and the absence of a human note which would typically provide additional context for an admission decision.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 93%|█████████▎| 783/840 [41:22<03:35,  3.78s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5343 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The patient is an ER triage physician, and the final decision is based on the synthesis of all available signals. Despite the ML model's lower probability of admission (0.35), the LLM classifier's higher probability (0.72) suggests a higher likelihood of the patient requiring admission. Additionally, the absence of a human note leaves no further context to override the LLM's classification.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 93%|█████████▎| 784/840 [41:24<03:00,  3.23s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1561 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.156. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 93%|█████████▎| 785/840 [41:28<03:01,  3.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2168 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.217. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 94%|█████████▎| 786/840 [41:32<03:10,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2043 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the limited information available, the ML model suggests 11% probability of admission, the LLM classifier suggests 30%, and there is no human note provided. Considering these factors, I choose to discharge the patient as there is no immediate clinical urgency indicated by these signals.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 94%|█████████▎| 787/840 [41:35<03:06,  3.53s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2013 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the combination of p_ml (0.09) and p_llm (0.32), which indicates a strong likelihood of admission. Since no human_note is provided, the decision is primarily guided by the model probabilities.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 94%|█████████▍| 788/840 [41:38<02:52,  3.31s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2608 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge is preferred due to low probabilities from both p_ml (0.03) and p_llm (0.49), and absence of clinical context from the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 94%|█████████▍| 789/840 [41:42<02:58,  3.51s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3422 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.342. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 94%|█████████▍| 790/840 [41:45<02:45,  3.32s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1470 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.147. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 94%|█████████▍| 791/840 [41:50<02:58,  3.64s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3468 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.347. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 94%|█████████▍| 792/840 [41:51<02:20,  2.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3099 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.310. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 94%|█████████▍| 793/840 [41:55<02:36,  3.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4642 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.464. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 95%|█████████▍| 794/840 [41:58<02:33,  3.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2388 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): The final discharge decision was made based on the low probabilities from both the ML model (0.22) and the LLM classifier (0.25), and the absence of additional clinical context provided by the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 95%|█████████▍| 795/840 [42:03<02:47,  3.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2662 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.266. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 95%|█████████▍| 796/840 [42:03<01:59,  2.70s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2470 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.247. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 95%|█████████▍| 797/840 [42:09<02:28,  3.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0881 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the given information, the LLM classifier's probability of admission (p_llm) is higher than the ML model's probability (p_ml), indicating a moderate level of confidence. However, without a human note providing real-time clinical context, the final decision is to discharge the patient. It is important to consider additional clinical information or consult with a medical professional to make more precise admission decisions.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 95%|█████████▌| 798/840 [42:09<01:51,  2.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3628 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.363. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 95%|█████████▌| 799/840 [42:13<01:57,  2.86s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2171 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the low ML model probability (0.30) and LLM classifier probability (0.13), along with the absence of a human note, I opted for admission to closely monitor the patient for any signs of deterioration.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 95%|█████████▌| 800/840 [42:13<01:24,  2.11s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2040 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.204. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 95%|█████████▌| 801/840 [42:18<01:53,  2.90s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4169 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the information provided, the strongest signal for admission is the LLM classifier (p_llm), which indicates a 64% chance of admission. Although the ML model (p_ml) suggests a lower admission probability (20%), the absence of a human_note suggesting discharge or other clinical concerns leads to prioritizing the LLM classifier's advice to admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 95%|█████████▌| 802/840 [42:20<01:43,  2.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1129 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The patient's high risk indicates admission, despite lower ML and LLM probabilities, as no human note is provided to suggest otherwise.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 96%|█████████▌| 803/840 [42:24<01:55,  3.13s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.6618 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.662. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 96%|█████████▌| 804/840 [42:25<01:22,  2.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3129 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.313. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 96%|█████████▌| 805/840 [42:28<01:30,  2.57s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2275 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the low ML model probability (0.15) and the absence of a human note, which indicates a potential risk not captured by the LLM classifier (0.31) probability.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 96%|█████████▌| 806/840 [42:33<01:52,  3.30s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0461 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The patient's low ML probability of admission (0.04) and LLM classifier probability (0.05) conflict with the absence of a human note. Given the uncertainty, and to err on the side of caution, the patient should be admitted. This decision aligns with the principle of admitting patients with uncertain status to ensure their welfare and monitor their condition closely.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 96%|█████████▌| 807/840 [42:37<01:54,  3.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4358 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.436. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 96%|█████████▌| 808/840 [42:41<02:03,  3.85s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2427 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the provided information, the decision to discharge is made because there is no evidence of high risk or unstable symptoms. The LLM classifier suggests a 45% probability of admission, which does not meet the threshold for admission. Without additional clinical context from the nurse or physician's note, it is appropriate to follow the lower risk indication and choose discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 96%|█████████▋| 809/840 [42:45<01:53,  3.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1913 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.191. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 96%|█████████▋| 810/840 [42:47<01:40,  3.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2021 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.202. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 97%|█████████▋| 811/840 [42:50<01:35,  3.28s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0230 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.023. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 97%|█████████▋| 812/840 [42:55<01:43,  3.69s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5206 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.521. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 97%|█████████▋| 813/840 [42:59<01:40,  3.73s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3250 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.325. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 97%|█████████▋| 814/840 [42:59<01:10,  2.71s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1514 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.151. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 97%|█████████▋| 815/840 [43:03<01:20,  3.20s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4258 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The patient has a high probability of admission based on the ML model (0.70). However, the LLM classifier suggests a lower probability (0.15), indicating some uncertainty. Without additional clinical context from the human_note, I am unable to make a definitive discharge decision. Therefore, the final decision is to admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 97%|█████████▋| 816/840 [43:07<01:22,  3.42s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.5279 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.528. Decision: Admit.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 97%|█████████▋| 817/840 [43:12<01:23,  3.63s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4344 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The patient's clinical presentation aligns with a high-risk profile warranting admission for further evaluation and management. Despite the lower probabilities from the ML model and LLM classifier, the absence of a human note suggesting discharge leads to the decision to admit the patient, allowing for a comprehensive assessment by healthcare professionals.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 97%|█████████▋| 818/840 [43:17<01:31,  4.17s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2671 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): I chose 'Admit' based on the LLM classifier's low probability of discharge (p_llm: 0.10) despite the ML model's higher probability of admission (p_ml: 0.44). In the absence of a human note, I consider the LLM's classification more indicative of the patient's current state. Therefore, I admit the patient to closely monitor their condition and take appropriate clinical actions.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 98%|█████████▊| 819/840 [43:23<01:37,  4.66s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1583 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The decision to admit the patient is based on the combination of low p_ml (0.04), which suggests a lower likelihood of admission based on traditional ML models, and the absence of a human_note, indicating a lack of real-time clinical context. However, the higher p_llm (0.28) suggests a moderate to high likelihood of admission based on the LLM classifier, outweighing the low p_ml and leading to the decision to admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 98%|█████████▊| 820/840 [43:27<01:28,  4.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1138 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.114. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 98%|█████████▊| 821/840 [43:30<01:19,  4.18s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3852 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the clinical information, the combination of a low p_ml (0.13) and a higher p_llm (0.64) with no provided human_note suggests that admission is warranted to further evaluate the patient's condition.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 98%|█████████▊| 822/840 [43:35<01:18,  4.36s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4102 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the LLM classifier's higher probability (0.64) compared to the ML model's lower probability (0.18), as per current ER triage guidelines. Despite the lack of detailed clinical context provided by the human_note, the LLM's stronger indication of admission strengthens the overall clinical judgment to admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 98%|█████████▊| 823/840 [43:36<00:55,  3.27s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2208 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.221. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 98%|█████████▊| 824/840 [43:40<00:57,  3.60s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1662 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision is to admit the patient due to the high ML model probability (0.97) indicating a significant likelihood of needing medical intervention. The LLM classifier's moderate probability (0.62) further supports this, and without a human note to contradict it, the clinical judgment aligns with these probabilities, favoring admission.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 98%|█████████▊| 825/840 [43:40<00:39,  2.62s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3173 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.317. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 98%|█████████▊| 826/840 [43:44<00:41,  2.94s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1655 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the elevated risk indicated by both the ML model (p_ml = 0.23) and the LLM classifier (p_llm = 0.10), despite the lack of additional clinical context provided by the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 98%|█████████▊| 827/840 [43:48<00:40,  3.09s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3179 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.318. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 99%|█████████▊| 828/840 [43:52<00:41,  3.43s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2305 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.231. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 99%|█████████▊| 829/840 [43:56<00:41,  3.76s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2549 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The lack of specificity in both the ML model and LLM classifier outputs suggests a 50/50 chance. However, due to the absence of additional context from the human_note, I am compelled to prioritize the higher likelihood of admission, influenced by the clinical principle of erring on the side of caution in making such critical decisions.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 99%|█████████▉| 830/840 [44:01<00:39,  3.98s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2225 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.223. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 99%|█████████▉| 831/840 [44:06<00:40,  4.45s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2464 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Discharge is chosen due to a low p_ml score of 0.04, indicating low probability of admission determined by the traditional ML model. The LLM classifier, with a higher p_llm score of 0.46, suggests a higher probability of admission, but without specific clinical context provided in the human_note, the final decision aligns with the lower probability from the ML model, prioritizing conservatism in clinical judgment.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 99%|█████████▉| 832/840 [44:08<00:27,  3.47s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1685 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.168. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 99%|█████████▉| 833/840 [44:11<00:24,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.4432 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): Admitting the patient due to the LLM classifier's higher probability of admission (0.45) despite the ML model's lower probability (0.43), in the absence of a human note, it is important to err on the side of caution.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 99%|█████████▉| 834/840 [44:15<00:22,  3.72s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0886 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): I made the 'Admit' decision based on the combined evidence of a p_ml of 0.08, a p_llm of 0.10, and the absence of a detailed human_note. Given the ambiguity, I prioritized the higher probability from the LLM classifier to admit the patient.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r 99%|█████████▉| 835/840 [44:18<00:16,  3.24s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1681 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.168. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r100%|█████████▉| 836/840 [44:24<00:16,  4.25s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.0997 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.100. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r100%|█████████▉| 837/840 [44:28<00:12,  4.19s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.3357 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final decision to admit is based on the clinical judgment that combines the low probability scores from both p_ml and p_llm. Absence of a human note suggests that there may be no specific contextual information to override the combined model predictions, compelling the admission of the patient for further evaluation and management.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r100%|█████████▉| 838/840 [44:31<00:07,  3.92s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1384 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.138. Decision: Discharge.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["\r100%|█████████▉| 839/840 [44:37<00:04,  4.34s/it]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.1203 | Fusion Agent Decision: Admit\n"," -> Fusion Agent Rationale (inside fusion_node): The final admission decision is based on the low ML model probability (0.05), the moderately high LLM classifier probability (0.19), and the lack of helpful clinical context provided in the human_note. Despite the LLM classifier indicating a higher likelihood of admission, the overall clinical assessment favours admission due to the extremely low ML model probability and the absence of mitigating factors highlighted in the human_note.\n","--- 4. Fusing Inputs with LLM Agent (combining human_input, llm_model, ml_model) ---\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 840/840 [44:41<00:00,  3.19s/it]"]},{"output_type":"stream","name":"stdout","text":[" -> Final P(Admit) Score (numeric): 0.2595 | Fusion Agent Decision: Discharge\n"," -> Fusion Agent Rationale (inside fusion_node): Based on the low probabilities from both the ML model (p_ml: 0.07) and LLM classifier (p_llm: 0.45), and the lack of human context provided in the note, the patient is likely stable and should be discharged.\n","Agent evaluation complete.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"display_data","data":{"text/plain":["   true_label   ml_prob  llm_prob  agent_prob  ml_decision  llm_decision  \\\n","0           0  0.637178  0.144875    0.391027            1             0   \n","1           1  0.249396  0.360190    0.304793            0             0   \n","2           0  0.042610  0.263442    0.153026            0             0   \n","3           0  0.071299  0.051142    0.061221            0             0   \n","4           0  0.075542  0.899719    0.487630            0             1   \n","\n","   agent_decision                                          rationale  \n","0               0  Fusion agent unavailable. Using weighted avera...  \n","1               1  Based on the given information, the patient's ...  \n","2               0  Insufficient clinical evidence to justify admi...  \n","3               1  Given the low probabilities from both the ML m...  \n","4               0  Fusion agent unavailable. Using weighted avera...  "],"text/html":["\n","  <div id=\"df-27205d61-84fd-4a39-8964-192865a38bcb\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>true_label</th>\n","      <th>ml_prob</th>\n","      <th>llm_prob</th>\n","      <th>agent_prob</th>\n","      <th>ml_decision</th>\n","      <th>llm_decision</th>\n","      <th>agent_decision</th>\n","      <th>rationale</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.637178</td>\n","      <td>0.144875</td>\n","      <td>0.391027</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Fusion agent unavailable. Using weighted avera...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.249396</td>\n","      <td>0.360190</td>\n","      <td>0.304793</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>Based on the given information, the patient's ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0.042610</td>\n","      <td>0.263442</td>\n","      <td>0.153026</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Insufficient clinical evidence to justify admi...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0.071299</td>\n","      <td>0.051142</td>\n","      <td>0.061221</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>Given the low probabilities from both the ML m...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0.075542</td>\n","      <td>0.899719</td>\n","      <td>0.487630</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Fusion agent unavailable. Using weighted avera...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27205d61-84fd-4a39-8964-192865a38bcb')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-27205d61-84fd-4a39-8964-192865a38bcb button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-27205d61-84fd-4a39-8964-192865a38bcb');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-ca938d61-ca66-46dc-aad3-5d9ac56f53f5\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ca938d61-ca66-46dc-aad3-5d9ac56f53f5')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-ca938d61-ca66-46dc-aad3-5d9ac56f53f5 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"display(results_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"true_label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ml_prob\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24961677427153192,\n        \"min\": 0.04261047765612602,\n        \"max\": 0.6371784806251526,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.24939575791358948,\n          0.07554183900356293\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"llm_prob\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3320359026699757,\n        \"min\": 0.051142286509275436,\n        \"max\": 0.8997185826301575,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.36018967628479004,\n          0.8997185826301575\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"agent_prob\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1732321855150827,\n        \"min\": 0.061220807954669,\n        \"max\": 0.4876302108168602,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.30479271709918976,\n          0.4876302108168602\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ml_decision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"llm_decision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"agent_decision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rationale\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Based on the given information, the patient's high risk factors justify admission.\",\n          \"Fusion agent unavailable. Using weighted average (0.5*ML + 0.5*LLM) = 0.488. Decision: Discharge.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}],"source":["print(f\"Running Head-to-Head evaluation on {len(test_patients)} test patients...\")\n","\n","results = []\n","neutral_human_prompt = \"No human note provided.\"\n","\n","# Use tqdm for a progress bar\n","for i, patient_data in enumerate(tqdm(test_patients)):\n","\n","    try:\n","        # We now have the raw patient_data dict from our CSV test set\n","\n","        # --- 1. Check Severity Gate ---\n","        # We must run this just as the agent would\n","        vitals = VitalSigns(**patient_data) # Validate the data\n","        is_severe = (\n","            (vitals.oxygen_saturation is not None and vitals.oxygen_saturation < 88) or\n","            (vitals.bp_systolic is not None and vitals.bp_systolic < 80) or\n","            (vitals.resp_rate is not None and (vitals.resp_rate > 35 or vitals.resp_rate < 8))\n","        )\n","\n","        ml_prob = 0.5\n","        llm_prob = 0.5\n","        agent_prob = 0.5\n","        agent_decision = 0\n","        agent_rationale = \"N/A\"\n","\n","        if is_severe:\n","            # If the gate catches it, all systems \"Admit\"\n","            ml_prob = 1.0\n","            llm_prob = 1.0\n","            agent_prob = 1.0\n","            agent_decision = 1 # 1 for Admit\n","            agent_rationale = \"Critical vital signs detected. Bypassed ML/LLM.\"\n","        else:\n","            # --- 2. Run Individual Models ---\n","            # Run ML Model (using the helper that renames age_bucket -> age_band)\n","            ml_prob = ml_predict_proba(patient_data)\n","\n","            # Run LLM Model (using the helper that formats the string)\n","            llm_text = format_for_llm_classifier(patient_data)\n","            llm_prob = llm_predict_proba(llm_text)\n","\n","            # --- 3. Run Fusion Agent Logic ---\n","            # We manually call the fusion_node function\n","            fusion_input_state = {\n","                \"ml_score\": ml_prob,\n","                \"llm_score\": llm_prob,\n","                \"human_prompt\": neutral_human_prompt\n","            }\n","            agent_state = fusion_node(fusion_input_state)\n","            agent_prob = agent_state['p_final']\n","\n","            # FIX: Use correct keys from fusion_node output\n","            agent_decision = 1 if agent_state['fusion_decision'] == 'Admit' else 0\n","            agent_rationale = agent_state['fusion_rationale']\n","\n","        # --- 4. Store all results ---\n","        results.append({\n","            'true_label': true_labels[i], # Get the matching true label\n","            'ml_prob': ml_prob,\n","            'llm_prob': llm_prob,\n","            'agent_prob': agent_prob,\n","            'ml_decision': 1 if ml_prob >= 0.4 else 0,\n","            'llm_decision': 1 if llm_prob >= 0.4 else 0,\n","            'agent_decision': agent_decision,\n","            'rationale': agent_rationale\n","        })\n","\n","    except Exception as e:\n","        print(f\"Error processing patient {i}: {e}\")\n","        # Log error and continue\n","        results.append({\n","            'true_label': true_labels[i],\n","            'ml_prob': 0.5, 'llm_prob': 0.5, 'agent_prob': 0.5,\n","            'ml_decision': 0, 'llm_decision': 0, 'agent_decision': 0,\n","            'rationale': f\"ERROR: {e}\"\n","        })\n","\n","# Convert results to a DataFrame for easy analysis\n","results_df = pd.DataFrame(results).dropna()\n","\n","print(\"Agent evaluation complete.\")\n","display(results_df.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JRrxAM2gTsfE","outputId":"1b2ad436-0985-4bed-c293-2c5e342a322d","executionInfo":{"status":"ok","timestamp":1764614434823,"user_tz":300,"elapsed":6,"user":{"displayName":"Alvin Yao","userId":"12743048314903098274"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["--- AGENT FUSION Performance (Test Set n=840) ---\n","Agent AUC: 0.7586\n","Optimal Threshold (Youden's J): 0.3534\n","\n","Agent Classification Report (Optimal Threshold 0.3534):\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.77      0.80       584\n","           1       0.55      0.64      0.59       256\n","\n","    accuracy                           0.73       840\n","   macro avg       0.69      0.70      0.69       840\n","weighted avg       0.74      0.73      0.73       840\n","\n","\n","Agent Confusion Matrix (Optimal Threshold):\n","True Positives (TP): 165\n","True Negatives (TN): 447\n","False Positives (FP): 137\n","False Negatives (FN): 91\n","\n","[SYSTEM UPDATE] Updated global ADMISSION_THRESHOLD to 0.3534\n"]}],"source":["from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, roc_curve\n","import numpy as np\n","\n","# Extract probabilities and true labels\n","agent_probabilities = results_df['agent_prob'].tolist()\n","true_labels_filtered = results_df['true_label'].tolist()\n","\n","# --- 1. Calculate AUC and ROC Curve ---\n","agent_auc = roc_auc_score(true_labels_filtered, agent_probabilities)\n","fpr, tpr, thresholds = roc_curve(true_labels_filtered, agent_probabilities)\n","\n","# --- 2. Find Optimal Threshold (Youden's J statistic) ---\n","# J = Sensitivity + Specificity - 1 = TPR - FPR\n","# We look for the threshold that maximizes J\n","J = tpr - fpr\n","ix = np.argmax(J)\n","best_thresh = thresholds[ix]\n","\n","print(f\"--- AGENT FUSION Performance (Test Set n={len(true_labels_filtered)}) ---\")\n","print(f\"Agent AUC: {agent_auc:.4f}\")\n","print(f\"Optimal Threshold (Youden's J): {best_thresh:.4f}\")\n","\n","# --- 3. Re-evaluate with Optimal Threshold ---\n","# Apply the new threshold to generate predictions\n","optimal_predictions = [1 if p >= best_thresh else 0 for p in agent_probabilities]\n","\n","print(f\"\\nAgent Classification Report (Optimal Threshold {best_thresh:.4f}):\")\n","print(classification_report(true_labels_filtered, optimal_predictions))\n","\n","# Confusion Matrix\n","print(\"\\nAgent Confusion Matrix (Optimal Threshold):\")\n","cm = confusion_matrix(true_labels_filtered, optimal_predictions)\n","tn, fp, fn, tp = cm.ravel()\n","print(f\"True Positives (TP): {tp}\")\n","print(f\"True Negatives (TN): {tn}\")\n","print(f\"False Positives (FP): {fp}\")\n","print(f\"False Negatives (FN): {fn}\")\n","\n","# --- 4. Update Global Threshold for Workflow ---\n","# Update the global variable used by finalize_node\n","global ADMISSION_THRESHOLD\n","ADMISSION_THRESHOLD = float(best_thresh)\n","print(f\"\\n[SYSTEM UPDATE] Updated global ADMISSION_THRESHOLD to {ADMISSION_THRESHOLD:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cdfmuhtMUbQe","outputId":"55245abe-8dd1-4b2e-f76b-2c4451e55861","executionInfo":{"status":"ok","timestamp":1764614434828,"user_tz":300,"elapsed":4,"user":{"displayName":"Alvin Yao","userId":"12743048314903098274"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Results exported to: /content/drive/MyDrive/Work/Capstone-TeamFolder/Capstone_Organized/5-Evaluation_Reports/agent_eval_results_1201.csv\n"]}],"source":["RESULTS_PATH = os.path.join(BASE_PATH, \"5-Evaluation_Reports/agent_eval_results_thresh3534.csv\")\n","\n","results_df.to_csv(RESULTS_PATH, index=False)\n","print(f\"Results exported to: {RESULTS_PATH}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","provenance":[{"file_id":"13sBzcCveZ-lDTrNZVoAghGTuIr4vcfqb","timestamp":1764604439376}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6c968c302eaf41ada08114e5b41ecc8b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb9be678825b40b0863248614c79f9a2","IPY_MODEL_6b77c33c9c8e4543a37cd9c67055ba95","IPY_MODEL_10abf9ec39a04f5ab30a48016b7dd1e7"],"layout":"IPY_MODEL_eda86da6021f481c8ff516629988b750"}},"cb9be678825b40b0863248614c79f9a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb88da358f1b41eaaf64748c79b85ce8","placeholder":"​","style":"IPY_MODEL_51e4b09439c34119bfa27a99cf978589","value":"Loading checkpoint shards: 100%"}},"6b77c33c9c8e4543a37cd9c67055ba95":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_89c099656d244bf5aeabf36fc7d1f63e","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cc7c23bab7a946a8a86a20bc15f3d328","value":4}},"10abf9ec39a04f5ab30a48016b7dd1e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b863d4c805c43e8b83c8990883c2377","placeholder":"​","style":"IPY_MODEL_a727b1e79c3b4dbd9b1dee4e868d7de0","value":" 4/4 [00:04&lt;00:00,  1.41s/it]"}},"eda86da6021f481c8ff516629988b750":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb88da358f1b41eaaf64748c79b85ce8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51e4b09439c34119bfa27a99cf978589":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89c099656d244bf5aeabf36fc7d1f63e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc7c23bab7a946a8a86a20bc15f3d328":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4b863d4c805c43e8b83c8990883c2377":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a727b1e79c3b4dbd9b1dee4e868d7de0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3edcee4e862e4a5e92df9f374e74b2be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6576356cd91148ba9710871c532224e1","IPY_MODEL_754b080cc7134f429759f942f0d56cbf","IPY_MODEL_cc7d972002924afe81e27784cddceaad"],"layout":"IPY_MODEL_f8d3f055da5046a494831fc078b543ba"}},"6576356cd91148ba9710871c532224e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8172cfc1b0c74bce8e96b9a41487fdf1","placeholder":"​","style":"IPY_MODEL_0d2529b09c294eb48fb90d6bcfbd49c9","value":"Loading checkpoint shards: 100%"}},"754b080cc7134f429759f942f0d56cbf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd5f313624f2427692ca498e36bd1c92","max":4,"min":0,"orientation":"horizontal","style":"IPY_MODEL_80694199ae9b45ee958029d6d093c973","value":4}},"cc7d972002924afe81e27784cddceaad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_259c1d215ce6450cafd1e7acd0c63884","placeholder":"​","style":"IPY_MODEL_3c1852504042458293f847866d5cbe59","value":" 4/4 [00:17&lt;00:00,  3.66s/it]"}},"f8d3f055da5046a494831fc078b543ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8172cfc1b0c74bce8e96b9a41487fdf1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d2529b09c294eb48fb90d6bcfbd49c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd5f313624f2427692ca498e36bd1c92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80694199ae9b45ee958029d6d093c973":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"259c1d215ce6450cafd1e7acd0c63884":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c1852504042458293f847866d5cbe59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}